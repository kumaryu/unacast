/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/renderer/azureStt.ts");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/* global fetch, btoa, Headers */\nconst core = __webpack_require__(/*! ./core */ \"./node_modules/bent/src/core.js\")\n\nclass StatusError extends Error {\n  constructor (res, ...params) {\n    super(...params)\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, StatusError)\n    }\n\n    this.name = 'StatusError'\n    this.message = res.statusMessage\n    this.statusCode = res.status\n    this.res = res\n    this.json = res.json.bind(res)\n    this.text = res.text.bind(res)\n    this.arrayBuffer = res.arrayBuffer.bind(res)\n    let buffer\n    const get = () => {\n      if (!buffer) buffer = this.arrayBuffer()\n      return buffer\n    }\n    Object.defineProperty(this, 'responseBody', { get })\n    // match Node.js headers object\n    this.headers = {}\n    for (const [key, value] of res.headers.entries()) {\n      this.headers[key.toLowerCase()] = value\n    }\n  }\n}\n\nconst mkrequest = (statusCodes, method, encoding, headers, baseurl) => async (_url, body, _headers = {}) => {\n  _url = baseurl + (_url || '')\n  let parsed = new URL(_url)\n\n  if (!headers) headers = {}\n  if (parsed.username) {\n    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password)\n    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search)\n  }\n  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {\n    throw new Error(`Unknown protocol, ${parsed.protocol}`)\n  }\n\n  if (body) {\n    if (body instanceof ArrayBuffer ||\n      ArrayBuffer.isView(body) ||\n      typeof body === 'string'\n    ) {\n      // noop\n    } else if (typeof body === 'object') {\n      body = JSON.stringify(body)\n      headers['Content-Type'] = 'application/json'\n    } else {\n      throw new Error('Unknown body type.')\n    }\n  }\n\n  _headers = new Headers({ ...(headers || {}), ..._headers })\n\n  const resp = await fetch(parsed, { method, headers: _headers, body })\n  resp.statusCode = resp.status\n\n  if (!statusCodes.has(resp.status)) {\n    throw new StatusError(resp)\n  }\n\n  if (encoding === 'json') return resp.json()\n  else if (encoding === 'buffer') return resp.arrayBuffer()\n  else if (encoding === 'string') return resp.text()\n  else return resp\n}\n\nmodule.exports = core(mkrequest)\n\n\n//# sourceURL=webpack:///./node_modules/bent/src/browser.js?");

/***/ }),

/***/ "./node_modules/bent/src/core.js":
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nconst encodings = new Set(['json', 'buffer', 'string'])\n\nmodule.exports = mkrequest => (...args) => {\n  const statusCodes = new Set()\n  let method\n  let encoding\n  let headers\n  let baseurl = ''\n\n  args.forEach(arg => {\n    if (typeof arg === 'string') {\n      if (arg.toUpperCase() === arg) {\n        if (method) {\n          const msg = `Can't set method to ${arg}, already set to ${method}.`\n          throw new Error(msg)\n        } else {\n          method = arg\n        }\n      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {\n        baseurl = arg\n      } else {\n        if (encodings.has(arg)) {\n          encoding = arg\n        } else {\n          throw new Error(`Unknown encoding, ${arg}`)\n        }\n      }\n    } else if (typeof arg === 'number') {\n      statusCodes.add(arg)\n    } else if (typeof arg === 'object') {\n      if (Array.isArray(arg) || arg instanceof Set) {\n        arg.forEach(code => statusCodes.add(code))\n      } else {\n        if (headers) {\n          throw new Error('Cannot set headers twice.')\n        }\n        headers = arg\n      }\n    } else {\n      throw new Error(`Unknown type: ${typeof arg}`)\n    }\n  })\n\n  if (!method) method = 'GET'\n  if (statusCodes.size === 0) {\n    statusCodes.add(200)\n  }\n\n  return mkrequest(statusCodes, method, encoding, headers, baseurl)\n}\n\n\n//# sourceURL=webpack:///./node_modules/bent/src/core.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/catchErrors.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-log/src/catchErrors.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/**\n * Some ideas from sindresorhus/electron-unhandled\n */\n\nvar electronApi = __webpack_require__(/*! ./electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\n\nvar isAttached = false;\n\nmodule.exports = function catchErrors(options) {\n  if (isAttached) return { stop: stop };\n  isAttached = true;\n\n  if (process.type === 'renderer') {\n    window.addEventListener('error', onRendererError);\n    window.addEventListener('unhandledrejection', onRendererRejection);\n  } else {\n    process.on('uncaughtException', onError);\n    process.on('unhandledRejection', onRejection);\n  }\n\n  return { stop: stop };\n\n  function onError(e) {\n    try {\n      if (typeof options.onError === 'function') {\n        if (options.onError(e) === false) {\n          return;\n        }\n      }\n\n      options.log(e);\n\n      if (options.showDialog && e.name.indexOf('UnhandledRejection') < 0) {\n        var type = process.type || 'main';\n        electronApi.showErrorBox(\n          'A JavaScript error occurred in the ' + type + ' process',\n          e.stack\n        );\n      }\n    } catch (logError) {\n      // eslint-disable-next-line no-console\n      console.error(e);\n    }\n  }\n\n  function onRejection(reason) {\n    if (reason instanceof Error) {\n      var reasonName = 'UnhandledRejection ' + reason.name;\n\n      var errPrototype = Object.getPrototypeOf(reason);\n      var nameProperty = Object.getOwnPropertyDescriptor(errPrototype, 'name');\n      if (!nameProperty || !nameProperty.writable) {\n        reason = new Error(reason.message);\n      }\n\n      reason.name = reasonName;\n      onError(reason);\n      return;\n    }\n\n    var error = new Error(JSON.stringify(reason));\n    error.name = 'UnhandledRejection';\n    onError(error);\n  }\n\n  function onRendererError(event) {\n    event.preventDefault();\n    onError(event.error);\n  }\n\n  function onRendererRejection(event) {\n    event.preventDefault();\n    onRejection(event.reason);\n  }\n\n  function stop() {\n    isAttached = false;\n\n    if (process.type === 'renderer') {\n      window.removeEventListener('error', onRendererError);\n      window.removeEventListener('unhandledrejection', onRendererRejection);\n    } else {\n      process.removeListener('uncaughtException', onError);\n      process.removeListener('unhandledRejection', onRejection);\n    }\n  }\n};\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/catchErrors.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/electronApi.js":
/*!******************************************************!*\
  !*** ./node_modules/electron-log/src/electronApi.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/**\n * Split Electron API from the main code\n */\n\nvar electron;\ntry {\n  // eslint-disable-next-line global-require\n  electron = __webpack_require__(/*! electron */ \"electron\");\n} catch (e) {\n  electron = null;\n}\n\nmodule.exports = {\n  getName: getName,\n  getPath: getPath,\n  getVersion: getVersion,\n  isDev: isDev,\n  isElectron: isElectron,\n  isIpcChannelListened: isIpcChannelListened,\n  loadRemoteModule: loadRemoteModule,\n  onIpc: onIpc,\n  sendIpc: sendIpc,\n  showErrorBox: showErrorBox,\n};\n\nfunction getApp() {\n  return getElectronModule('app');\n}\n\nfunction getName() {\n  var app = getApp();\n  if (!app) return null;\n\n  return 'name' in app ? app.name : app.getName();\n}\n\nfunction getElectronModule(name) {\n  if (!electron) {\n    return null;\n  }\n\n  if (electron[name]) {\n    return electron[name];\n  }\n\n  if (electron.remote) {\n    return electron.remote[name];\n  }\n\n  return null;\n}\n\nfunction getIpc() {\n  if (process.type === 'browser' && electron && electron.ipcMain) {\n    return electron.ipcMain;\n  }\n\n  if (process.type === 'renderer' && electron && electron.ipcRenderer) {\n    return electron.ipcRenderer;\n  }\n\n  return null;\n}\n\n\nfunction getPath(name) {\n  var app = getApp();\n  if (!app) return null;\n\n  try {\n    return app.getPath(name);\n  } catch (e) {\n    return null;\n  }\n}\n\nfunction getRemote() {\n  if (electron && electron.remote) {\n    return electron.remote;\n  }\n\n  return null;\n}\n\nfunction getVersion() {\n  var app = getApp();\n  if (!app) return null;\n\n  return 'version' in app ? app.version : app.getVersion();\n}\n\nfunction isDev() {\n  // based on sindresorhus/electron-is-dev\n  var app = getApp();\n  if (!app) return false;\n\n  return !app.isPackaged || process.env.ELECTRON_IS_DEV === '1';\n}\n\nfunction isElectron() {\n  return process.type === 'browser' || process.type === 'renderer';\n}\n\n/**\n * Return true if the process listens for the IPC channel\n * @param {string} channel\n */\nfunction isIpcChannelListened(channel) {\n  var ipc = getIpc();\n  return ipc ? ipc.listenerCount(channel) > 0 : false;\n}\n\n/**\n * Try to load the module in the opposite process\n * @param {string} moduleName\n */\nfunction loadRemoteModule(moduleName) {\n  if (process.type === 'browser') {\n    getApp().on('web-contents-created', function (e, contents) {\n      var promise = contents.executeJavaScript(\n        'try {require(\"' + moduleName + '\")} catch(e){}; void 0;'\n      );\n\n      // Do nothing on error, just prevent Unhandled rejection\n      if (promise && typeof promise.catch === 'function') {\n        promise.catch(function () {});\n      }\n    });\n  } else if (process.type === 'renderer') {\n    try {\n      getRemote().require(moduleName);\n    } catch (e) {\n      // Can't be required. Webpack?\n    }\n  }\n}\n\n/**\n * Listen to async messages sent from opposite process\n * @param {string} channel\n * @param {function} listener\n */\nfunction onIpc(channel, listener) {\n  var ipc = getIpc();\n  if (ipc) {\n    ipc.on(channel, listener);\n  }\n}\n\n/**\n * Sent a message to opposite process\n * @param {string} channel\n * @param {any} message\n */\nfunction sendIpc(channel, message) {\n  if (process.type === 'browser') {\n    sendIpcToRenderer(channel, message);\n  } else if (process.type === 'renderer') {\n    sendIpcToMain(channel, message);\n  }\n}\n\nfunction sendIpcToMain(channel, message) {\n  var ipc = getIpc();\n  if (ipc) {\n    ipc.send(channel, message);\n  }\n}\n\nfunction sendIpcToRenderer(channel, message) {\n  if (!electron || !electron.BrowserWindow) {\n    return;\n  }\n\n  electron.BrowserWindow.getAllWindows().forEach(function (wnd) {\n    wnd.webContents && wnd.webContents.send(channel, message);\n  });\n}\n\nfunction showErrorBox(title, message) {\n  var dialog = getElectronModule('dialog');\n  if (!dialog) return;\n\n  dialog.showErrorBox(title, message);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/electronApi.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/index.js":
/*!************************************************!*\
  !*** ./node_modules/electron-log/src/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar catchErrors = __webpack_require__(/*! ./catchErrors */ \"./node_modules/electron-log/src/catchErrors.js\");\nvar electronApi = __webpack_require__(/*! ./electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar log = __webpack_require__(/*! ./log */ \"./node_modules/electron-log/src/log.js\").log;\nvar scopeFactory = __webpack_require__(/*! ./scope */ \"./node_modules/electron-log/src/scope.js\");\nvar transportConsole = __webpack_require__(/*! ./transports/console */ \"./node_modules/electron-log/src/transports/console.js\");\nvar transportFile = __webpack_require__(/*! ./transports/file */ \"./node_modules/electron-log/src/transports/file/index.js\");\nvar transportIpc = __webpack_require__(/*! ./transports/ipc */ \"./node_modules/electron-log/src/transports/ipc.js\");\nvar transportRemote = __webpack_require__(/*! ./transports/remote */ \"./node_modules/electron-log/src/transports/remote.js\");\n\nmodule.exports = create('default');\nmodule.exports.default = module.exports;\n\n/**\n * @param {string} logId\n * @return {ElectronLog.ElectronLog}\n */\nfunction create(logId) {\n  /**\n   * @type {ElectronLog.ElectronLog}\n   */\n  var instance = {\n    catchErrors: function callCatchErrors(options) {\n      var opts = Object.assign({}, {\n        log: instance.error,\n        showDialog: process.type === 'browser',\n      }, options || {});\n\n      catchErrors(opts);\n    },\n    create: create,\n    functions: {},\n    hooks: [],\n    isDev: electronApi.isDev(),\n    levels: ['error', 'warn', 'info', 'verbose', 'debug', 'silly'],\n    logId: logId,\n    variables: {\n      processType: process.type,\n    },\n  };\n\n  instance.scope = scopeFactory(instance);\n\n  instance.transports = {\n    console: transportConsole(instance),\n    file: transportFile(instance),\n    remote: transportRemote(instance),\n    ipc: transportIpc(instance),\n  };\n\n  instance.levels.forEach(function (level) {\n    instance[level] = log.bind(null, instance, { level: level });\n    instance.functions[level] = instance[level];\n  });\n\n  instance.log = log.bind(null, instance, { level: 'info' });\n  instance.functions.log = instance.log;\n\n  return instance;\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/log.js":
/*!**********************************************!*\
  !*** ./node_modules/electron-log/src/log.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = {\n  compareLevels: compareLevels,\n  log: log,\n  runTransport: runTransport,\n  runTransports: runTransports,\n};\n\nfunction log(electronLog, options) {\n  var transports = electronLog.transports;\n\n  var message = {\n    data: Array.prototype.slice.call(arguments, 2),\n    date: new Date(),\n    level: options.level,\n    scope: options.scope ? options.scope.toJSON() : null,\n    variables: electronLog.variables,\n  };\n\n  runTransports(transports, message, electronLog);\n}\n\nfunction runTransports(transports, message, electronLog) {\n  for (var i in transports) {\n    if (Object.prototype.hasOwnProperty.call(transports, i)) {\n      runTransport(transports[i], message, electronLog);\n    }\n  }\n}\n\nfunction runTransport(transport, message, electronLog) {\n  if (typeof transport !== 'function' || transport.level === false) {\n    return;\n  }\n\n  if (!compareLevels(electronLog.levels, transport.level, message.level)) {\n    return;\n  }\n\n  message = runHooks(electronLog.hooks, transport, message);\n\n  if (message) {\n    transport(message);\n  }\n}\n\nfunction compareLevels(levels, passLevel, checkLevel) {\n  var pass = levels.indexOf(passLevel);\n  var check = levels.indexOf(checkLevel);\n  if (check === -1 || pass === -1) {\n    return true;\n  }\n\n  return check <= pass;\n}\n\nfunction runHooks(hooks, transport, message) {\n  if (!hooks || !hooks.length) {\n    return message;\n  }\n\n  // eslint-disable-next-line no-plusplus\n  for (var i = 0; i < hooks.length; i++) {\n    message = hooks[i](message, transport);\n    if (!message) break;\n  }\n\n  return message;\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/log.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/scope.js":
/*!************************************************!*\
  !*** ./node_modules/electron-log/src/scope.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar log = __webpack_require__(/*! ./log */ \"./node_modules/electron-log/src/log.js\").log;\n\nmodule.exports = scopeFactory;\n\n/**\n * @param {ElectronLog.ElectronLog} electronLog\n * @return {ElectronLog.Scope}\n */\nfunction scopeFactory(electronLog) {\n  scope.labelPadding = true;\n  scope.defaultLabel = '';\n\n  /** @private */\n  scope.maxLabelLength = 0;\n\n  /**\n   * @type {typeof getOptions}\n   * @package\n   */\n  scope.getOptions = getOptions;\n\n  return scope;\n\n  function scope(label) {\n    var instance = {\n      label: label,\n      toJSON: function () {\n        return {\n          label: this.label,\n        };\n      },\n    };\n\n    electronLog.levels.forEach(function (level) {\n      instance[level] = log.bind(null, electronLog, {\n        level: level,\n        scope: instance,\n      });\n    });\n\n    instance.log = instance.info;\n\n    scope.maxLabelLength = Math.max(scope.maxLabelLength, label.length);\n\n    return instance;\n  }\n\n  function getOptions() {\n    return {\n      defaultLabel: scope.defaultLabel,\n      labelLength: getLabelLength(),\n    };\n  }\n\n  function getLabelLength() {\n    if (scope.labelPadding === true) {\n      return scope.maxLabelLength;\n    }\n\n    if (scope.labelPadding === false) {\n      return 0;\n    }\n\n    if (typeof scope.labelPadding === 'number') {\n      return scope.labelPadding;\n    }\n\n    return 0;\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/scope.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/index.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar object = __webpack_require__(/*! ./object */ \"./node_modules/electron-log/src/transform/object.js\");\nvar style = __webpack_require__(/*! ./style */ \"./node_modules/electron-log/src/transform/style.js\");\nvar template = __webpack_require__(/*! ./template */ \"./node_modules/electron-log/src/transform/template.js\");\n\nmodule.exports = {\n  applyAnsiStyles: style.applyAnsiStyles,\n  concatFirstStringElements: template.concatFirstStringElements,\n  customFormatterFactory: customFormatterFactory,\n  maxDepthFactory: object.maxDepthFactory,\n  removeStyles: style.removeStyles,\n  toJSON: object.toJSON,\n  toString: object.toString,\n  transform: transform,\n};\n\nfunction customFormatterFactory(customFormat, concatFirst, scopeOptions) {\n  if (typeof customFormat === 'string') {\n    return function customStringFormatter(data, message) {\n      return transform(message, [\n        template.templateVariables,\n        template.templateScopeFactory(scopeOptions),\n        template.templateDate,\n        template.templateText,\n        concatFirst && template.concatFirstStringElements,\n      ], [customFormat].concat(data));\n    };\n  }\n\n  if (typeof customFormat === 'function') {\n    return function customFunctionFormatter(data, message) {\n      var modifiedMessage = Object.assign({}, message, { data: data });\n      var texts = customFormat(modifiedMessage, data);\n      return [].concat(texts);\n    };\n  }\n\n  return function (data) {\n    return [].concat(data);\n  };\n}\n\nfunction transform(message, transformers, initialData) {\n  return transformers.reduce(function (data, transformer) {\n    if (typeof transformer === 'function') {\n      return transformer(data, message);\n    }\n\n    return data;\n  }, initialData || message.data);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transform/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/object.js":
/*!***********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/object.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = {\n  maxDepthFactory: maxDepthFactory,\n  serialize: serialize,\n  toJSON: toJSON,\n  toString: toString,\n};\n\nfunction createSerializer() {\n  var seen = createWeakSet();\n\n  return function (key, value) {\n    if (typeof value === 'object' && value !== null) {\n      if (seen.has(value)) {\n        return undefined;\n      }\n\n      seen.add(value);\n    }\n\n    return serialize(key, value);\n  };\n}\n\n/**\n * @return {WeakSet<object>}\n */\nfunction createWeakSet() {\n  if (typeof WeakSet !== 'undefined') {\n    return new WeakSet();\n  }\n\n  var cache = [];\n  this.add = function (value) { cache.push(value) };\n  this.has = function (value) { return cache.indexOf(value) !== -1 };\n\n  return this;\n}\n\nfunction maxDepth(data, depth) {\n  if (!data) {\n    return data;\n  }\n\n  if (depth < 1) {\n    if (data.map) return '[array]';\n    if (typeof data === 'object') return '[object]';\n\n    return data;\n  }\n\n  if (typeof data.map === 'function') {\n    return data.map(function (child) {\n      return maxDepth(child, depth - 1);\n    });\n  }\n\n  if (typeof data !== 'object') {\n    return data;\n  }\n\n  if (data && typeof data.toISOString === 'function') {\n    return data;\n  }\n\n  // noinspection PointlessBooleanExpressionJS\n  if (data === null) {\n    return null;\n  }\n\n  if (data instanceof Error) {\n    return data;\n  }\n\n  var newJson = {};\n  for (var i in data) {\n    if (!Object.prototype.hasOwnProperty.call(data, i)) continue;\n    newJson[i] = maxDepth(data[i], depth - 1);\n  }\n\n  return newJson;\n}\n\nfunction maxDepthFactory(depth) {\n  depth = depth || 6;\n\n  return function maxDepthFunction(data) {\n    return maxDepth(data, depth);\n  };\n}\n\nfunction serialize(key, value) {\n  if (value instanceof Error) {\n    var object = Object.assign(\n      {\n        constructor: (value.constructor && value.constructor.name) || 'Error',\n      },\n      value,\n      { stack: value.stack }\n    );\n\n    if (!object.stack) {\n      object.message = value.message;\n    }\n\n    if (value.constructor && value.constructor.name) {\n      object.constructor = value.constructor.name;\n    }\n\n    return object;\n  }\n\n  if (!value) {\n    return value;\n  }\n\n  if (typeof value.toJSON === 'function') {\n    return value.toJSON();\n  }\n\n  if (typeof value === 'function') {\n    return '[function] ' + value.toString();\n  }\n\n  return value;\n}\n\nfunction toJSON(data) {\n  return JSON.parse(JSON.stringify(data, createSerializer()));\n}\n\nfunction toString(data) {\n  var simplifiedData = data.map(function (item) {\n    if (item === undefined) {\n      return undefined;\n    }\n\n    return JSON.parse(JSON.stringify(item, createSerializer(), '  '));\n  });\n\n  return util.format.apply(util, simplifiedData);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transform/object.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/style.js":
/*!**********************************************************!*\
  !*** ./node_modules/electron-log/src/transform/style.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = {\n  applyAnsiStyles: applyAnsiStyles,\n  removeStyles: removeStyles,\n  transformStyles: transformStyles,\n};\n\nvar ANSI_COLORS = {\n  unset: '\\x1b[0m',\n  black: '\\x1b[30m',\n  red: '\\x1b[31m',\n  green: '\\x1b[32m',\n  yellow: '\\x1b[33m',\n  blue: '\\x1b[34m',\n  magenta: '\\x1b[35m',\n  cyan: '\\x1b[36m',\n  white: '\\x1b[37m',\n};\n\nfunction applyAnsiStyles(data) {\n  return transformStyles(data, styleToAnsi, resetAnsiStyle);\n}\n\nfunction styleToAnsi(style) {\n  var color = style.replace(/color:\\s*(\\w+).*/, '$1').toLowerCase();\n  return ANSI_COLORS[color] || '';\n}\n\nfunction resetAnsiStyle(string) {\n  return string + ANSI_COLORS.unset;\n}\n\nfunction removeStyles(data) {\n  return transformStyles(data, function () { return '' });\n}\n\nfunction transformStyles(data, onStyleFound, onStyleApplied) {\n  var foundStyles = {};\n\n  return data.reduce(function (result, item, index, array) {\n    if (foundStyles[index]) {\n      return result;\n    }\n\n    if (typeof item === 'string') {\n      var valueIndex = index;\n      var styleApplied = false;\n\n      item = item.replace(/%[1cdfiOos]/g, function (match) {\n        valueIndex += 1;\n\n        if (match !== '%c') {\n          return match;\n        }\n\n        var style = array[valueIndex];\n        if (typeof style === 'string') {\n          foundStyles[valueIndex] = true;\n          styleApplied = true;\n          return onStyleFound(style, item);\n        }\n\n        return match;\n      });\n\n      if (styleApplied && onStyleApplied) {\n        item = onStyleApplied(item);\n      }\n    }\n\n    result.push(item);\n    return result;\n  }, []);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transform/style.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transform/template.js":
/*!*************************************************************!*\
  !*** ./node_modules/electron-log/src/transform/template.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = {\n  concatFirstStringElements: concatFirstStringElements,\n  formatDate: formatDate,\n  formatTimeZone: formatTimeZone,\n  pad: pad,\n  padString: padString,\n  templateDate: templateDate,\n  templateVariables: templateVariables,\n  templateScopeFactory: templateScopeFactory,\n  templateText: templateText,\n};\n\n/**\n * The first argument of console.log may contain templates. In the library\n * the first element is a string related to transports.console.format. So\n * this function concatenates first two elements to make templates like %d\n * work\n * @param {*[]} data\n * @return {*[]}\n */\nfunction concatFirstStringElements(data) {\n  if (typeof data[0] !== 'string' || typeof data[1] !== 'string') {\n    return data;\n  }\n\n  if (data[0].match(/%[1cdfiOos]/)) {\n    return data;\n  }\n\n  data[1] = data[0] + ' ' + data[1];\n  data.shift();\n\n  return data;\n}\n\nfunction formatDate(template, date) {\n  return template\n    .replace('{y}', String(date.getFullYear()))\n    .replace('{m}', pad(date.getMonth() + 1))\n    .replace('{d}', pad(date.getDate()))\n    .replace('{h}', pad(date.getHours()))\n    .replace('{i}', pad(date.getMinutes()))\n    .replace('{s}', pad(date.getSeconds()))\n    .replace('{ms}', pad(date.getMilliseconds(), 3))\n    .replace('{z}', formatTimeZone(date.getTimezoneOffset()))\n    .replace('{iso}', date.toISOString());\n}\n\nfunction formatTimeZone(minutesOffset) {\n  var m = Math.abs(minutesOffset);\n  return (minutesOffset >= 0 ? '-' : '+')\n    + pad(Math.floor(m / 60)) + ':'\n    + pad(m % 60);\n}\n\nfunction pad(number, zeros) {\n  zeros = zeros || 2;\n  return (new Array(zeros + 1).join('0') + number).substr(-zeros, zeros);\n}\n\nfunction padString(value, length) {\n  length = Math.max(length, value.length);\n  var padValue = Array(length + 1).join(' ');\n  return (value + padValue).substring(0, length);\n}\n\nfunction templateDate(data, message) {\n  var template = data[0];\n  if (typeof template !== 'string') {\n    return data;\n  }\n\n  data[0] = formatDate(template, message.date);\n  return data;\n}\n\n/**\n * @param {{ labelLength: number, defaultLabel: string }} options\n */\nfunction templateScopeFactory(options) {\n  options = options || {};\n  var labelLength = options.labelLength || 0;\n\n  return function templateScope(data, message) {\n    var template = data[0];\n    var label = message.scope && message.scope.label;\n\n    if (!label) {\n      label = options.defaultLabel;\n    }\n\n    var scopeText;\n    if (label === '') {\n      scopeText = labelLength > 0 ? padString('', labelLength + 3) : '';\n    } else if (typeof label === 'string') {\n      scopeText = padString(' (' + label + ')', labelLength + 3);\n    } else {\n      scopeText = '';\n    }\n\n    data[0] = template.replace('{scope}', scopeText);\n    return data;\n  };\n}\n\nfunction templateVariables(data, message) {\n  var template = data[0];\n  var variables = message.variables;\n\n  if (typeof template !== 'string' || !message.variables) {\n    return data;\n  }\n\n  for (var i in variables) {\n    if (!Object.prototype.hasOwnProperty.call(variables, i)) continue;\n    template = template.replace('{' + i + '}', variables[i]);\n  }\n\n  template = template.replace('{level}', message.level);\n\n  data[0] = template;\n  return data;\n}\n\nfunction templateText(data) {\n  var template = data[0];\n  if (typeof template !== 'string') {\n    return data;\n  }\n\n  var textTplPosition = template.lastIndexOf('{text}');\n  if (textTplPosition === template.length - 6) {\n    data[0] = template.replace(/\\s?{text}/, '');\n    if (data[0] === '') {\n      data.shift();\n    }\n\n    return data;\n  }\n\n  var templatePieces = template.split('{text}');\n  var result = [];\n\n  if (templatePieces[0] !== '') {\n    result.push(templatePieces[0]);\n  }\n\n  result = result.concat(data.slice(1));\n\n  if (templatePieces[1] !== '') {\n    result.push(templatePieces[1]);\n  }\n\n  return result;\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transform/template.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/console.js":
/*!*************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/console.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/* eslint-disable no-multi-spaces, no-console */\n\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\n\nvar original = {\n  context: console,\n  error:   console.error,\n  warn:    console.warn,\n  info:    console.info,\n  verbose: console.verbose,\n  debug:   console.debug,\n  silly:   console.silly,\n  log:     console.log,\n};\n\nmodule.exports = consoleTransportFactory;\nmodule.exports.transformRenderer = transformRenderer;\nmodule.exports.transformMain = transformMain;\n\nvar separator = process.platform === 'win32' ? '>' : '›';\nvar DEFAULT_FORMAT = {\n  browser: '%c{h}:{i}:{s}.{ms}{scope}%c ' + separator + ' {text}',\n  renderer: '{h}:{i}:{s}.{ms}{scope} › {text}',\n  worker: '{h}:{i}:{s}.{ms}{scope} › {text}',\n};\n\nfunction consoleTransportFactory(electronLog) {\n  transport.level  = 'silly';\n  transport.useStyles = process.env.FORCE_STYLES;\n  transport.format = DEFAULT_FORMAT[process.type] || DEFAULT_FORMAT.browser;\n\n  return transport;\n\n  function transport(message) {\n    var scopeOptions = electronLog.scope.getOptions();\n\n    var data;\n    if (process.type === 'renderer' || process.type === 'worker') {\n      data = transformRenderer(message, transport, scopeOptions);\n    } else {\n      data = transformMain(message, transport, scopeOptions);\n    }\n\n    consoleLog(message.level, data);\n  }\n}\n\nfunction transformRenderer(message, transport, scopeOptions) {\n  return transform.transform(message, [\n    transform.customFormatterFactory(transport.format, true, scopeOptions),\n  ]);\n}\n\nfunction transformMain(message, transport, scopeOptions) {\n  var useStyles = canUseStyles(transport.useStyles, message.level);\n\n  return transform.transform(message, [\n    addTemplateColorFactory(transport.format),\n    transform.customFormatterFactory(transport.format, false, scopeOptions),\n    useStyles ? transform.applyAnsiStyles : transform.removeStyles,\n    transform.concatFirstStringElements,\n    transform.maxDepthFactory(4),\n    transform.toJSON,\n  ]);\n}\n\nfunction addTemplateColorFactory(format) {\n  return function addTemplateColors(data, message) {\n    if (format !== DEFAULT_FORMAT.browser) {\n      return data;\n    }\n\n    return ['color:' + levelToStyle(message.level), 'color:unset'].concat(data);\n  };\n}\n\nfunction canUseStyles(useStyleValue, level) {\n  if (useStyleValue === true || useStyleValue === false) {\n    return useStyleValue;\n  }\n\n  var useStderr = level === 'error' || level === 'warn';\n  var stream = useStderr ? process.stderr : process.stdout;\n  return stream && stream.isTTY;\n}\n\nfunction consoleLog(level, args) {\n  if (original[level]) {\n    original[level].apply(original.context, args);\n  } else {\n    original.log.apply(original.context, args);\n  }\n}\n\nfunction levelToStyle(level) {\n  switch (level) {\n    case 'error': return 'red';\n    case 'warn':  return 'yellow';\n    case 'info':  return 'cyan';\n    default:      return 'unset';\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/console.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/file.js":
/*!***************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/file.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar EventEmitter = __webpack_require__(/*! events */ \"events\");\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar os = __webpack_require__(/*! os */ \"os\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar util = __webpack_require__(/*! util */ \"util\");\n\nmodule.exports = {\n  File: File,\n  FileRegistry: FileRegistry,\n  NullFile: NullFile,\n};\n\n/**\n * File manipulations on filesystem\n * @class\n * @extends EventEmitter\n * @property {number} size\n *\n * @constructor\n * @param {string} filePath\n * @param {WriteOptions} [writeOptions]\n * @param {boolean} [writeAsync]\n */\nfunction File(filePath, writeOptions, writeAsync) {\n  EventEmitter.call(this);\n\n  /**\n   * @type {string}\n   * @readonly\n   */\n  this.path = filePath;\n\n  /**\n   * @type {number}\n   * @private\n   */\n  this.initialSize = undefined;\n\n  /**\n   * @type {number}\n   * @readonly\n   */\n  this.bytesWritten = 0;\n\n  /**\n   * @type {boolean}\n   * @private\n   */\n  this.writeAsync = Boolean(writeAsync);\n\n  /**\n   * @type {string[]}\n   * @private\n   */\n  this.asyncWriteQueue = [];\n\n  /**\n   * @type {WriteOptions}\n   * @private\n   */\n  this.writeOptions = writeOptions || {\n    flag: 'a',\n    mode: 438, // 0666\n    encoding: 'utf8',\n  };\n\n  Object.defineProperty(this, 'size', {\n    get: this.getSize.bind(this),\n  });\n}\n\nutil.inherits(File, EventEmitter);\n\nFile.prototype.clear = function () {\n  try {\n    fs.writeFileSync(this.path, '', {\n      mode: this.writeOptions.mode,\n      flag: 'w',\n    });\n    this.reset();\n    return true;\n  } catch (e) {\n    if (e.code === 'ENOENT') {\n      return true;\n    }\n\n    this.emit('error', e, this);\n    return false;\n  }\n};\n\nFile.prototype.crop = function (bytesAfter) {\n  try {\n    var content = readFileSyncFromEnd(this.path, bytesAfter || 4096);\n    this.clear();\n    this.writeLine('[log cropped]' + os.EOL + content);\n  } catch (e) {\n    this.emit(\n      'error',\n      new Error('Couldn\\'t crop file ' + this.path + '. ' + e.message),\n      this\n    );\n  }\n};\n\nFile.prototype.toString = function () {\n  return this.path;\n};\n\n/**\n * @package\n */\nFile.prototype.reset = function () {\n  this.initialSize = undefined;\n  this.bytesWritten = 0;\n};\n\n/**\n * @package\n */\nFile.prototype.writeLine = function (text) {\n  text += os.EOL;\n\n  if (this.writeAsync) {\n    this.asyncWriteQueue.push(text);\n    this.nextAsyncWrite();\n    return;\n  }\n\n  try {\n    fs.writeFileSync(this.path, text, this.writeOptions);\n    this.increaseBytesWrittenCounter(text);\n  } catch (e) {\n    this.emit(\n      'error',\n      new Error('Couldn\\'t write to ' + this.path + '. ' + e.message),\n      this\n    );\n  }\n};\n\n/**\n * @return {number}\n * @protected\n */\nFile.prototype.getSize = function () {\n  if (this.initialSize === undefined) {\n    try {\n      var stats = fs.statSync(this.path);\n      this.initialSize = stats.size;\n    } catch (e) {\n      this.initialSize = 0;\n    }\n  }\n\n  return this.initialSize + this.bytesWritten;\n};\n\n/**\n * @return {boolean}\n * @package\n */\nFile.prototype.isNull = function () {\n  return false;\n};\n\n/**\n * @private\n */\nFile.prototype.increaseBytesWrittenCounter = function (text) {\n  this.bytesWritten += Buffer.byteLength(text, this.writeOptions.encoding);\n};\n\n/**\n * @private\n */\nFile.prototype.nextAsyncWrite = function () {\n  var file = this;\n\n  if (this.asyncWriteQueue.length < 1) {\n    return;\n  }\n\n  var text = this.asyncWriteQueue.shift();\n\n  fs.writeFile(this.path, text, this.writeOptions, function (e) {\n    if (e) {\n      file.emit(\n        'error',\n        new Error('Couldn\\'t write to ' + file.path + '. ' + e.message),\n        this\n      );\n    } else {\n      file.increaseBytesWrittenCounter(text);\n    }\n\n    file.nextAsyncWrite();\n  });\n};\n\n/**\n * File manipulations on filesystem\n * @class\n * @property {number} size\n *\n * @constructor\n * @param {string} filePath\n */\nfunction NullFile(filePath) {\n  File.call(this, filePath);\n}\n\nutil.inherits(NullFile, File);\n\nNullFile.prototype.clear = function () {};\nNullFile.prototype.crop = function () {};\nNullFile.prototype.writeLine = function () {};\nNullFile.prototype.getSize = function () { return 0 };\nNullFile.prototype.isNull = function () { return true };\n\n/**\n * Collection, key is a file path, value is a File instance\n * @class\n *\n * @constructor\n */\nfunction FileRegistry() {\n  EventEmitter.call(this);\n  this.store = {};\n\n  this.emitError = this.emitError.bind(this);\n}\n\nutil.inherits(FileRegistry, EventEmitter);\n\n/**\n * Provide a File object corresponding to the filePath\n * @param {string} filePath\n * @param {WriteOptions} [writeOptions]\n * @param {boolean} [async]\n * @return {File}\n */\nFileRegistry.prototype.provide = function (filePath, writeOptions, async) {\n  var file;\n  try {\n    filePath = path.resolve(filePath);\n\n    if (this.store[filePath]) {\n      return this.store[filePath];\n    }\n\n    file = this.createFile(filePath, writeOptions, Boolean(async));\n  } catch (e) {\n    file = new NullFile(filePath);\n    this.emitError(e, file);\n  }\n\n  file.on('error', this.emitError);\n  this.store[filePath] = file;\n  return file;\n};\n\n/**\n * @param {string} filePath\n * @param {WriteOptions} writeOptions\n * @param {boolean} async\n * @return {File}\n * @private\n */\nFileRegistry.prototype.createFile = function (filePath, writeOptions, async) {\n  this.testFileWriting(filePath);\n  return new File(filePath, writeOptions, async);\n};\n\n/**\n * @param {Error} error\n * @param {File} file\n * @private\n */\nFileRegistry.prototype.emitError = function (error, file) {\n  this.emit('error', error, file);\n};\n\n/**\n * @param {string} filePath\n * @private\n */\nFileRegistry.prototype.testFileWriting = function (filePath) {\n  mkDir(path.dirname(filePath));\n  fs.writeFileSync(filePath, '', { flag: 'a' });\n};\n\nfunction mkDir(dirPath) {\n  if (checkNodeJsVersion(10.12)) {\n    fs.mkdirSync(dirPath, { recursive: true });\n    return true;\n  }\n\n  try {\n    fs.mkdirSync(dirPath);\n    return true;\n  } catch (error) {\n    if (error.code === 'ENOENT') {\n      return mkDir(path.dirname(dirPath)) && mkDir(dirPath);\n    }\n\n    try {\n      if (fs.statSync(dirPath).isDirectory()) {\n        return true;\n      }\n\n      // noinspection ExceptionCaughtLocallyJS\n      throw error;\n    } catch (e) {\n      throw e;\n    }\n  }\n}\n\nfunction checkNodeJsVersion(version) {\n  if (!process.versions) {\n    return false;\n  }\n\n  var nodeVersion = Number(\n    process.version.match(/^v(\\d+\\.\\d+)/)[1].replace(/\\.(\\d)$/, '.0$1')\n  );\n\n  return nodeVersion >= version;\n}\n\nfunction readFileSyncFromEnd(filePath, bytesCount) {\n  var buffer = Buffer.alloc(bytesCount);\n  var stats = fs.statSync(filePath);\n\n  var readLength = Math.min(stats.size, bytesCount);\n  var offset = Math.max(0, stats.size - bytesCount);\n\n  var fd = fs.openSync(filePath, 'r');\n  var totalBytes = fs.readSync(fd, buffer, 0, readLength, offset);\n  fs.closeSync(fd);\n\n  return buffer.toString('utf8', 0, totalBytes);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/file/file.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/index.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar util = __webpack_require__(/*! util */ \"util\");\nvar transform = __webpack_require__(/*! ../../transform */ \"./node_modules/electron-log/src/transform/index.js\");\nvar FileRegistry = __webpack_require__(/*! ./file */ \"./node_modules/electron-log/src/transports/file/file.js\").FileRegistry;\nvar variables = __webpack_require__(/*! ./variables */ \"./node_modules/electron-log/src/transports/file/variables.js\");\n\nmodule.exports = fileTransportFactory;\n\n// Shared between multiple file transport instances\nvar globalRegistry = new FileRegistry();\n\nfunction fileTransportFactory(electronLog, customRegistry) {\n  var pathVariables = variables.getPathVariables(process.platform);\n\n  var registry = customRegistry || globalRegistry;\n  registry.on('error', function (e, file) {\n    logConsole('Can\\'t write to ' + file, e);\n  });\n\n  /* eslint-disable no-multi-spaces */\n  transport.archiveLog   = archiveLog;\n  transport.fileName     = getDefaultFileName();\n  transport\n    .format = '[{y}-{m}-{d} {h}:{i}:{s}.{ms}] [{level}]{scope} {text}';\n  transport.getFile      = getFile;\n  transport.level        = 'silly';\n  transport.maxSize      = 1024 * 1024;\n  transport.resolvePath  = resolvePath;\n  transport.sync         = true;\n  transport.writeOptions = {\n    flag: 'a',\n    mode: 438, // 0666\n    encoding: 'utf8',\n  };\n\n  initDeprecated();\n\n  return transport;\n\n  function transport(message) {\n    var file = getFile(message);\n\n    var needLogRotation = transport.maxSize > 0\n      && file.size > transport.maxSize;\n\n    if (needLogRotation) {\n      transport.archiveLog(file);\n      file.reset();\n    }\n\n    var scopeOptions = electronLog.scope.getOptions();\n    var content = transform.transform(message, [\n      transform.removeStyles,\n      transform.customFormatterFactory(transport.format, false, scopeOptions),\n      transform.concatFirstStringElements,\n      transform.maxDepthFactory(),\n      transform.toString,\n    ]);\n\n    file.writeLine(content);\n  }\n\n  function archiveLog(file) {\n    var oldPath = file.toString();\n    var inf = path.parse(oldPath);\n    try {\n      fs.renameSync(oldPath, path.join(inf.dir, inf.name + '.old' + inf.ext));\n    } catch (e) {\n      logConsole('Could not rotate log', e);\n      var quarterOfMaxSize = Math.round(transport.maxSize / 4);\n      file.crop(Math.min(quarterOfMaxSize, 256 * 1024));\n    }\n  }\n\n  function logConsole(message, error) {\n    var data = ['electron-log.transports.file: ' + message];\n\n    if (error) {\n      data.push(error);\n    }\n\n    electronLog.transports.console({\n      data: data,\n      date: new Date(),\n      level: 'warn',\n    });\n  }\n\n  function getFile(msg) {\n    var vars = Object.assign({}, pathVariables, {\n      fileName: transport.fileName,\n    });\n\n    var filePath = transport.resolvePath(vars, msg);\n    return registry.provide(filePath, transport.writeOptions, !transport.sync);\n  }\n\n  /**\n   * @param {PathVariables} vars\n   */\n  function resolvePath(vars) {\n    return path.join(vars.libraryDefaultDir, vars.fileName);\n  }\n\n  function initDeprecated() {\n    var isDeprecatedText = ' is deprecated and will be removed in v5.';\n    var isDeprecatedProp = ' property' + isDeprecatedText;\n\n    Object.defineProperties(transport, {\n      bytesWritten: {\n        get: util.deprecate(getBytesWritten, 'bytesWritten' + isDeprecatedProp),\n      },\n\n      file: {\n        get: util.deprecate(getLogFile, 'file' + isDeprecatedProp),\n        set: util.deprecate(setLogFile, 'file' + isDeprecatedProp),\n      },\n\n      fileSize: {\n        get: util.deprecate(getFileSize, 'file' + isDeprecatedProp),\n      },\n    });\n\n    transport.clear = util.deprecate(clear, 'clear()' + isDeprecatedText);\n    transport.findLogPath = util.deprecate(\n      getLogFile,\n      'findLogPath()' + isDeprecatedText\n    );\n    transport.init = util.deprecate(init, 'init()' + isDeprecatedText);\n\n    function getBytesWritten() {\n      return getFile().bytesWritten;\n    }\n\n    function getLogFile() {\n      return getFile().path;\n    }\n\n    function setLogFile(filePath) {\n      transport.resolvePath = function () {\n        return filePath;\n      };\n    }\n\n    function getFileSize() {\n      return getFile().size;\n    }\n\n    function clear() {\n      getFile().clear();\n    }\n\n    function init() {}\n  }\n}\n\nfunction getDefaultFileName() {\n  switch (process.type) {\n    case 'renderer': return 'renderer.log';\n    case 'worker': return 'worker.log';\n    default: return 'main.log';\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/file/index.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/packageJson.js":
/*!**********************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/packageJson.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/* eslint-disable consistent-return */\n\nvar fs = __webpack_require__(/*! fs */ \"fs\");\nvar path = __webpack_require__(/*! path */ \"path\");\n\nmodule.exports = {\n  readPackageJson: readPackageJson,\n  tryReadJsonAt: tryReadJsonAt,\n};\n\n/**\n * @return {{ name?: string, version?: string}}\n */\nfunction readPackageJson() {\n  return tryReadJsonAt(__webpack_require__.c[__webpack_require__.s] && __webpack_require__.c[__webpack_require__.s].filename)\n    || tryReadJsonAt(process.resourcesPath, 'app.asar')\n    || tryReadJsonAt(process.cwd())\n    || { name: null, version: null };\n}\n\n/**\n * @param {...string} searchPath\n * @return {{ name?: string, version?: string } | null}\n */\nfunction tryReadJsonAt(searchPath) {\n  try {\n    searchPath = path.join.apply(path, arguments);\n    var fileName = findUp('package.json', searchPath);\n    if (!fileName) {\n      return null;\n    }\n\n    var json = JSON.parse(fs.readFileSync(fileName, 'utf8'));\n    var name = json.productName || json.name;\n    if (!name || name.toLowerCase() === 'electron') {\n      return null;\n    }\n\n    if (json.productName || json.name) {\n      return {\n        name: name,\n        version: json.version,\n      };\n    }\n  } catch (e) {\n    return null;\n  }\n}\n\n/**\n * @param {string} fileName\n * @param {string} [cwd]\n * @return {string | null}\n */\nfunction findUp(fileName, cwd) {\n  var currentPath = cwd;\n  // eslint-disable-next-line no-constant-condition\n  while (true) {\n    var parsedPath = path.parse(currentPath);\n    var root = parsedPath.root;\n    var dir = parsedPath.dir;\n\n    if (fs.existsSync(path.join(currentPath, fileName))) {\n      return path.resolve(path.join(currentPath, fileName));\n    }\n\n    if (currentPath === root) {\n      return null;\n    }\n\n    currentPath = dir;\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/file/packageJson.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/file/variables.js":
/*!********************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/file/variables.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar os = __webpack_require__(/*! os */ \"os\");\nvar path = __webpack_require__(/*! path */ \"path\");\nvar electronApi = __webpack_require__(/*! ../../electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar packageJson = __webpack_require__(/*! ./packageJson */ \"./node_modules/electron-log/src/transports/file/packageJson.js\");\n\nmodule.exports = {\n  getAppData: getAppData,\n  getLibraryDefaultDir: getLibraryDefaultDir,\n  getLibraryTemplate: getLibraryTemplate,\n  getNameAndVersion: getNameAndVersion,\n  getPathVariables: getPathVariables,\n  getUserData: getUserData,\n};\n\nfunction getAppData(platform) {\n  var appData = electronApi.getPath('appData');\n  if (appData) {\n    return appData;\n  }\n\n  var home = getHome();\n\n  switch (platform) {\n    case 'darwin': {\n      return path.join(home, 'Library/Application Support');\n    }\n\n    case 'win32': {\n      return process.env.APPDATA || path.join(home, 'AppData/Roaming');\n    }\n\n    default: {\n      return process.env.XDG_CONFIG_HOME || path.join(home, '.config');\n    }\n  }\n}\n\nfunction getHome() {\n  return os.homedir ? os.homedir() : process.env.HOME;\n}\n\nfunction getLibraryDefaultDir(platform, appName) {\n  if (platform === 'darwin') {\n    return path.join(getHome(), 'Library/Logs', appName);\n  }\n\n  return path.join(getUserData(platform, appName), 'logs');\n}\n\nfunction getLibraryTemplate(platform) {\n  if (platform === 'darwin') {\n    return path.join(getHome(), 'Library/Logs', '{appName}');\n  }\n\n  return path.join(getAppData(platform), '{appName}', 'logs');\n}\n\nfunction getNameAndVersion() {\n  var name = electronApi.getName();\n  var version = electronApi.getVersion();\n\n  if (name && version) {\n    return { name: name, version: version };\n  }\n\n  var packageValues = packageJson.readPackageJson();\n  if (!name) {\n    name = packageValues.name;\n  }\n\n  if (!version) {\n    version = packageValues.version;\n  }\n\n  return { name: name, version: version };\n}\n\n/**\n * @param {string} platform\n * @return {PathVariables}\n */\nfunction getPathVariables(platform) {\n  var nameAndVersion = getNameAndVersion();\n  var appName = nameAndVersion.name;\n  var appVersion = nameAndVersion.version;\n\n  return {\n    appData: getAppData(platform),\n    appName: appName,\n    appVersion: appVersion,\n    electronDefaultDir: electronApi.getPath('logs'),\n    home: getHome(),\n    libraryDefaultDir: getLibraryDefaultDir(platform, appName),\n    libraryTemplate: getLibraryTemplate(platform),\n    temp: electronApi.getPath('temp') || os.tmpdir(),\n    userData: getUserData(platform, appName),\n  };\n}\n\nfunction getUserData(platform, appName) {\n  return electronApi.getPath('userData')\n    || path.join(getAppData(platform), appName);\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/file/variables.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/ipc.js":
/*!*********************************************************!*\
  !*** ./node_modules/electron-log/src/transports/ipc.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\nvar electronApi = __webpack_require__(/*! ../electronApi */ \"./node_modules/electron-log/src/electronApi.js\");\nvar log = __webpack_require__(/*! ../log.js */ \"./node_modules/electron-log/src/log.js\");\n\nmodule.exports = ipcTransportFactory;\n\nfunction ipcTransportFactory(electronLog) {\n  transport.eventId = '__ELECTRON_LOG_IPC_' + electronLog.logId + '__';\n  transport.level = electronLog.isDev ? 'silly' : false;\n\n  // Prevent problems when there are multiple instances after webpack\n  if (electronApi.isIpcChannelListened(transport.eventId)) {\n    return function () {};\n  }\n\n  electronApi.onIpc(transport.eventId, function (_, message) {\n    message.date = new Date(message.date);\n\n    log.runTransport(\n      electronLog.transports.console,\n      message,\n      electronLog\n    );\n  });\n\n  electronApi.loadRemoteModule('electron-log');\n\n  return electronApi.isElectron() ? transport : null;\n\n  function transport(message) {\n    var ipcMessage = Object.assign({}, message, {\n      data: transform.transform(message, [\n        transform.removeStyles,\n        transform.toJSON,\n        transform.maxDepthFactory(3),\n      ]),\n    });\n\n    electronApi.sendIpc(transport.eventId, ipcMessage);\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/ipc.js?");

/***/ }),

/***/ "./node_modules/electron-log/src/transports/remote.js":
/*!************************************************************!*\
  !*** ./node_modules/electron-log/src/transports/remote.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar http = __webpack_require__(/*! http */ \"http\");\nvar https = __webpack_require__(/*! https */ \"https\");\nvar url = __webpack_require__(/*! url */ \"url\");\nvar log = __webpack_require__(/*! ../log */ \"./node_modules/electron-log/src/log.js\");\nvar transform = __webpack_require__(/*! ../transform */ \"./node_modules/electron-log/src/transform/index.js\");\n\nmodule.exports = remoteTransportFactory;\n\nfunction remoteTransportFactory(electronLog) {\n  transport.client = { name: 'electron-application' };\n  transport.depth = 6;\n  transport.level = false;\n  transport.requestOptions = {};\n  transport.url = null;\n\n  return transport;\n\n  function transport(message) {\n    if (!transport.url) return;\n\n    var request = post(transport.url, transport.requestOptions, {\n      client: transport.client,\n      data: transform.transform(message, [\n        transform.removeStyles,\n        transform.toJSON,\n        transform.maxDepthFactory(transport.depth + 1),\n      ]),\n      date: message.date.getTime(),\n      level: message.level,\n      variables: message.variables,\n    });\n\n    request.on('error', function (error) {\n      var errorMessage = {\n        data: [\n          'electron-log.transports.remote:'\n          + ' cannot send HTTP request to ' + transport.url,\n          error,\n        ],\n        date: new Date(),\n        level: 'warn',\n      };\n\n      var transports = [\n        electronLog.transports.console,\n        electronLog.transports.ipc,\n        electronLog.transports.file,\n      ];\n\n      log.runTransports(transports, errorMessage, electronLog);\n    });\n  }\n}\n\nfunction post(serverUrl, requestOptions, data) {\n  var urlObject = url.parse(serverUrl);\n  var httpTransport = urlObject.protocol === 'https:' ? https : http;\n\n  var body = JSON.stringify(data);\n\n  var options = {\n    hostname: urlObject.hostname,\n    port:     urlObject.port,\n    path:     urlObject.path,\n    method:   'POST',\n    headers:  {\n      'Content-Length': body.length,\n      'Content-Type':   'application/json',\n    },\n  };\n\n  Object.assign(options, requestOptions);\n\n  var request = httpTransport.request(options);\n  request.write(body);\n  request.end();\n\n  return request;\n}\n\n\n//# sourceURL=webpack:///./node_modules/electron-log/src/transports/remote.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AudioConfig, AudioStreamFormat, AudioFormatTag, AudioInputStream, PullAudioInputStream, PushAudioInputStream, AudioOutputStream, PullAudioOutputStream, PushAudioOutputStream, CancellationReason, PullAudioInputStreamCallback, PushAudioOutputStreamCallback, KeywordRecognitionModel, SessionEventArgs, RecognitionEventArgs, OutputFormat, IntentRecognitionEventArgs, RecognitionResult, SpeechRecognitionResult, IntentRecognitionResult, LanguageUnderstandingModel, SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs, SpeechRecognitionCanceledEventArgs, TranslationRecognitionEventArgs, TranslationSynthesisEventArgs, TranslationRecognitionResult, TranslationSynthesisResult, ResultReason, SpeechConfig, SpeechConfigImpl, SpeechTranslationConfig, SpeechTranslationConfigImpl, PropertyCollection, PropertyId, Recognizer, SpeechRecognizer, IntentRecognizer, VoiceProfileType, TranslationRecognizer, Translations, NoMatchReason, NoMatchDetails, TranslationRecognitionCanceledEventArgs, IntentRecognitionCanceledEventArgs, CancellationDetailsBase, CancellationDetails, CancellationErrorCode, ConnectionEventArgs, ServiceEventArgs, Connection, PhraseListGrammar, DialogServiceConfig, BotFrameworkConfig, CustomCommandsConfig, DialogServiceConnector, ActivityReceivedEventArgs, TurnStatusReceivedEventArgs, ServicePropertyChannel, ProfanityOption, BaseAudioPlayer, ConnectionMessageEventArgs, ConnectionMessage, VoiceProfile, VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails, VoiceProfileResult, VoiceProfileCancellationDetails, VoiceProfilePhraseResult, VoiceProfileClient, SpeakerRecognizer, SpeakerIdentificationModel, SpeakerVerificationModel, AutoDetectSourceLanguageConfig, AutoDetectSourceLanguageResult, SourceLanguageConfig, SpeakerRecognitionResult, SpeakerRecognitionResultType, SpeakerRecognitionCancellationDetails, Conversation, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, ParticipantChangedReason, User, SpeechSynthesisOutputFormat, SpeechSynthesizer, SynthesisResult, SpeechSynthesisResult, SpeechSynthesisEventArgs, SpeechSynthesisWordBoundaryEventArgs, SpeechSynthesisBookmarkEventArgs, SpeechSynthesisVisemeEventArgs, SpeechSynthesisBoundaryType, SynthesisVoicesResult, VoiceInfo, SpeakerAudioDestination, ConversationTranscriptionCanceledEventArgs, PronunciationAssessmentGradingSystem, PronunciationAssessmentGranularity, PronunciationAssessmentConfig, PronunciationAssessmentResult, LanguageIdMode, LanguageIdPriority, Diagnostics, LogLevel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _src_common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./src/common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./src/sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamFormat\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioStreamFormat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioFormatTag\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioFormatTag\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioInputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioInputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioInputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioInputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioInputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioOutputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioOutputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioOutputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioOutputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStream\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioOutputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationReason\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStreamCallback\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioInputStreamCallback\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStreamCallback\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioOutputStreamCallback\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"KeywordRecognitionModel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"KeywordRecognitionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SessionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SessionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OutputFormat\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"IntentRecognitionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechRecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"IntentRecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageUnderstandingModel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"LanguageUnderstandingModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechRecognitionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranscriptionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionCanceledEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechRecognitionCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationRecognitionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationSynthesisEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationRecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationSynthesisResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ResultReason\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfigImpl\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechConfigImpl\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechTranslationConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfigImpl\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechTranslationConfigImpl\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PropertyCollection\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PropertyId\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Recognizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Recognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechRecognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"IntentRecognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileType\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationRecognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Translations\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Translations\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NoMatchReason\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"NoMatchReason\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NoMatchDetails\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"NoMatchDetails\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionCanceledEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationRecognitionCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionCanceledEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"IntentRecognitionCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetailsBase\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationDetailsBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetails\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationDetails\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationErrorCode\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServiceEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Connection\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Connection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PhraseListGrammar\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PhraseListGrammar\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BotFrameworkConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BotFrameworkConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CustomCommandsConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CustomCommandsConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConnector\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConnector\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ActivityReceivedEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ActivityReceivedEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TurnStatusReceivedEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TurnStatusReceivedEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServicePropertyChannel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServicePropertyChannel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ProfanityOption\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ProfanityOption\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BaseAudioPlayer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BaseAudioPlayer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessage\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessage\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfile\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfile\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentCancellationDetails\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentCancellationDetails\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileCancellationDetails\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileCancellationDetails\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfilePhraseResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfilePhraseResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileClient\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileClient\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerIdentificationModel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerIdentificationModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerVerificationModel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerVerificationModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AutoDetectSourceLanguageConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"AutoDetectSourceLanguageResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SourceLanguageConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SourceLanguageConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResultType\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionResultType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionCancellationDetails\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionCancellationDetails\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Conversation\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Conversation\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationExpirationEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationExpirationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationParticipantsChangedEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationParticipantsChangedEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationCanceledEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranslationCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranslationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranslationResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslator\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranslator\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriber\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranscriber\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Participant\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Participant\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantChangedReason\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ParticipantChangedReason\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"User\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"User\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisOutputFormat\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisOutputFormat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesizer\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisWordBoundaryEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisWordBoundaryEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBookmarkEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisBookmarkEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisVisemeEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisVisemeEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBoundaryType\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisBoundaryType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisVoicesResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisVoicesResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceInfo\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceInfo\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerAudioDestination\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerAudioDestination\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionCanceledEventArgs\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConversationTranscriptionCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGradingSystem\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PronunciationAssessmentGradingSystem\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGranularity\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PronunciationAssessmentGranularity\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentConfig\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PronunciationAssessmentConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentResult\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PronunciationAssessmentResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdMode\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"LanguageIdMode\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdPriority\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"LanguageIdPriority\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Diagnostics\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Diagnostics\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LogLevel\", function() { return _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"LogLevel\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n// Common.Storage.SetLocalStorage(new Common.Browser.LocalStorage());\n// Common.Storage.SetSessionStorage(new Common.Browser.SessionStorage());\n_src_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.attachConsoleListener(new _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConsoleLoggingListener\"]());\n// Speech SDK API\n\n\n//# sourceMappingURL=microsoft.cognitiveservices.speech.sdk.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js ***!
  \*************************************************************************************************************/
/*! exports provided: CertCheckAgent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CertCheckAgent\", function() { return CertCheckAgent; });\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tls */ \"tls\");\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(tls__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../external/ocsp/ocsp */ 1);\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! agent-base */ 2);\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(agent_base__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! async-disk-cache */ 3);\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(async_disk_cache__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! https-proxy-agent */ 4);\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(https_proxy_agent__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! net */ \"net\");\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(net__WEBPACK_IMPORTED_MODULE_6__);\n/* harmony import */ var _common_OCSPEvents__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/OCSPEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js\");\n/* eslint-disable import/order */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-ignore\n\n\n\n\nclass CertCheckAgent {\n    constructor(proxyInfo) {\n        if (!!proxyInfo) {\n            this.privProxyInfo = proxyInfo;\n        }\n        // Initialize this here to allow tests to set the env variable before the cache is constructed.\n        if (!CertCheckAgent.privDiskCache) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-call\n            CertCheckAgent.privDiskCache = new async_disk_cache__WEBPACK_IMPORTED_MODULE_4___default.a(\"microsoft-cognitiveservices-speech-sdk-cache\", { supportBuffer: true, location: (typeof process !== \"undefined\" && !!process.env.SPEECH_OCSP_CACHE_ROOT) ? process.env.SPEECH_OCSP_CACHE_ROOT : undefined });\n        }\n    }\n    // Test hook to force the disk cache to be recreated.\n    static forceReinitDiskCache() {\n        CertCheckAgent.privDiskCache = undefined;\n        CertCheckAgent.privMemCache = {};\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    GetAgent(disableStapling) {\n        // eslint-disable-next-line @typescript-eslint/unbound-method\n        const agent = new agent_base__WEBPACK_IMPORTED_MODULE_3___default.a.Agent(this.CreateConnection);\n        if (this.privProxyInfo !== undefined &&\n            this.privProxyInfo.HostName !== undefined &&\n            this.privProxyInfo.Port > 0) {\n            const proxyName = \"privProxyInfo\";\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n            agent[proxyName] = this.privProxyInfo;\n        }\n        return agent;\n    }\n    static GetProxyAgent(proxyInfo) {\n        const httpProxyOptions = {\n            host: proxyInfo.HostName,\n            port: proxyInfo.Port,\n        };\n        if (!!proxyInfo.UserName) {\n            httpProxyOptions.headers = {\n                \"Proxy-Authentication\": \"Basic \" + new Buffer(`${proxyInfo.UserName}:${(proxyInfo.Password === undefined) ? \"\" : proxyInfo.Password}`).toString(\"base64\"),\n            };\n        }\n        else {\n            httpProxyOptions.headers = {};\n        }\n        httpProxyOptions.headers.requestOCSP = \"true\";\n        const httpProxyAgent = new https_proxy_agent__WEBPACK_IMPORTED_MODULE_5___default.a(httpProxyOptions);\n        return httpProxyAgent;\n    }\n    static OCSPCheck(socketPromise, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ocspRequest;\n            let stapling;\n            let resolved = false;\n            const socket = yield socketPromise;\n            socket.cork();\n            const tlsSocket = socket;\n            return new Promise((resolve, reject) => {\n                socket.on(\"OCSPResponse\", (data) => {\n                    if (!!data) {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPStapleReceivedEvent\"]());\n                        stapling = data;\n                    }\n                });\n                socket.on(\"error\", (error) => {\n                    if (!resolved) {\n                        resolved = true;\n                        socket.destroy();\n                        reject(error);\n                    }\n                });\n                // eslint-disable-next-line @typescript-eslint/no-misused-promises, @typescript-eslint/explicit-function-return-type\n                tlsSocket.on(\"secure\", () => __awaiter(this, void 0, void 0, function* () {\n                    const peer = tlsSocket.getPeerCertificate(true);\n                    try {\n                        const issuer = yield this.GetIssuer(peer);\n                        // We always need a request to verify the response.\n                        ocspRequest = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"request\"].generate(peer.raw, issuer.raw);\n                        // Do we have a result for this certificate in our memory cache?\n                        const sig = ocspRequest.id.toString(\"hex\");\n                        // Stapled response trumps cached response.\n                        if (!stapling) {\n                            const cacheEntry = yield CertCheckAgent.GetResponseFromCache(sig, ocspRequest, proxyInfo);\n                            stapling = cacheEntry;\n                        }\n                        yield this.VerifyOCSPResponse(stapling, ocspRequest, proxyInfo);\n                        socket.uncork();\n                        resolved = true;\n                        resolve(socket);\n                    }\n                    catch (e) {\n                        socket.destroy();\n                        resolved = true;\n                        reject(e);\n                    }\n                }));\n            });\n        });\n    }\n    static GetIssuer(peer) {\n        if (peer.issuerCertificate) {\n            return Promise.resolve(peer.issuerCertificate);\n        }\n        return new Promise((resolve, reject) => {\n            const ocspAgent = new _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"Agent\"]({});\n            ocspAgent.fetchIssuer(peer, null, (error, value) => {\n                if (!!error) {\n                    reject(error);\n                    return;\n                }\n                resolve(value);\n            });\n        });\n    }\n    static GetResponseFromCache(signature, ocspRequest, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let cachedResponse = CertCheckAgent.privMemCache[signature];\n            if (!!cachedResponse) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPMemoryCacheHitEvent\"](signature));\n            }\n            // Do we have a result for this certificate on disk in %TMP%?\n            if (!cachedResponse) {\n                try {\n                    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n                    const diskCacheResponse = yield CertCheckAgent.privDiskCache.get(signature);\n                    if (!!diskCacheResponse.isCached) {\n                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPDiskCacheHitEvent\"](signature));\n                        CertCheckAgent.StoreMemoryCacheEntry(signature, diskCacheResponse.value);\n                        cachedResponse = diskCacheResponse.value;\n                    }\n                }\n                catch (error) {\n                    cachedResponse = null;\n                }\n            }\n            if (!cachedResponse) {\n                return cachedResponse;\n            }\n            try {\n                const cachedOcspResponse = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"utils\"].parseResponse(cachedResponse);\n                const responseValue = cachedOcspResponse.value;\n                const tbsData = responseValue.tbsResponseData;\n                if (tbsData.responses.length < 1) {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheFetchErrorEvent\"](signature, \"Not enough data in cached response\"));\n                    return;\n                }\n                const cachedStartTime = tbsData.responses[0].thisUpdate;\n                const cachedNextTime = tbsData.responses[0].nextUpdate;\n                if (cachedNextTime < (Date.now() + this.testTimeOffset - 60000)) {\n                    // Cached entry has expired.\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheEntryExpiredEvent\"](signature, cachedNextTime));\n                    cachedResponse = null;\n                }\n                else {\n                    // If we're within one day of the next update, or 50% of the way through the validity period,\n                    // background an update to the cache.\n                    const minUpdate = Math.min(24 * 60 * 60 * 1000, (cachedNextTime - cachedStartTime) / 2);\n                    if ((cachedNextTime - (Date.now() + this.testTimeOffset)) < minUpdate) {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheEntryNeedsRefreshEvent\"](signature, cachedStartTime, cachedNextTime));\n                        this.UpdateCache(ocspRequest, proxyInfo).catch((error) => {\n                            // Well, not much we can do here.\n                            this.onEvent(new _common_OCSPEvents__WEBPACK_IMPORTED_MODULE_7__[\"OCSPCacheUpdateErrorEvent\"](signature, error.toString()));\n                        });\n                    }\n                    else {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheHitEvent\"](signature, cachedStartTime, cachedNextTime));\n                    }\n                }\n            }\n            catch (error) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheFetchErrorEvent\"](signature, error));\n                cachedResponse = null;\n            }\n            if (!cachedResponse) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheMissEvent\"](signature));\n            }\n            return cachedResponse;\n        });\n    }\n    static VerifyOCSPResponse(cacheValue, ocspRequest, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ocspResponse = cacheValue;\n            // Do we have a valid response?\n            if (!ocspResponse) {\n                ocspResponse = yield CertCheckAgent.GetOCSPResponse(ocspRequest, proxyInfo);\n            }\n            return new Promise((resolve, reject) => {\n                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"verify\"]({ request: ocspRequest, response: ocspResponse }, (error) => {\n                    if (!!error) {\n                        CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPVerificationFailedEvent\"](ocspRequest.id.toString(\"hex\"), error));\n                        // Bad Cached Value? One more try without the cache.\n                        if (!!cacheValue) {\n                            this.VerifyOCSPResponse(null, ocspRequest, proxyInfo).then(() => {\n                                resolve();\n                            }, (error) => {\n                                reject(error);\n                            });\n                        }\n                        else {\n                            reject(error);\n                        }\n                    }\n                    else {\n                        if (!cacheValue) {\n                            CertCheckAgent.StoreCacheEntry(ocspRequest.id.toString(\"hex\"), ocspResponse);\n                        }\n                        resolve();\n                    }\n                });\n            });\n        });\n    }\n    static UpdateCache(req, proxyInfo) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const signature = req.id.toString(\"hex\");\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheUpdateNeededEvent\"](signature));\n            const rawResponse = yield this.GetOCSPResponse(req, proxyInfo);\n            this.StoreCacheEntry(signature, rawResponse);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPCacheUpdateCompleteEvent\"](req.id.toString(\"hex\")));\n        });\n    }\n    static StoreCacheEntry(sig, rawResponse) {\n        this.StoreMemoryCacheEntry(sig, rawResponse);\n        this.StoreDiskCacheEntry(sig, rawResponse);\n    }\n    static StoreMemoryCacheEntry(sig, rawResponse) {\n        this.privMemCache[sig] = rawResponse;\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPMemoryCacheStoreEvent\"](sig));\n    }\n    static StoreDiskCacheEntry(sig, rawResponse) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n        this.privDiskCache.set(sig, rawResponse).then(() => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPDiskCacheStoreEvent\"](sig));\n        });\n    }\n    static GetOCSPResponse(req, proxyInfo) {\n        const ocspMethod = \"1.3.6.1.5.5.7.48.1\";\n        let options = {};\n        if (!!proxyInfo) {\n            const agent = CertCheckAgent.GetProxyAgent(proxyInfo);\n            options.agent = agent;\n        }\n        return new Promise((resolve, reject) => {\n            _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"utils\"].getAuthorityInfo(req.cert, ocspMethod, (error, uri) => {\n                if (error) {\n                    reject(error);\n                    return;\n                }\n                const url = new URL(uri);\n                options = Object.assign(Object.assign({}, options), { host: url.host, protocol: url.protocol, port: url.port, path: url.pathname, hostname: url.host });\n                _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__[\"utils\"].getResponse(options, req.data, (error, raw) => {\n                    if (error) {\n                        reject(error);\n                        return;\n                    }\n                    const certID = req.certID;\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OCSPResponseRetrievedEvent\"](certID.toString(\"hex\")));\n                    resolve(raw);\n                });\n            });\n        });\n    }\n    static onEvent(event) {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(event);\n    }\n    CreateConnection(request, options) {\n        const enableOCSP = (typeof process !== \"undefined\" && process.env.NODE_TLS_REJECT_UNAUTHORIZED !== \"0\" && process.env.SPEECH_CONDUCT_OCSP_CHECK !== \"0\") && options.secureEndpoint;\n        let socketPromise;\n        options = Object.assign(Object.assign({}, options), {\n            requestOCSP: !CertCheckAgent.forceDisableOCSPStapling,\n            servername: options.host\n        });\n        if (!!this.privProxyInfo) {\n            const httpProxyAgent = CertCheckAgent.GetProxyAgent(this.privProxyInfo);\n            const baseAgent = httpProxyAgent;\n            socketPromise = new Promise((resolve, reject) => {\n                baseAgent.callback(request, options, (error, socket) => {\n                    if (!!error) {\n                        reject(error);\n                    }\n                    else {\n                        resolve(socket);\n                    }\n                });\n            });\n        }\n        else {\n            if (!!options.secureEndpoint) {\n                socketPromise = Promise.resolve(tls__WEBPACK_IMPORTED_MODULE_0__[\"connect\"](options));\n            }\n            else {\n                socketPromise = Promise.resolve(net__WEBPACK_IMPORTED_MODULE_6__[\"connect\"](options));\n            }\n        }\n        if (!!enableOCSP) {\n            return CertCheckAgent.OCSPCheck(socketPromise, this.privProxyInfo);\n        }\n        else {\n            return socketPromise;\n        }\n    }\n}\n// Test hook to enable forcing expiration / refresh to happen.\nCertCheckAgent.testTimeOffset = 0;\n// Test hook to disable stapling for cache testing.\nCertCheckAgent.forceDisableOCSPStapling = false;\n// An in memory cache for recived responses.\nCertCheckAgent.privMemCache = {};\n\n//# sourceMappingURL=CertChecks.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js ***!
  \*************************************************************************************************************************/
/*! exports provided: ConsoleLoggingListener */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConsoleLoggingListener\", function() { return ConsoleLoggingListener; });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/LogLevel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LogLevel.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass ConsoleLoggingListener {\n    constructor(logLevelFilter = _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__[\"LogLevel\"].None) {\n        this.privLogPath = undefined;\n        this.privLogLevelFilter = logLevelFilter;\n    }\n    set logPath(path) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__[\"openSync\"], \"\\nFile System access not available\");\n        this.privLogPath = path;\n    }\n    onEvent(event) {\n        if (event.eventType >= this.privLogLevelFilter) {\n            const log = this.toString(event);\n            if (!!this.privLogPath) {\n                fs__WEBPACK_IMPORTED_MODULE_0__[\"writeFileSync\"](this.privLogPath, log + \"\\n\", { flag: \"a+\" });\n            }\n            switch (event.eventType) {\n                case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__[\"LogLevel\"].Debug:\n                    // eslint-disable-next-line no-console\n                    console.debug(log);\n                    break;\n                case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__[\"LogLevel\"].Info:\n                    // eslint-disable-next-line no-console\n                    console.info(log);\n                    break;\n                case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__[\"LogLevel\"].Warning:\n                    // eslint-disable-next-line no-console\n                    console.warn(log);\n                    break;\n                case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__[\"LogLevel\"].Error:\n                    // eslint-disable-next-line no-console\n                    console.error(log);\n                    break;\n                default:\n                    // eslint-disable-next-line no-console\n                    console.log(log);\n                    break;\n            }\n        }\n    }\n    toString(event) {\n        const logFragments = [\n            `${event.eventTime}`,\n            `${event.name}`,\n        ];\n        const e = event;\n        for (const prop in e) {\n            if (prop && event.hasOwnProperty(prop) &&\n                prop !== \"eventTime\" && prop !== \"eventType\" &&\n                prop !== \"eventId\" && prop !== \"name\" &&\n                prop !== \"constructor\") {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n                const value = e[prop];\n                let valueToLog = \"<NULL>\";\n                if (value !== undefined && value !== null) {\n                    if (typeof (value) === \"number\" || typeof (value) === \"string\") {\n                        valueToLog = value.toString();\n                    }\n                    else {\n                        valueToLog = JSON.stringify(value);\n                    }\n                }\n                logFragments.push(`${prop}: ${valueToLog}`);\n            }\n        }\n        return logFragments.join(\" | \");\n    }\n}\n\n//# sourceMappingURL=ConsoleLoggingListener.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js ***!
  \**********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _ConsoleLoggingListener__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConsoleLoggingListener */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConsoleLoggingListener\", function() { return _ConsoleLoggingListener__WEBPACK_IMPORTED_MODULE_0__[\"ConsoleLoggingListener\"]; });\n\n/* harmony import */ var _IRecorder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IRecorder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js\");\n/* harmony import */ var _IRecorder__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_IRecorder__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IRecorder__WEBPACK_IMPORTED_MODULE_1__) if([\"ConsoleLoggingListener\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IRecorder__WEBPACK_IMPORTED_MODULE_1__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./MicAudioSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioWorkletSourceURLPropertyName\", function() { return _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__[\"AudioWorkletSourceURLPropertyName\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MicAudioSource\", function() { return _MicAudioSource__WEBPACK_IMPORTED_MODULE_2__[\"MicAudioSource\"]; });\n\n/* harmony import */ var _FileAudioSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FileAudioSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FileAudioSource\", function() { return _FileAudioSource__WEBPACK_IMPORTED_MODULE_3__[\"FileAudioSource\"]; });\n\n/* harmony import */ var _PCMRecorder__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./PCMRecorder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PcmRecorder\", function() { return _PCMRecorder__WEBPACK_IMPORTED_MODULE_4__[\"PcmRecorder\"]; });\n\n/* harmony import */ var _WebsocketConnection__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./WebsocketConnection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"WebsocketConnection\", function() { return _WebsocketConnection__WEBPACK_IMPORTED_MODULE_5__[\"WebsocketConnection\"]; });\n\n/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"WebsocketMessageAdapter\", function() { return _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_6__[\"WebsocketMessageAdapter\"]; });\n\n/* harmony import */ var _ReplayableAudioNode__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ReplayableAudioNode */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ReplayableAudioNode\", function() { return _ReplayableAudioNode__WEBPACK_IMPORTED_MODULE_7__[\"ReplayableAudioNode\"]; });\n\n/* harmony import */ var _ProxyInfo__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ProxyInfo */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ProxyInfo\", function() { return _ProxyInfo__WEBPACK_IMPORTED_MODULE_8__[\"ProxyInfo\"]; });\n\n/* harmony import */ var _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RestMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RestRequestType\", function() { return _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__[\"RestRequestType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RestMessageAdapter\", function() { return _RestMessageAdapter__WEBPACK_IMPORTED_MODULE_9__[\"RestMessageAdapter\"]; });\n\n/* harmony import */ var _RestConfigBase__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./RestConfigBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RestConfigBase\", function() { return _RestConfigBase__WEBPACK_IMPORTED_MODULE_10__[\"RestConfigBase\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js ***!
  \******************************************************************************************************************/
/*! exports provided: FileAudioSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FileAudioSource\", function() { return FileAudioSource; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass FileAudioSource {\n    constructor(file, filename, audioSourceId) {\n        this.privStreams = {};\n        this.privHeaderEnd = 44;\n        this.privId = audioSourceId ? audioSourceId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privSource = file;\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && this.privSource instanceof Blob) {\n            this.privFilename = file.name;\n        }\n        else {\n            this.privFilename = filename || \"unknown.wav\";\n        }\n        // Read the header.\n        this.privAudioFormatPromise = this.readHeader();\n    }\n    get format() {\n        return this.privAudioFormatPromise;\n    }\n    get blob() {\n        return Promise.resolve(this.privSource);\n    }\n    turnOn() {\n        if (this.privFilename.lastIndexOf(\".wav\") !== this.privFilename.length - 4) {\n            const errorMsg = this.privFilename + \" is not supported. Only WAVE files are allowed at the moment.\";\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceErrorEvent\"](errorMsg, \"\"));\n            return Promise.reject(errorMsg);\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceInitializingEvent\"](this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceReadyEvent\"](this.privId));\n        return;\n    }\n    id() {\n        return this.privId;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachingEvent\"](this.privId, audioNodeId));\n            const stream = yield this.upload(audioNodeId);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachedEvent\"](this.privId, audioNodeId));\n            return Promise.resolve({\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    stream.readEnded();\n                    delete this.privStreams[audioNodeId];\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n                    yield this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            });\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n        }\n    }\n    turnOff() {\n        for (const streamId in this.privStreams) {\n            if (streamId) {\n                const stream = this.privStreams[streamId];\n                if (stream && !stream.isClosed) {\n                    stream.close();\n                }\n            }\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceOffEvent\"](this.privId)); // no stream now\n        return Promise.resolve();\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.privAudioFormatPromise.then((result) => (Promise.resolve({\n            bitspersample: result.bitsPerSample,\n            channelcount: result.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"connectivity\"].Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"File\",\n            samplerate: result.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"type\"].File,\n        })));\n    }\n    readHeader() {\n        // Read the wave header.\n        const maxHeaderSize = 512;\n        const header = this.privSource.slice(0, maxHeaderSize);\n        const headerResult = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Deferred\"]();\n        const processHeader = (header) => {\n            const view = new DataView(header);\n            const getWord = (index) => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));\n            // RIFF 4 bytes.\n            if (\"RIFF\" !== getWord(0)) {\n                headerResult.reject(\"Invalid WAV header in file, RIFF was not found\");\n                return;\n            }\n            // length, 4 bytes\n            // RIFF Type & fmt 8 bytes\n            if (\"WAVE\" !== getWord(8) || \"fmt \" !== getWord(12)) {\n                headerResult.reject(\"Invalid WAV header in file, WAVEfmt was not found\");\n                return;\n            }\n            const formatSize = view.getInt32(16, true);\n            const channelCount = view.getUint16(22, true);\n            const sampleRate = view.getUint32(24, true);\n            const bitsPerSample = view.getUint16(34, true);\n            // Confirm if header is 44 bytes long.\n            let pos = 36 + Math.max(formatSize - 16, 0);\n            for (; getWord(pos) !== \"data\"; pos += 2) {\n                if (pos > maxHeaderSize - 8) {\n                    headerResult.reject(\"Invalid WAV header in file, data block was not found\");\n                    return;\n                }\n            }\n            this.privHeaderEnd = pos + 8;\n            headerResult.resolve(_sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__[\"AudioStreamFormat\"].getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));\n        };\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && header instanceof Blob) {\n            const reader = new FileReader();\n            reader.onload = (event) => {\n                const header = event.target.result;\n                processHeader(header);\n            };\n            reader.readAsArrayBuffer(header);\n        }\n        else {\n            const h = header;\n            processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));\n        }\n        return headerResult.promise;\n    }\n    upload(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const onerror = (error) => {\n                const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeErrorEvent\"](this.privId, audioNodeId, errorMsg));\n                throw new Error(errorMsg);\n            };\n            try {\n                yield this.turnOn();\n                const format = yield this.privAudioFormatPromise;\n                const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ChunkedArrayBufferStream\"](format.avgBytesPerSec / 10, audioNodeId);\n                this.privStreams[audioNodeId] = stream;\n                const chunk = this.privSource.slice(this.privHeaderEnd);\n                const processFile = (buff) => {\n                    if (stream.isClosed) {\n                        return; // output stream was closed (somebody called TurnOff). We're done here.\n                    }\n                    stream.writeStreamChunk({\n                        buffer: buff,\n                        isEnd: false,\n                        timeReceived: Date.now(),\n                    });\n                    stream.close();\n                };\n                if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && chunk instanceof Blob) {\n                    const reader = new FileReader();\n                    reader.onerror = (ev) => onerror(ev.toString());\n                    reader.onload = (event) => {\n                        const fileBuffer = event.target.result;\n                        processFile(fileBuffer);\n                    };\n                    reader.readAsArrayBuffer(chunk);\n                }\n                else {\n                    const c = chunk;\n                    processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));\n                }\n                return stream;\n            }\n            catch (e) {\n                onerror(e);\n            }\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(event);\n    }\n}\n\n//# sourceMappingURL=FileAudioSource.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js ***!
  \************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IRecorder.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/IRecorder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js ***!
  \*****************************************************************************************************************/
/*! exports provided: AudioWorkletSourceURLPropertyName, MicAudioSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioWorkletSourceURLPropertyName\", function() { return AudioWorkletSourceURLPropertyName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MicAudioSource\", function() { return MicAudioSource; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nconst AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nclass MicAudioSource {\n    constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n        this.privRecorder = privRecorder;\n        this.deviceId = deviceId;\n        this.privStreams = {};\n        this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n        this.privId = audioSourceId ? audioSourceId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privMediaStream = mediaStream || null;\n        this.privIsClosing = false;\n    }\n    get format() {\n        return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n    }\n    get blob() {\n        return Promise.reject(\"Not implemented for Mic input\");\n    }\n    turnOn() {\n        if (this.privInitializeDeferral) {\n            return this.privInitializeDeferral.promise;\n        }\n        this.privInitializeDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Deferred\"]();\n        try {\n            this.createAudioContext();\n        }\n        catch (error) {\n            if (error instanceof Error) {\n                const typedError = error;\n                this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                this.privInitializeDeferral.reject(error);\n            }\n            return this.privInitializeDeferral.promise;\n        }\n        const nav = window.navigator;\n        let getUserMedia = (\n        // eslint-disable-next-line\n        nav.getUserMedia ||\n            nav.webkitGetUserMedia ||\n            nav.mozGetUserMedia ||\n            nav.msGetUserMedia);\n        if (!!nav.mediaDevices) {\n            getUserMedia = (constraints, successCallback, errorCallback) => {\n                nav.mediaDevices\n                    .getUserMedia(constraints)\n                    .then(successCallback)\n                    .catch(errorCallback);\n            };\n        }\n        if (!getUserMedia) {\n            const errorMsg = \"Browser does not support getUserMedia.\";\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceErrorEvent\"](errorMsg, \"\")); // mic initialized error - no streamid at this point\n        }\n        else {\n            const next = () => {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceInitializingEvent\"](this.privId)); // no stream id\n                if (this.privMediaStream && this.privMediaStream.active) {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceReadyEvent\"](this.privId));\n                    this.privInitializeDeferral.resolve();\n                }\n                else {\n                    getUserMedia({ audio: this.deviceId ? { deviceId: this.deviceId } : true, video: false }, (mediaStream) => {\n                        this.privMediaStream = mediaStream;\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceReadyEvent\"](this.privId));\n                        this.privInitializeDeferral.resolve();\n                    }, (error) => {\n                        const errorMsg = `Error occurred during microphone initialization: ${error}`;\n                        this.privInitializeDeferral.reject(errorMsg);\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceErrorEvent\"](this.privId, errorMsg));\n                    });\n                }\n            };\n            if (this.privContext.state === \"suspended\") {\n                // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n                // https://github.com/WebAudio/web-audio-api/issues/790\n                this.privContext.resume()\n                    .then(next)\n                    .catch((reason) => {\n                    this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n                });\n            }\n            else {\n                next();\n            }\n        }\n        return this.privInitializeDeferral.promise;\n    }\n    id() {\n        return this.privId;\n    }\n    attach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachingEvent\"](this.privId, audioNodeId));\n        return this.listen(audioNodeId).then((stream) => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachedEvent\"](this.privId, audioNodeId));\n            return {\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    stream.readEnded();\n                    delete this.privStreams[audioNodeId];\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n                    return this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            };\n        });\n    }\n    detach(audioNodeId) {\n        if (audioNodeId && this.privStreams[audioNodeId]) {\n            this.privStreams[audioNodeId].close();\n            delete this.privStreams[audioNodeId];\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n        }\n    }\n    turnOff() {\n        return __awaiter(this, void 0, void 0, function* () {\n            for (const streamId in this.privStreams) {\n                if (streamId) {\n                    const stream = this.privStreams[streamId];\n                    if (stream) {\n                        stream.close();\n                    }\n                }\n            }\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceOffEvent\"](this.privId)); // no stream now\n            if (this.privInitializeDeferral) {\n                // Correctly handle when browser forces mic off before turnOn() completes\n                // eslint-disable-next-line @typescript-eslint/await-thenable\n                yield this.privInitializeDeferral;\n                this.privInitializeDeferral = null;\n            }\n            yield this.destroyAudioContext();\n            return;\n        });\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return this.getMicrophoneLabel().then((label) => ({\n            bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n            channelcount: MicAudioSource.AUDIOFORMAT.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"connectivity\"].Unknown,\n            manufacturer: \"Speech SDK\",\n            model: label,\n            samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"type\"].Microphones,\n        }));\n    }\n    setProperty(name, value) {\n        if (name === AudioWorkletSourceURLPropertyName) {\n            this.privRecorder.setWorkletUrl(value);\n        }\n        else {\n            throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n        }\n    }\n    getMicrophoneLabel() {\n        const defaultMicrophoneName = \"microphone\";\n        // If we did this already, return the value.\n        if (this.privMicrophoneLabel !== undefined) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        // If the stream isn't currently running, we can't query devices because security.\n        if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n            return Promise.resolve(defaultMicrophoneName);\n        }\n        // Setup a default\n        this.privMicrophoneLabel = defaultMicrophoneName;\n        // Get the id of the device running the audio track.\n        const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;\n        // If the browser doesn't support getting the device ID, set a default and return.\n        if (undefined === microphoneDeviceId) {\n            return Promise.resolve(this.privMicrophoneLabel);\n        }\n        const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Deferred\"]();\n        // Enumerate the media devices.\n        navigator.mediaDevices.enumerateDevices().then((devices) => {\n            for (const device of devices) {\n                if (device.deviceId === microphoneDeviceId) {\n                    // Found the device\n                    this.privMicrophoneLabel = device.label;\n                    break;\n                }\n            }\n            deferred.resolve(this.privMicrophoneLabel);\n        }, () => deferred.resolve(this.privMicrophoneLabel));\n        return deferred.promise;\n    }\n    listen(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.turnOn();\n            const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ChunkedArrayBufferStream\"](this.privOutputChunkSize, audioNodeId);\n            this.privStreams[audioNodeId] = stream;\n            try {\n                this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n            }\n            catch (error) {\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeErrorEvent\"](this.privId, audioNodeId, error));\n                throw error;\n            }\n            const result = stream;\n            return result;\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(event);\n    }\n    createAudioContext() {\n        if (!!this.privContext) {\n            return;\n        }\n        this.privContext = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__[\"AudioStreamFormatImpl\"].getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n    }\n    destroyAudioContext() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privContext) {\n                return;\n            }\n            this.privRecorder.releaseMediaResources(this.privContext);\n            // This pattern brought to you by a bug in the TypeScript compiler where it\n            // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n            // https://github.com/Microsoft/TypeScript/issues/11498\n            let hasClose = false;\n            if (\"close\" in this.privContext) {\n                hasClose = true;\n            }\n            if (hasClose) {\n                if (!this.privIsClosing) {\n                    // The audio context close may take enough time that the close is called twice\n                    this.privIsClosing = true;\n                    yield this.privContext.close();\n                    this.privContext = null;\n                    this.privIsClosing = false;\n                }\n            }\n            else if (null !== this.privContext && this.privContext.state === \"running\") {\n                // Suspend actually takes a callback, but analogous to the\n                // resume method, it'll be only fired if suspend is called\n                // in a direct response to a user action. The later is not always\n                // the case, as TurnOff is also called, when we receive an\n                // end-of-speech message from the service. So, doing a best effort\n                // fire-and-forget here.\n                yield this.privContext.suspend();\n            }\n        });\n    }\n}\nMicAudioSource.AUDIOFORMAT = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__[\"AudioStreamFormat\"].getDefaultInputFormat();\n\n//# sourceMappingURL=MicAudioSource.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js ***!
  \**************************************************************************************************************/
/*! exports provided: PcmRecorder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PcmRecorder\", function() { return PcmRecorder; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass PcmRecorder {\n    constructor(stopInputOnRelease) {\n        this.privStopInputOnRelease = stopInputOnRelease;\n    }\n    record(context, mediaStream, outputStream) {\n        const desiredSampleRate = 16000;\n        const waveStreamEncoder = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RiffPcmEncoder\"](context.sampleRate, desiredSampleRate);\n        const micInput = context.createMediaStreamSource(mediaStream);\n        const attachScriptProcessor = () => {\n            // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n            const scriptNode = (() => {\n                let bufferSize = 0;\n                try {\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n                catch (error) {\n                    // Webkit (<= version 31) requires a valid bufferSize.\n                    bufferSize = 2048;\n                    let audioSampleRate = context.sampleRate;\n                    while (bufferSize < 16384 && audioSampleRate >= (2 * desiredSampleRate)) {\n                        bufferSize <<= 1;\n                        audioSampleRate >>= 1;\n                    }\n                    return context.createScriptProcessor(bufferSize, 1, 1);\n                }\n            })();\n            scriptNode.onaudioprocess = (event) => {\n                const inputFrame = event.inputBuffer.getChannelData(0);\n                if (outputStream && !outputStream.isClosed) {\n                    const waveFrame = waveStreamEncoder.encode(inputFrame);\n                    if (!!waveFrame) {\n                        outputStream.writeStreamChunk({\n                            buffer: waveFrame,\n                            isEnd: false,\n                            timeReceived: Date.now(),\n                        });\n                    }\n                }\n            };\n            micInput.connect(scriptNode);\n            scriptNode.connect(context.destination);\n            this.privMediaResources = {\n                scriptProcessorNode: scriptNode,\n                source: micInput,\n                stream: mediaStream,\n            };\n        };\n        // https://webaudio.github.io/web-audio-api/#audioworklet\n        // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread\n        if (!!context.audioWorklet) {\n            if (!this.privSpeechProcessorScript) {\n                const workletScript = `class SP extends AudioWorkletProcessor {\r\n                    constructor(options) {\r\n                      super(options);\r\n                    }\r\n                    process(inputs, outputs) {\r\n                      const input = inputs[0];\r\n                      const output = [];\r\n                      for (let channel = 0; channel < input.length; channel += 1) {\r\n                        output[channel] = input[channel];\r\n                      }\r\n                      this.port.postMessage(output[0]);\r\n                      return true;\r\n                    }\r\n                  }\r\n                  registerProcessor('speech-processor', SP);`;\n                const blob = new Blob([workletScript], { type: \"application/javascript; charset=utf-8\" });\n                this.privSpeechProcessorScript = URL.createObjectURL(blob);\n            }\n            context.audioWorklet\n                .addModule(this.privSpeechProcessorScript)\n                .then(() => {\n                const workletNode = new AudioWorkletNode(context, \"speech-processor\");\n                workletNode.port.onmessage = (ev) => {\n                    const inputFrame = ev.data;\n                    if (outputStream && !outputStream.isClosed) {\n                        const waveFrame = waveStreamEncoder.encode(inputFrame);\n                        if (!!waveFrame) {\n                            outputStream.writeStreamChunk({\n                                buffer: waveFrame,\n                                isEnd: false,\n                                timeReceived: Date.now(),\n                            });\n                        }\n                    }\n                };\n                micInput.connect(workletNode);\n                workletNode.connect(context.destination);\n                this.privMediaResources = {\n                    scriptProcessorNode: workletNode,\n                    source: micInput,\n                    stream: mediaStream,\n                };\n            })\n                .catch(() => {\n                attachScriptProcessor();\n            });\n        }\n        else {\n            try {\n                attachScriptProcessor();\n            }\n            catch (err) {\n                throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);\n            }\n        }\n    }\n    releaseMediaResources(context) {\n        if (this.privMediaResources) {\n            if (this.privMediaResources.scriptProcessorNode) {\n                this.privMediaResources.scriptProcessorNode.disconnect(context.destination);\n                this.privMediaResources.scriptProcessorNode = null;\n            }\n            if (this.privMediaResources.source) {\n                this.privMediaResources.source.disconnect();\n                if (this.privStopInputOnRelease) {\n                    this.privMediaResources.stream.getTracks().forEach((track) => track.stop());\n                }\n                this.privMediaResources.source = null;\n            }\n        }\n    }\n    setWorkletUrl(url) {\n        this.privSpeechProcessorScript = url;\n    }\n}\n\n//# sourceMappingURL=PCMRecorder.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js ***!
  \************************************************************************************************************/
/*! exports provided: ProxyInfo */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ProxyInfo\", function() { return ProxyInfo; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ProxyInfo {\n    constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.privProxyHostName = proxyHostName;\n        this.privProxyPort = proxyPort;\n        this.privProxyUserName = proxyUserName;\n        this.privProxyPassword = proxyPassword;\n    }\n    static fromParameters(parameters) {\n        return new ProxyInfo(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_ProxyUserName), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_ProxyPassword));\n    }\n    static fromRecognizerConfig(config) {\n        return this.fromParameters(config.parameters);\n    }\n    get HostName() {\n        return this.privProxyHostName;\n    }\n    get Port() {\n        return this.privProxyPort;\n    }\n    get UserName() {\n        return this.privProxyUserName;\n    }\n    get Password() {\n        return this.privProxyPassword;\n    }\n}\n\n//# sourceMappingURL=ProxyInfo.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js ***!
  \**********************************************************************************************************************/
/*! exports provided: ReplayableAudioNode */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ReplayableAudioNode\", function() { return ReplayableAudioNode; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ReplayableAudioNode {\n    constructor(audioSource, bytesPerSecond) {\n        this.privBuffers = [];\n        this.privReplayOffset = 0;\n        this.privLastShrinkOffset = 0;\n        this.privBufferStartOffset = 0;\n        this.privBufferSerial = 0;\n        this.privBufferedBytes = 0;\n        this.privReplay = false;\n        this.privLastChunkAcquiredTime = 0;\n        this.privAudioNode = audioSource;\n        this.privBytesPerSecond = bytesPerSecond;\n    }\n    id() {\n        return this.privAudioNode.id();\n    }\n    // Reads and returns the next chunk of audio buffer.\n    // If replay of existing buffers are needed, read() will first seek and replay\n    // existing content, and upoin completion it will read new content from the underlying\n    // audio node, saving that content into the replayable buffers.\n    read() {\n        // if there is a replay request to honor.\n        if (!!this.privReplay && this.privBuffers.length !== 0) {\n            // Find the start point in the buffers.\n            // Offsets are in 100ns increments.\n            // So how many bytes do we need to seek to get the right offset?\n            const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;\n            let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n            if (0 !== (bytesToSeek % 2)) {\n                bytesToSeek++;\n            }\n            let i = 0;\n            while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n                bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n            }\n            if (i < this.privBuffers.length) {\n                const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);\n                this.privReplayOffset += (retVal.byteLength / this.privBytesPerSecond) * 1e+7;\n                // If we've reached the end of the buffers, stop replaying.\n                if (i === this.privBuffers.length - 1) {\n                    this.privReplay = false;\n                }\n                return Promise.resolve({\n                    buffer: retVal,\n                    isEnd: false,\n                    timeReceived: this.privBuffers[i].chunk.timeReceived,\n                });\n            }\n        }\n        return this.privAudioNode.read()\n            .then((result) => {\n            if (result && result.buffer) {\n                this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));\n                this.privBufferedBytes += result.buffer.byteLength;\n            }\n            return result;\n        });\n    }\n    detach() {\n        this.privBuffers = undefined;\n        return this.privAudioNode.detach();\n    }\n    replay() {\n        if (this.privBuffers && 0 !== this.privBuffers.length) {\n            this.privReplay = true;\n            this.privReplayOffset = this.privLastShrinkOffset;\n        }\n    }\n    // Shrinks the existing audio buffers to start at the new offset, or at the\n    // beginning of the buffer closest to the requested offset.\n    // A replay request will start from the last shrink point.\n    shrinkBuffers(offset) {\n        if (this.privBuffers === undefined || this.privBuffers.length === 0) {\n            return;\n        }\n        this.privLastShrinkOffset = offset;\n        // Find the start point in the buffers.\n        // Offsets are in 100ns increments.\n        // So how many bytes do we need to seek to get the right offset?\n        const offsetToSeek = offset - this.privBufferStartOffset;\n        let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n        let i = 0;\n        while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n            bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n        }\n        this.privBufferStartOffset = Math.round(offset - ((bytesToSeek / this.privBytesPerSecond) * 1e+7));\n        this.privBuffers = this.privBuffers.slice(i);\n    }\n    // Finds the time a buffer of audio was first seen by offset.\n    findTimeAtOffset(offset) {\n        if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {\n            return 0;\n        }\n        for (const value of this.privBuffers) {\n            const startOffset = (value.byteOffset / this.privBytesPerSecond) * 1e7;\n            const endOffset = startOffset + ((value.chunk.buffer.byteLength / this.privBytesPerSecond) * 1e7);\n            if (offset >= startOffset && offset <= endOffset) {\n                return value.chunk.timeReceived;\n            }\n        }\n        return 0;\n    }\n}\n// Primary use of this class is to help debugging problems with the replay\n// code. If the memory cost of alloc / dealloc gets too much, drop it and just use\n// the ArrayBuffer directly.\nclass BufferEntry {\n    constructor(chunk, serial, byteOffset) {\n        this.chunk = chunk;\n        this.serial = serial;\n        this.byteOffset = byteOffset;\n    }\n}\n\n//# sourceMappingURL=ReplayableAudioNode.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js ***!
  \*****************************************************************************************************************/
/*! exports provided: RestConfigBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RestConfigBase\", function() { return RestConfigBase; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RestConfigBase {\n    static get requestOptions() {\n        return RestConfigBase.privDefaultRequestOptions;\n    }\n    static get configParams() {\n        return RestConfigBase.privDefaultParams;\n    }\n    static get restErrors() {\n        return RestConfigBase.privRestErrors;\n    }\n}\nRestConfigBase.privDefaultRequestOptions = {\n    headers: {\n        Accept: \"application/json\",\n    },\n    ignoreCache: false,\n    timeout: 10000,\n};\nRestConfigBase.privRestErrors = {\n    authInvalidSubscriptionKey: \"You must specify either an authentication token to use, or a Cognitive Speech subscription key.\",\n    authInvalidSubscriptionRegion: \"You must specify the Cognitive Speech region to use.\",\n    invalidArgs: \"Required input not found: {arg}.\",\n    invalidCreateJoinConversationResponse: \"Creating/Joining conversation failed with HTTP {status}.\",\n    invalidParticipantRequest: \"The requested participant was not found.\",\n    permissionDeniedConnect: \"Required credentials not found.\",\n    permissionDeniedConversation: \"Invalid operation: only the host can {command} the conversation.\",\n    permissionDeniedParticipant: \"Invalid operation: only the host can {command} a participant.\",\n    permissionDeniedSend: \"Invalid operation: the conversation is not in a connected state.\",\n    permissionDeniedStart: \"Invalid operation: there is already an active conversation.\",\n};\nRestConfigBase.privDefaultParams = {\n    apiVersion: \"api-version\",\n    authorization: \"Authorization\",\n    clientAppId: \"X-ClientAppId\",\n    contentTypeKey: \"Content-Type\",\n    correlationId: \"X-CorrelationId\",\n    languageCode: \"language\",\n    nickname: \"nickname\",\n    profanity: \"profanity\",\n    requestId: \"X-RequestId\",\n    roomId: \"roomid\",\n    sessionToken: \"token\",\n    subscriptionKey: \"Ocp-Apim-Subscription-Key\",\n    subscriptionRegion: \"Ocp-Apim-Subscription-Region\",\n    token: \"X-CapitoToken\",\n};\n\n//# sourceMappingURL=RestConfigBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js ***!
  \*********************************************************************************************************************/
/*! exports provided: RestRequestType, RestMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RestRequestType\", function() { return RestRequestType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RestMessageAdapter\", function() { return RestMessageAdapter; });\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bent */ \"./node_modules/bent/src/browser.js\");\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bent__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nvar RestRequestType;\n(function (RestRequestType) {\n    RestRequestType[\"Get\"] = \"GET\";\n    RestRequestType[\"Post\"] = \"POST\";\n    RestRequestType[\"Delete\"] = \"DELETE\";\n    RestRequestType[\"File\"] = \"file\";\n})(RestRequestType || (RestRequestType = {}));\n// accept rest operations via request method and return abstracted objects from server response\nclass RestMessageAdapter {\n    constructor(configParams) {\n        if (!configParams) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"configParams\");\n        }\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    static extractHeaderValue(headerKey, headers) {\n        let headerValue = \"\";\n        try {\n            const arr = headers.trim().split(/[\\r\\n]+/);\n            const headerMap = {};\n            arr.forEach((line) => {\n                const parts = line.split(\": \");\n                const header = parts.shift().toLowerCase();\n                const value = parts.join(\": \");\n                headerMap[header] = value;\n            });\n            headerValue = headerMap[headerKey.toLowerCase()];\n        }\n        catch (e) {\n            // ignore the error\n        }\n        return headerValue;\n    }\n    set options(configParams) {\n        this.privHeaders = configParams.headers;\n        this.privIgnoreCache = configParams.ignoreCache;\n    }\n    setHeaders(key, value) {\n        this.privHeaders[key] = value;\n    }\n    request(method, uri, queryParams = {}, body = null, binaryBody = null) {\n        const responseReceivedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Deferred\"]();\n        const requestCommand = method === RestRequestType.File ? \"POST\" : method;\n        const handleRestResponse = (data, j = {}) => {\n            const d = data;\n            return {\n                data: JSON.stringify(j),\n                headers: JSON.stringify(data.headers),\n                json: j,\n                ok: data.statusCode >= 200 && data.statusCode < 300,\n                status: data.statusCode,\n                statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage\n            };\n        };\n        const blobToArrayBuffer = (blob) => {\n            const reader = new FileReader();\n            reader.readAsArrayBuffer(blob);\n            return new Promise((resolve) => {\n                reader.onloadend = () => {\n                    resolve(reader.result);\n                };\n            });\n        };\n        const send = (postData) => {\n            const sendRequest = bent__WEBPACK_IMPORTED_MODULE_0___default()(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);\n            const params = this.queryParams(queryParams) === \"\" ? \"\" : `?${this.queryParams(queryParams)}`;\n            sendRequest(params, postData).then((data) => __awaiter(this, void 0, void 0, function* () {\n                if (method === RestRequestType.Delete || data.statusCode === 204) {\n                    // No JSON from Delete and reset (204) operations\n                    responseReceivedDeferral.resolve(handleRestResponse(data));\n                }\n                else {\n                    try {\n                        const j = yield data.json();\n                        responseReceivedDeferral.resolve(handleRestResponse(data, j));\n                    }\n                    catch (_a) {\n                        responseReceivedDeferral.resolve(handleRestResponse(data));\n                    }\n                }\n            })).catch((error) => {\n                responseReceivedDeferral.reject(error);\n            });\n        };\n        if (this.privIgnoreCache) {\n            this.privHeaders[\"Cache-Control\"] = \"no-cache\";\n        }\n        if (method === RestRequestType.File && binaryBody) {\n            const contentType = \"multipart/form-data\";\n            this.privHeaders[\"content-type\"] = contentType;\n            this.privHeaders[\"Content-Type\"] = contentType;\n            if (typeof (Blob) !== \"undefined\" && binaryBody instanceof Blob) {\n                blobToArrayBuffer(binaryBody).then((res) => {\n                    send(res);\n                }).catch((error) => {\n                    responseReceivedDeferral.reject(error);\n                });\n            }\n            else {\n                send(binaryBody);\n            }\n        }\n        else {\n            if (method === RestRequestType.Post && body) {\n                this.privHeaders[\"content-type\"] = \"application/json\";\n                this.privHeaders[\"Content-Type\"] = \"application/json\";\n            }\n            send(body);\n        }\n        return responseReceivedDeferral.promise;\n    }\n    withQuery(url, params = {}) {\n        const queryString = this.queryParams(params);\n        return queryString ? url + (url.indexOf(\"?\") === -1 ? \"?\" : \"&\") + queryString : url;\n    }\n    queryParams(params = {}) {\n        return Object.keys(params)\n            .map((k) => encodeURIComponent(k) + \"=\" + encodeURIComponent(params[k]))\n            .join(\"&\");\n    }\n}\n\n//# sourceMappingURL=RestMessageAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js ***!
  \**********************************************************************************************************************/
/*! exports provided: WebsocketConnection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"WebsocketConnection\", function() { return WebsocketConnection; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nclass WebsocketConnection {\n    constructor(uri, queryParameters, headers, messageFormatter, proxyInfo, enableCompression = false, connectionId) {\n        this.privIsDisposed = false;\n        if (!uri) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"messageFormatter\");\n        }\n        this.privMessageFormatter = messageFormatter;\n        let queryParams = \"\";\n        let i = 0;\n        if (queryParameters) {\n            for (const paramName in queryParameters) {\n                if (paramName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const val = encodeURIComponent(queryParameters[paramName]);\n                    queryParams += `${paramName}=${val}`;\n                    i++;\n                }\n            }\n        }\n        if (headers) {\n            for (const headerName in headers) {\n                if (headerName) {\n                    queryParams += ((i === 0) && (uri.indexOf(\"?\") === -1)) ? \"?\" : \"&\";\n                    const val = encodeURIComponent(headers[headerName]);\n                    queryParams += `${headerName}=${val}`;\n                    i++;\n                }\n            }\n        }\n        this.privUri = uri + queryParams;\n        this.privId = connectionId ? connectionId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privConnectionMessageAdapter = new _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_1__[\"WebsocketMessageAdapter\"](this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privConnectionMessageAdapter) {\n                yield this.privConnectionMessageAdapter.close();\n            }\n        });\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    get id() {\n        return this.privId;\n    }\n    state() {\n        return this.privConnectionMessageAdapter.state;\n    }\n    open() {\n        return this.privConnectionMessageAdapter.open();\n    }\n    send(message) {\n        return this.privConnectionMessageAdapter.send(message);\n    }\n    read() {\n        return this.privConnectionMessageAdapter.read();\n    }\n    get events() {\n        return this.privConnectionMessageAdapter.events;\n    }\n}\n\n//# sourceMappingURL=WebsocketConnection.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js ***!
  \**************************************************************************************************************************/
/*! exports provided: WebsocketMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"WebsocketMessageAdapter\", function() { return WebsocketMessageAdapter; });\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ws */ 0);\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(ws__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _CertChecks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./CertChecks */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// Node.JS specific web socket / browser support.\n\n\n\n\nclass WebsocketMessageAdapter {\n    constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {\n        if (!uri) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ArgumentNullError\"](\"uri\");\n        }\n        if (!messageFormatter) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ArgumentNullError\"](\"messageFormatter\");\n        }\n        this.proxyInfo = proxyInfo;\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"EventSource\"]();\n        this.privConnectionId = connectionId;\n        this.privMessageFormatter = messageFormatter;\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].None;\n        this.privUri = uri;\n        this.privHeaders = headers;\n        this.privEnableCompression = enableCompression;\n        // Add the connection ID to the headers\n        this.privHeaders[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].ConnectionId] = this.privConnectionId;\n        this.privLastErrorReceived = \"\";\n    }\n    get state() {\n        return this.privConnectionState;\n    }\n    open() {\n        if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Disconnected) {\n            return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);\n        }\n        if (this.privConnectionEstablishDeferral) {\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.privConnectionEstablishDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        this.privCertificateValidatedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connecting;\n        try {\n            if (typeof WebSocket !== \"undefined\" && !WebsocketMessageAdapter.forceNpmWebSocket) {\n                // Browser handles cert checks.\n                this.privCertificateValidatedDeferral.resolve();\n                this.privWebsocketClient = new WebSocket(this.privUri);\n            }\n            else {\n                const options = { headers: this.privHeaders, perMessageDeflate: this.privEnableCompression };\n                // The ocsp library will handle validation for us and fail the connection if needed.\n                this.privCertificateValidatedDeferral.resolve();\n                const checkAgent = new _CertChecks__WEBPACK_IMPORTED_MODULE_3__[\"CertCheckAgent\"](this.proxyInfo);\n                options.agent = checkAgent.GetAgent();\n                // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465\n                // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61\n                const uri = new URL(this.privUri);\n                let protocol = uri.protocol;\n                if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"wss:\") {\n                    protocol = \"https:\";\n                }\n                else if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"ws:\") {\n                    protocol = \"http:\";\n                }\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n                options.agent.protocol = protocol;\n                this.privWebsocketClient = new ws__WEBPACK_IMPORTED_MODULE_0___default.a(this.privUri, options);\n            }\n            this.privWebsocketClient.binaryType = \"arraybuffer\";\n            this.privReceivingMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Queue\"]();\n            this.privDisconnectDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n            this.privSendMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Queue\"]();\n            this.processSendQueue().catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BackgroundEvent\"](reason));\n            });\n        }\n        catch (error) {\n            this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionOpenResponse\"](500, error));\n            return this.privConnectionEstablishDeferral.promise;\n        }\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionStartEvent\"](this.privConnectionId, this.privUri));\n        this.privWebsocketClient.onopen = () => {\n            this.privCertificateValidatedDeferral.promise.then(() => {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connected;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionEstablishedEvent\"](this.privConnectionId));\n                this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionOpenResponse\"](200, \"\"));\n            }, (error) => {\n                this.privConnectionEstablishDeferral.reject(error);\n            });\n        };\n        this.privWebsocketClient.onerror = (e) => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionErrorEvent\"](this.privConnectionId, e.message, e.type));\n            this.privLastErrorReceived = e.message;\n        };\n        this.privWebsocketClient.onclose = (e) => {\n            if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connecting) {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Disconnected;\n                // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));\n                this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionOpenResponse\"](e.code, e.reason + \" \" + this.privLastErrorReceived));\n            }\n            else {\n                this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Disconnected;\n                this.privWebsocketClient = null;\n                this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionClosedEvent\"](this.privConnectionId, e.code, e.reason));\n            }\n            this.onClose(e.code, e.reason).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BackgroundEvent\"](reason));\n            });\n        };\n        this.privWebsocketClient.onmessage = (e) => {\n            const networkReceivedTime = new Date().toISOString();\n            if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connected) {\n                const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n                // let id = ++this.idCounter;\n                this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);\n                if (e.data instanceof ArrayBuffer) {\n                    const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RawWebsocketMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Binary, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageReceivedEvent\"](this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid binary message format. Error: ${error}`);\n                    });\n                }\n                else {\n                    const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RawWebsocketMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Text, e.data);\n                    this.privMessageFormatter\n                        .toConnectionMessage(rawMessage)\n                        .then((connectionMessage) => {\n                        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageReceivedEvent\"](this.privConnectionId, networkReceivedTime, connectionMessage));\n                        deferred.resolve(connectionMessage);\n                    }, (error) => {\n                        // TODO: Events for these ?\n                        deferred.reject(`Invalid text message format. Error: ${error}`);\n                    });\n                }\n            }\n        };\n        return this.privConnectionEstablishDeferral.promise;\n    }\n    send(message) {\n        if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connected) {\n            return Promise.reject(`Cannot send on connection that is in ${_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"][this.privConnectionState]} state`);\n        }\n        const messageSendStatusDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        const messageSendDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);\n        this.privMessageFormatter\n            .fromConnectionMessage(message)\n            .then((rawMessage) => {\n            messageSendDeferral.resolve({\n                Message: message,\n                RawWebsocketMessage: rawMessage,\n                sendStatusDeferral: messageSendStatusDeferral,\n            });\n        }, (error) => {\n            messageSendDeferral.reject(`Error formatting the message. ${error}`);\n        });\n        return messageSendStatusDeferral.promise;\n    }\n    read() {\n        if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Connected) {\n            return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);\n        }\n        return this.privReceivingMessageQueue.dequeue();\n    }\n    close(reason) {\n        if (this.privWebsocketClient) {\n            if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Disconnected) {\n                this.privWebsocketClient.close(1000, reason ? reason : \"Normal closure by client\");\n            }\n        }\n        else {\n            return Promise.resolve();\n        }\n        return this.privDisconnectDeferral.promise;\n    }\n    get events() {\n        return this.privConnectionEvents;\n    }\n    sendRawMessage(sendItem) {\n        try {\n            // indicates we are draining the queue and it came with no message;\n            if (!sendItem) {\n                return Promise.resolve();\n            }\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageSentEvent\"](this.privConnectionId, new Date().toISOString(), sendItem.Message));\n            // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing\n            if (this.isWebsocketOpen) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);\n            }\n            else {\n                return Promise.reject(\"websocket send error: Websocket not ready \" + this.privConnectionId + \" \" + sendItem.Message.id + \" \" + new Error().stack);\n            }\n            return Promise.resolve();\n        }\n        catch (e) {\n            return Promise.reject(`websocket send error: ${e}`);\n        }\n    }\n    onClose(code, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const closeReason = `Connection closed. ${code}: ${reason}`;\n            this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionState\"].Disconnected;\n            this.privDisconnectDeferral.resolve();\n            yield this.privReceivingMessageQueue.drainAndDispose(() => {\n                // TODO: Events for these ?\n                // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));\n            }, closeReason);\n            yield this.privSendMessageQueue.drainAndDispose((pendingSendItem) => {\n                pendingSendItem.sendStatusDeferral.reject(closeReason);\n            }, closeReason);\n        });\n    }\n    processSendQueue() {\n        return __awaiter(this, void 0, void 0, function* () {\n            while (true) {\n                const itemToSend = this.privSendMessageQueue.dequeue();\n                const sendItem = yield itemToSend;\n                // indicates we are draining the queue and it came with no message;\n                if (!sendItem) {\n                    return;\n                }\n                try {\n                    yield this.sendRawMessage(sendItem);\n                    sendItem.sendStatusDeferral.resolve();\n                }\n                catch (sendError) {\n                    sendItem.sendStatusDeferral.reject(sendError);\n                }\n            }\n        });\n    }\n    onEvent(event) {\n        this.privConnectionEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(event);\n    }\n    get isWebsocketOpen() {\n        return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;\n    }\n}\nWebsocketMessageAdapter.forceNpmWebSocket = false;\n\n//# sourceMappingURL=WebsocketMessageAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js ***!
  \***************************************************************************************************************/
/*! exports provided: AddedLmIntent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AddedLmIntent\", function() { return AddedLmIntent; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class AddedLmIntent\n */\n// eslint-disable-next-line max-classes-per-file\nclass AddedLmIntent {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param modelImpl - The model.\n     * @param intentName - The intent name.\n     */\n    constructor(modelImpl, intentName) {\n        this.modelImpl = modelImpl;\n        this.intentName = intentName;\n    }\n}\n\n//# sourceMappingURL=AddedLmIntent.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js ***!
  \*************************************************************************************************************/
/*! exports provided: AgentConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AgentConfig\", function() { return AgentConfig; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the agent.config message sent to the speech service.\n */\nclass AgentConfig {\n    toJsonString() {\n        return JSON.stringify(this.iPrivConfig);\n    }\n    get() {\n        return this.iPrivConfig;\n    }\n    /**\n     * Setter for the agent.config object.\n     * @param value a JSON serializable object.\n     */\n    set(value) {\n        this.iPrivConfig = value;\n    }\n}\n\n//# sourceMappingURL=AgentConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \****************************************************************************************************************************************/
/*! exports provided: CognitiveSubscriptionKeyAuthentication */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CognitiveSubscriptionKeyAuthentication\", function() { return CognitiveSubscriptionKeyAuthentication; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * @class\n */\nclass CognitiveSubscriptionKeyAuthentication {\n    /**\n     * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.\n     * @constructor\n     * @param {string} subscriptionKey - The subscription key\n     */\n    constructor(subscriptionKey) {\n        if (!subscriptionKey) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"subscriptionKey\");\n        }\n        this.privAuthInfo = new _IAuthentication__WEBPACK_IMPORTED_MODULE_2__[\"AuthInfo\"](_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].AuthKey, subscriptionKey);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetch(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n    /**\n     * Fetches the subscription key.\n     * @member\n     * @function\n     * @public\n     * @param {string} authFetchEventId - The id to fetch.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    fetchOnExpiry(authFetchEventId) {\n        return Promise.resolve(this.privAuthInfo);\n    }\n}\n\n//# sourceMappingURL=CognitiveSubscriptionKeyAuthentication.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js ***!
  \******************************************************************************************************************************/
/*! exports provided: CognitiveTokenAuthentication */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CognitiveTokenAuthentication\", function() { return CognitiveTokenAuthentication; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass CognitiveTokenAuthentication {\n    constructor(fetchCallback, fetchOnExpiryCallback) {\n        if (!fetchCallback) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"fetchCallback\");\n        }\n        if (!fetchOnExpiryCallback) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"fetchOnExpiryCallback\");\n        }\n        this.privFetchCallback = fetchCallback;\n        this.privFetchOnExpiryCallback = fetchOnExpiryCallback;\n    }\n    fetch(authFetchEventId) {\n        return this.privFetchCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__[\"AuthInfo\"](_HeaderNames__WEBPACK_IMPORTED_MODULE_2__[\"HeaderNames\"].Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n    fetchOnExpiry(authFetchEventId) {\n        return this.privFetchOnExpiryCallback(authFetchEventId).then((token) => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__[\"AuthInfo\"](_HeaderNames__WEBPACK_IMPORTED_MODULE_2__[\"HeaderNames\"].Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n    }\n}\nCognitiveTokenAuthentication.privTokenPrefix = \"bearer \";\n\n//# sourceMappingURL=CognitiveTokenAuthentication.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ConnectionFactoryBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionFactoryBase\", function() { return ConnectionFactoryBase; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass ConnectionFactoryBase {\n    static getHostSuffix(region) {\n        if (!!region) {\n            if (region.toLowerCase().startsWith(\"china\")) {\n                return \".azure.cn\";\n            }\n            if (region.toLowerCase().startsWith(\"usgov\")) {\n                return \".azure.us\";\n            }\n        }\n        return \".microsoft.com\";\n    }\n    setCommonUrlParams(config, queryParams, endpoint) {\n        const propertyIdToParameterMap = new Map([\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].Speech_SegmentationSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].SegmentationSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_EnableAudioLogging, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].EnableAudioLogging],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_EndSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].EndSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_InitialSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].InitialSilenceTimeoutMs],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_PostProcessingOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].Postprocessing],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_ProfanityOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].Profanity],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_RequestWordLevelTimestamps, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].EnableWordLevelTimestamps],\n            [_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_StablePartialResultThreshold, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__[\"QueryParameterNames\"].StableIntermediateThreshold],\n        ]);\n        propertyIdToParameterMap.forEach((parameterName, propertyId) => {\n            this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);\n        });\n        const serviceProperties = JSON.parse(config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServicePropertiesPropertyName\"], \"{}\"));\n        Object.keys(serviceProperties).forEach((value) => {\n            queryParams[value] = serviceProperties[value];\n        });\n    }\n    setUrlParameter(propId, parameterName, config, queryParams, endpoint) {\n        const value = config.parameters.getProperty(propId, undefined);\n        if (value && (!endpoint || endpoint.search(parameterName) === -1)) {\n            queryParams[parameterName] = value.toLocaleLowerCase();\n        }\n    }\n}\n\n//# sourceMappingURL=ConnectionFactoryBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js ***!
  \************************************************************************************************************************/
/*! exports provided: DialogConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogConnectionFactory\", function() { return DialogConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n\n\nclass DialogConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__[\"ConnectionFactoryBase\"] {\n    create(config, authInfo, connectionId) {\n        const applicationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, \"\");\n        const dialogType = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region);\n        const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, \"en-US\");\n        const requestTurnStatus = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_Request_Bot_Status_Messages, \"true\");\n        const queryParams = {};\n        queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormatPropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"].Simple]).toLowerCase();\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Language] = language;\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].RequestBotStatusMessages] = requestTurnStatus;\n        if (applicationId) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].BotId] = applicationId;\n            if (dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConfig\"].DialogTypes.CustomCommands) {\n                queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].CustomCommandsAppId] = applicationId;\n            }\n        }\n        const resourceInfix = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConfig\"].DialogTypes.CustomCommands ? \"commands/\"\n            : \"\";\n        const version = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConfig\"].DialogTypes.CustomCommands ? \"v1\"\n            : dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"DialogServiceConfig\"].DialogTypes.BotFramework ? \"v3\"\n                : \"v0\";\n        const headers = {};\n        if (authInfo.token != null && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        // The URL used for connection is chosen in a priority order of specification:\n        //  1. If a custom endpoint is provided, that URL is used verbatim.\n        //  2. If a custom host is provided (e.g. \"wss://my.custom.endpoint.com:1123\"), a URL is constructed from it.\n        //  3. If no custom connection details are provided, a URL is constructed from default values.\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint, \"\");\n        if (!endpoint) {\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);\n            const standardizedHost = host.endsWith(\"/\") ? host : host + \"/\";\n            endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\nDialogConnectionFactory.ApiKey = \"api\";\nDialogConnectionFactory.BaseUrl = \"convai.speech\";\n\n//# sourceMappingURL=DialogConnectorFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js ***!
  \**********************************************************************************************************************/
/*! exports provided: DialogServiceAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceAdapter\", function() { return DialogServiceAdapter; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_DialogEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/DialogEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./DialogServiceTurnStateManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n\n\nclass DialogServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_6__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"EventSource\"]();\n        this.privDialogServiceConnector = dialogServiceConnector;\n        this.receiveMessageOverride = () => this.receiveDialogMessageOverride();\n        this.privTurnStateManager = new _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_5__[\"DialogServiceTurnStateManager\"]();\n        this.recognizeOverride =\n            (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);\n        this.postConnectImplOverride = (connection) => this.dialogConnectImpl(connection);\n        this.configConnectionOverride = (connection) => this.configConnection(connection);\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privDialogAudioSource = audioSource;\n        this.agentConfigSent = false;\n        this.privLastResult = null;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                this.terminateMessageLoop = true;\n            }\n        });\n    }\n    sendMessage(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const interactionGuid = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"createGuid\"])();\n            const requestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"createNoDashGuid\"])();\n            const agentMessage = {\n                context: {\n                    interactionId: interactionGuid\n                },\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                messagePayload: JSON.parse(message),\n                version: 0.5\n            };\n            const agentMessageJson = JSON.stringify(agentMessage);\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Text, \"agent\", requestId, \"application/json\", agentMessageJson));\n        });\n    }\n    privDisconnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationErrorCode\"].NoError, \"Disconnecting\");\n            this.terminateMessageLoop = true;\n            this.agentConfigSent = false;\n            return;\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyCollection\"]();\n        if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Text) {\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        let result;\n        let processed;\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.phrase\":\n                const speechPhrase = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SimpleSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);\n                if (speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionStatus\"].TooManyRequests && speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionStatus\"].Error) {\n                    const args = this.fireEventForResult(speechPhrase, resultProps);\n                    this.privLastResult = args.result;\n                    if (!!this.privDialogServiceConnector.recognized) {\n                        try {\n                            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.hypothesis\":\n                const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SpeechHypothesis\"].fromJSON(connectionMessage.textBody);\n                const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"ResultReason\"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);\n                this.privRequestSession.onHypothesis(offset);\n                const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionEventArgs\"](result, hypothesis.Duration, this.privRequestSession.sessionId);\n                if (!!this.privDialogServiceConnector.recognizing) {\n                    try {\n                        this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.keyword\":\n                const keyword = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SpeechKeyword\"].fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, keyword.Status === \"Accepted\" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"ResultReason\"].RecognizedKeyword : _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"ResultReason\"].NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);\n                if (keyword.Status !== \"Accepted\") {\n                    this.privLastResult = result;\n                }\n                const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionEventArgs\"](result, result.duration, result.resultId);\n                if (!!this.privDialogServiceConnector.recognized) {\n                    try {\n                        this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"audio\":\n                {\n                    const audioRequestId = connectionMessage.requestId.toUpperCase();\n                    const turn = this.privTurnStateManager.GetTurn(audioRequestId);\n                    try {\n                        // Empty binary message signals end of stream.\n                        if (!connectionMessage.binaryBody) {\n                            turn.endAudioStream();\n                        }\n                        else {\n                            turn.audioStream.write(connectionMessage.binaryBody);\n                        }\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"response\":\n                {\n                    this.handleResponseMessage(connectionMessage);\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.terminateMessageLoop = true;\n            if (!!this.privRequestSession.isRecognizing) {\n                yield this.privRequestSession.onStopRecognizing();\n            }\n            if (!!this.privDialogServiceConnector.canceled) {\n                const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyCollection\"]();\n                properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationErrorCode\"][errorCode]);\n                const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionCanceledEventArgs\"](cancellationReason, error, errorCode, undefined, sessionId);\n                try {\n                    this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);\n                    /* eslint-disable no-empty */\n                }\n                catch (_a) { }\n                if (!!this.privSuccessCallback) {\n                    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionResult\"](undefined, // ResultId\n                    _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"ResultReason\"].Canceled, undefined, // Text\n                    undefined, // Duration\n                    undefined, // Offset\n                    undefined, // Language\n                    undefined, // Language Detection Confidence\n                    undefined, // Speaker Id\n                    error, undefined, // Json\n                    properties);\n                    try {\n                        this.privSuccessCallback(result);\n                        this.privSuccessCallback = undefined;\n                        /* eslint-disable no-empty */\n                    }\n                    catch (_b) { }\n                }\n            }\n        });\n    }\n    listenOnce(recoMode, successCallback, errorCallback) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privRecognizerConfig.recognitionMode = recoMode;\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallback;\n            this.privRequestSession.startNewRecognition();\n            this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);\n            this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].Speech_SessionId, this.privRequestSession.sessionId);\n            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n            const conPromise = this.connectImpl();\n            const preAudioPromise = this.sendPreAudioMessages();\n            const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);\n            const format = yield this.privDialogAudioSource.format;\n            const deviceInfo = yield this.privDialogAudioSource.deviceInfo;\n            const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ReplayableAudioNode\"](node, format.avgBytesPerSec);\n            yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n            this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n            try {\n                yield conPromise;\n                yield preAudioPromise;\n            }\n            catch (error) {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationErrorCode\"].ConnectionFailure, error);\n                return Promise.resolve();\n            }\n            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SessionEventArgs\"](this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.sessionStarted) {\n                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n            }\n            const audioSendPromise = this.sendAudio(audioNode);\n            // /* eslint-disable no-empty */\n            audioSendPromise.then(() => { }, (error) => __awaiter(this, void 0, void 0, function* () {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationErrorCode\"].RuntimeError, error);\n            }));\n        });\n    }\n    // Establishes a websocket connection to the end point.\n    dialogConnectImpl(connection) {\n        this.privConnectionLoop = this.startMessageLoop();\n        return connection;\n    }\n    receiveDialogMessageOverride() {\n        // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n        const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        const loop = () => __awaiter(this, void 0, void 0, function* () {\n            try {\n                const isDisposed = this.isDisposed();\n                const terminateMessageLoop = (!this.isDisposed() && this.terminateMessageLoop);\n                if (isDisposed || terminateMessageLoop) {\n                    // We're done.\n                    communicationCustodian.resolve(undefined);\n                    return;\n                }\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (!message) {\n                    return loop();\n                }\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__[\"SpeechConnectionMessage\"].fromConnectionMessage(message);\n                switch (connectionMessage.path.toLowerCase()) {\n                    case \"turn.start\":\n                        {\n                            const turnRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.StartTurn(turnRequestId);\n                            }\n                            else {\n                                this.privRequestSession.onServiceTurnStartResponse();\n                            }\n                        }\n                        break;\n                    case \"speech.startdetected\":\n                        const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SpeechDetected\"].fromJSON(connectionMessage.textBody);\n                        const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"RecognitionEventArgs\"](speechStartDetected.Offset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechStartDetected) {\n                            this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                        }\n                        break;\n                    case \"speech.enddetected\":\n                        let json;\n                        if (connectionMessage.textBody.length > 0) {\n                            json = connectionMessage.textBody;\n                        }\n                        else {\n                            // If the request was empty, the JSON returned is empty.\n                            json = \"{ Offset: 0 }\";\n                        }\n                        const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SpeechDetected\"].fromJSON(json);\n                        this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n                        const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"RecognitionEventArgs\"](speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                        if (!!this.privRecognizer.speechEndDetected) {\n                            this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                        }\n                        break;\n                    case \"turn.end\":\n                        {\n                            const turnEndRequestId = connectionMessage.requestId.toUpperCase();\n                            const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n                            // turn started by the service\n                            if (turnEndRequestId !== audioSessionReqId) {\n                                this.privTurnStateManager.CompleteTurn(turnEndRequestId);\n                            }\n                            else {\n                                // Audio session turn\n                                const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SessionEventArgs\"](this.privRequestSession.sessionId);\n                                yield this.privRequestSession.onServiceTurnEndResponse(false);\n                                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                                    if (!!this.privRecognizer.sessionStopped) {\n                                        this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                                    }\n                                }\n                                // report result to promise.\n                                if (!!this.privSuccessCallback && this.privLastResult) {\n                                    try {\n                                        this.privSuccessCallback(this.privLastResult);\n                                        this.privLastResult = null;\n                                    }\n                                    catch (e) {\n                                        if (!!this.privErrorCallback) {\n                                            this.privErrorCallback(e);\n                                        }\n                                    }\n                                    // Only invoke the call back once.\n                                    // and if it's successful don't invoke the\n                                    // error after that.\n                                    this.privSuccessCallback = undefined;\n                                    this.privErrorCallback = undefined;\n                                }\n                            }\n                        }\n                        break;\n                    default:\n                        try {\n                            const processed = yield this.processTypeSpecificMessages(connectionMessage);\n                            if (!processed) {\n                                if (!!this.serviceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceEvent\"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                        }\n                        catch (e) {\n                            //\n                        }\n                }\n                const ret = loop();\n                return ret;\n            }\n            catch (error) {\n                this.terminateMessageLoop = true;\n                communicationCustodian.resolve();\n            }\n        });\n        loop().catch((reason) => {\n            _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BackgroundEvent\"](reason));\n        });\n        return communicationCustodian.promise;\n    }\n    startMessageLoop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.terminateMessageLoop = false;\n            try {\n                yield this.receiveDialogMessageOverride();\n            }\n            catch (error) {\n                yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"CancellationErrorCode\"].RuntimeError, error);\n            }\n            return Promise.resolve();\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configConnection(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.terminateMessageLoop) {\n                this.terminateMessageLoop = false;\n                return Promise.reject(\"Connection to service terminated.\");\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n            yield this.sendAgentConfig(connection);\n            return connection;\n        });\n    }\n    sendPreAudioMessages() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            this.addKeywordContextData();\n            yield this.sendSpeechContext(connection, true);\n            yield this.sendAgentContext(connection);\n            yield this.sendWaveHeader(connection);\n        });\n    }\n    sendAgentConfig(connection) {\n        if (this.agentConfig && !this.agentConfigSent) {\n            if (this.privRecognizerConfig\n                .parameters\n                .getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].Conversation_DialogType) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"DialogServiceConfig\"].DialogTypes.CustomCommands) {\n                const config = this.agentConfig.get();\n                config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, \"en-us\");\n                this.agentConfig.set(config);\n            }\n            this.onEvent(new _common_DialogEvents__WEBPACK_IMPORTED_MODULE_1__[\"SendingAgentContextMessageEvent\"](this.agentConfig));\n            const agentConfigJson = this.agentConfig.toJsonString();\n            // guard against sending this multiple times on one connection\n            this.agentConfigSent = true;\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Text, \"agent.config\", this.privRequestSession.requestId, \"application/json\", agentConfigJson));\n        }\n        return;\n    }\n    sendAgentContext(connection) {\n        const guid = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"createGuid\"])();\n        const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].Conversation_Speech_Activity_Template);\n        const agentContext = {\n            channelData: \"\",\n            context: {\n                interactionId: guid\n            },\n            messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,\n            version: 0.5\n        };\n        const agentContextJson = JSON.stringify(agentContext);\n        return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"].Text, \"speech.agent.context\", this.privRequestSession.requestId, \"application/json\", agentContextJson));\n    }\n    fireEventForResult(serviceResult, properties) {\n        const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_6__[\"EnumTranslation\"].implTranslateRecognitionResult(serviceResult.RecognitionStatus);\n        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);\n        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"SpeechRecognitionEventArgs\"](result, offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    handleResponseMessage(responseMessage) {\n        // \"response\" messages can contain either \"message\" (activity) or \"MessageStatus\" data. Fire the appropriate\n        // event according to the message type that's specified.\n        const responsePayload = JSON.parse(responseMessage.textBody);\n        switch (responsePayload.messageType.toLowerCase()) {\n            case \"message\":\n                const responseRequestId = responseMessage.requestId.toUpperCase();\n                const activityPayload = _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_7__[\"ActivityPayloadResponse\"].fromJSON(responseMessage.textBody);\n                const turn = this.privTurnStateManager.GetTurn(responseRequestId);\n                // update the conversation Id\n                if (activityPayload.conversationId) {\n                    const updateAgentConfig = this.agentConfig.get();\n                    updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;\n                    this.agentConfig.set(updateAgentConfig);\n                }\n                const pullAudioOutputStream = turn.processActivityPayload(activityPayload, _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioOutputFormatImpl\"].fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, undefined)));\n                const activity = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"ActivityReceivedEventArgs\"](activityPayload.messagePayload, pullAudioOutputStream);\n                if (!!this.privDialogServiceConnector.activityReceived) {\n                    try {\n                        this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            case \"messagestatus\":\n                if (!!this.privDialogServiceConnector.turnStatusReceived) {\n                    try {\n                        this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__[\"TurnStatusReceivedEventArgs\"](responseMessage.textBody));\n                        /* eslint-disable-next-line no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                break;\n            default:\n                _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"BackgroundEvent\"](`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));\n                break;\n        }\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Events\"].instance.onEvent(event);\n    }\n    addKeywordContextData() {\n        const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect\");\n        if (keywordPropertyValue === undefined) {\n            return;\n        }\n        const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Offsets\");\n        const keywordDurationPropertyValue = this.privRecognizerConfig.parameters\n            .getProperty(\"SPEECH-KeywordsToDetect-Durations\");\n        const keywords = keywordPropertyValue.split(\";\");\n        const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(\";\");\n        const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(\";\");\n        const keywordDefinitionArray = [];\n        for (let i = 0; i < keywords.length; i++) {\n            const definition = {};\n            definition.text = keywords[i];\n            if (i < keywordOffsets.length) {\n                definition.offset = Number(keywordOffsets[i]);\n            }\n            if (i < keywordDurations.length) {\n                definition.duration = Number(keywordDurations[i]);\n            }\n            keywordDefinitionArray.push(definition);\n        }\n        this.speechContext.setSection(\"invocationSource\", \"VoiceActivationWithKeyword\");\n        this.speechContext.setSection(\"keywordDetection\", [{\n                clientDetectedKeywords: keywordDefinitionArray,\n                onReject: { action: \"EndOfTurn\" },\n                type: \"startTrigger\"\n            }]);\n    }\n}\n\n//# sourceMappingURL=DialogServiceAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js ***!
  \************************************************************************************************************************/
/*! exports provided: DialogServiceTurnState */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceTurnState\", function() { return DialogServiceTurnState; });\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass DialogServiceTurnState {\n    constructor(manager, requestId) {\n        this.privRequestId = requestId;\n        this.privIsCompleted = false;\n        this.privAudioStream = null;\n        this.privTurnManager = manager;\n        this.resetTurnEndTimeout();\n    }\n    get audioStream() {\n        // Called when is needed to stream.\n        this.resetTurnEndTimeout();\n        return this.privAudioStream;\n    }\n    processActivityPayload(payload, audioFormat) {\n        if (payload.messageDataStreamType === _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_2__[\"MessageDataStreamType\"].TextToSpeechAudio) {\n            this.privAudioStream = _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__[\"AudioOutputStream\"].createPullStream();\n            this.privAudioStream.format = (audioFormat !== undefined) ? audioFormat : _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"AudioOutputFormatImpl\"].getDefaultOutputFormat();\n        }\n        return this.privAudioStream;\n    }\n    endAudioStream() {\n        if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {\n            this.privAudioStream.close();\n        }\n    }\n    complete() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.endAudioStream();\n    }\n    resetTurnEndTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = setTimeout(() => {\n            this.privTurnManager.CompleteTurn(this.privRequestId);\n            return;\n        }, 2000);\n    }\n}\n\n//# sourceMappingURL=DialogServiceTurnState.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: DialogServiceTurnStateManager */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceTurnStateManager\", function() { return DialogServiceTurnStateManager; });\n/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceTurnState */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass DialogServiceTurnStateManager {\n    constructor() {\n        this.privTurnMap = new Map();\n        return;\n    }\n    StartTurn(id) {\n        if (this.privTurnMap.has(id)) {\n            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Service error: There is already a turn with id:\" + id);\n        }\n        const turnState = new _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceTurnState\"](this, id);\n        this.privTurnMap.set(id, turnState);\n        return this.privTurnMap.get(id);\n    }\n    GetTurn(id) {\n        return this.privTurnMap.get(id);\n    }\n    CompleteTurn(id) {\n        if (!this.privTurnMap.has(id)) {\n            throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Service error: Received turn end for an unknown turn id:\" + id);\n        }\n        const turnState = this.privTurnMap.get(id);\n        turnState.complete();\n        this.privTurnMap.delete(id);\n        return turnState;\n    }\n}\n\n//# sourceMappingURL=DialogServiceTurnStateManager.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js ***!
  \***********************************************************************************************************************/
/*! exports provided: DynamicGrammarBuilder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DynamicGrammarBuilder\", function() { return DynamicGrammarBuilder; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Responsible for building the object to be sent to the speech service to support dynamic grammars.\n * @class DynamicGrammarBuilder\n */\nclass DynamicGrammarBuilder {\n    // Adds one more reference phrases to the dynamic grammar to send.\n    // All added phrases are generic phrases.\n    addPhrase(phrase) {\n        if (!this.privPhrases) {\n            this.privPhrases = [];\n        }\n        if (phrase instanceof Array) {\n            this.privPhrases = this.privPhrases.concat(phrase);\n        }\n        else {\n            this.privPhrases.push(phrase);\n        }\n    }\n    // Clears all phrases stored in the current object.\n    clearPhrases() {\n        this.privPhrases = undefined;\n    }\n    // Adds one or more reference grammars to the current grammar.\n    addReferenceGrammar(grammar) {\n        if (!this.privGrammars) {\n            this.privGrammars = [];\n        }\n        if (grammar instanceof Array) {\n            this.privGrammars = this.privGrammars.concat(grammar);\n        }\n        else {\n            this.privGrammars.push(grammar);\n        }\n    }\n    // clears all grammars stored on the recognizer.\n    clearGrammars() {\n        this.privGrammars = undefined;\n    }\n    // Generates an object that represents the dynamic grammar used by the Speech Service.\n    // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance\n    // of a DynamicGrammarBuilder\n    generateGrammarObject() {\n        if (this.privGrammars === undefined && this.privPhrases === undefined) {\n            return undefined;\n        }\n        const retObj = {};\n        retObj.ReferenceGrammars = this.privGrammars;\n        if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {\n            const retPhrases = [];\n            this.privPhrases.forEach((value) => {\n                retPhrases.push({\n                    Text: value,\n                });\n            });\n            retObj.Groups = [{ Type: \"Generic\", Items: retPhrases }];\n        }\n        return retObj;\n    }\n}\n\n//# sourceMappingURL=DynamicGrammarBuilder.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js ***!
  \**************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=DynamicGrammarInterfaces.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js ***!
  \*****************************************************************************************************************/
/*! exports provided: EnumTranslation */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"EnumTranslation\", function() { return EnumTranslation; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EnumTranslation {\n    static implTranslateRecognitionResult(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].Canceled;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Success:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].RecognizedSpeech;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].NoMatch:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].InitialSilenceTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].BabbleTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].EndOfDictation:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].NoMatch;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Error:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].BadRequest:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Forbidden:\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].Canceled;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelResult(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationReason\"].EndOfStream;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Success:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].EndOfDictation:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].NoMatch:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationReason\"].EndOfStream;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].InitialSilenceTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].BabbleTimeout:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Error:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].BadRequest:\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Forbidden:\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationReason\"].Error;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateCancelErrorCode(recognitionStatus) {\n        let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].NoError;\n        switch (recognitionStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Error:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].ServiceError;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].TooManyRequests:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].TooManyRequests;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].BadRequest:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].BadRequestParameters;\n                break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Forbidden:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].Forbidden;\n                break;\n            default:\n                reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].NoError;\n                break;\n        }\n        return reason;\n    }\n    static implTranslateErrorDetails(cancellationErrorCode) {\n        let errorDetails = \"The speech service encountered an internal error and could not continue.\";\n        switch (cancellationErrorCode) {\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].Forbidden:\n                errorDetails = \"The recognizer is using a free subscription that ran out of quota.\";\n                break;\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].BadRequestParameters:\n                errorDetails = \"Invalid parameter or unsupported audio format in the request.\";\n                break;\n            case _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"].TooManyRequests:\n                errorDetails = \"The number of parallel requests exceeded the number of allowed concurrent transcriptions.\";\n                break;\n            default:\n                break;\n        }\n        return errorDetails;\n    }\n}\n\n//# sourceMappingURL=EnumTranslation.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js ***!
  \*********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OutputFormatPropertyName\", function() { return OutputFormatPropertyName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationErrorCodePropertyName\", function() { return CancellationErrorCodePropertyName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServicePropertiesPropertyName\", function() { return ServicePropertiesPropertyName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ForceDictationPropertyName\", function() { return ForceDictationPropertyName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguagesOpenRangeOptionName\", function() { return AutoDetectSourceLanguagesOpenRangeOptionName; });\n/* harmony import */ var _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CognitiveSubscriptionKeyAuthentication\", function() { return _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__[\"CognitiveSubscriptionKeyAuthentication\"]; });\n\n/* harmony import */ var _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CognitiveTokenAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CognitiveTokenAuthentication\", function() { return _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__[\"CognitiveTokenAuthentication\"]; });\n\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AuthInfo\", function() { return _IAuthentication__WEBPACK_IMPORTED_MODULE_2__[\"AuthInfo\"]; });\n\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./IConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js\");\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__) if([\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ISynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js\");\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__) if([\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./IntentConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentConnectionFactory\", function() { return _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__[\"IntentConnectionFactory\"]; });\n\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"SpeechRecognitionEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionTriggeredEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionTriggeredEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ListeningStartedEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"ListeningStartedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectingToServiceEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"ConnectingToServiceEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionStartedEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionStartedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionCompletionStatus\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionCompletionStatus\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionEndedEvent\", function() { return _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__[\"RecognitionEndedEvent\"]; });\n\n/* harmony import */ var _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceRecognizerBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServiceRecognizerBase\", function() { return _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__[\"ServiceRecognizerBase\"]; });\n\n/* harmony import */ var _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./RecognizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionMode\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"RecognitionMode\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechResultFormat\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"SpeechResultFormat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognizerConfig\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"RecognizerConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechServiceConfig\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"SpeechServiceConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Context\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"Context\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"System\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"System\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OS\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"OS\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Device\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"Device\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"connectivity\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"connectivity\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"type\", function() { return _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__[\"type\"]; });\n\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SpeechServiceInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js\");\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__) if([\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"SpeechRecognitionEvent\",\"RecognitionTriggeredEvent\",\"ListeningStartedEvent\",\"ConnectingToServiceEvent\",\"RecognitionStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"ServiceRecognizerBase\",\"RecognitionMode\",\"SpeechResultFormat\",\"RecognizerConfig\",\"SpeechServiceConfig\",\"Context\",\"System\",\"OS\",\"Device\",\"connectivity\",\"type\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./WebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"WebsocketMessageFormatter\", function() { return _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__[\"WebsocketMessageFormatter\"]; });\n\n/* harmony import */ var _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./SpeechConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechConnectionFactory\", function() { return _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__[\"SpeechConnectionFactory\"]; });\n\n/* harmony import */ var _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./TranscriberConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranscriberConnectionFactory\", function() { return _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__[\"TranscriberConnectionFactory\"]; });\n\n/* harmony import */ var _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./TranslationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationConnectionFactory\", function() { return _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__[\"TranslationConnectionFactory\"]; });\n\n/* harmony import */ var _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechSynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisConnectionFactory\", function() { return _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__[\"SpeechSynthesisConnectionFactory\"]; });\n\n/* harmony import */ var _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./EnumTranslation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"EnumTranslation\", function() { return _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__[\"EnumTranslation\"]; });\n\n/* harmony import */ var _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./ServiceMessages/Enums */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisStatus\", function() { return _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__[\"SynthesisStatus\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionStatus\", function() { return _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__[\"RecognitionStatus\"]; });\n\n/* harmony import */ var _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisEnd\", function() { return _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__[\"TranslationSynthesisEnd\"]; });\n\n/* harmony import */ var _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./ServiceMessages/TranslationHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationHypothesis\", function() { return _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__[\"TranslationHypothesis\"]; });\n\n/* harmony import */ var _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./ServiceMessages/TranslationPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationPhrase\", function() { return _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__[\"TranslationPhrase\"]; });\n\n/* harmony import */ var _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationServiceRecognizer\", function() { return _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__[\"TranslationServiceRecognizer\"]; });\n\n/* harmony import */ var _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./ServiceMessages/SpeechDetected */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechDetected\", function() { return _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__[\"SpeechDetected\"]; });\n\n/* harmony import */ var _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ServiceMessages/SpeechHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechHypothesis\", function() { return _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__[\"SpeechHypothesis\"]; });\n\n/* harmony import */ var _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./ServiceMessages/SpeechKeyword */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechKeyword\", function() { return _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__[\"SpeechKeyword\"]; });\n\n/* harmony import */ var _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechServiceRecognizer\", function() { return _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__[\"SpeechServiceRecognizer\"]; });\n\n/* harmony import */ var _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./TranscriptionServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranscriptionServiceRecognizer\", function() { return _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__[\"TranscriptionServiceRecognizer\"]; });\n\n/* harmony import */ var _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetailedSpeechPhrase\", function() { return _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__[\"DetailedSpeechPhrase\"]; });\n\n/* harmony import */ var _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SimpleSpeechPhrase\", function() { return _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__[\"SimpleSpeechPhrase\"]; });\n\n/* harmony import */ var _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./AddedLmIntent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AddedLmIntent\", function() { return _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__[\"AddedLmIntent\"]; });\n\n/* harmony import */ var _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentServiceRecognizer\", function() { return _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__[\"IntentServiceRecognizer\"]; });\n\n/* harmony import */ var _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/IntentResponse */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentResponse\", function() { return _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__[\"IntentResponse\"]; });\n\n/* harmony import */ var _RequestSession__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./RequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RequestSession\", function() { return _RequestSession__WEBPACK_IMPORTED_MODULE_31__[\"RequestSession\"]; });\n\n/* harmony import */ var _SpeechContext__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./SpeechContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechContext\", function() { return _SpeechContext__WEBPACK_IMPORTED_MODULE_32__[\"SpeechContext\"]; });\n\n/* harmony import */ var _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./DynamicGrammarBuilder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DynamicGrammarBuilder\", function() { return _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__[\"DynamicGrammarBuilder\"]; });\n\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./DynamicGrammarInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js\");\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34___default = /*#__PURE__*/__webpack_require__.n(_DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__) if([\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"SpeechRecognitionEvent\",\"RecognitionTriggeredEvent\",\"ListeningStartedEvent\",\"ConnectingToServiceEvent\",\"RecognitionStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"ServiceRecognizerBase\",\"RecognitionMode\",\"SpeechResultFormat\",\"RecognizerConfig\",\"SpeechServiceConfig\",\"Context\",\"System\",\"OS\",\"Device\",\"connectivity\",\"type\",\"WebsocketMessageFormatter\",\"SpeechConnectionFactory\",\"TranscriberConnectionFactory\",\"TranslationConnectionFactory\",\"SpeechSynthesisConnectionFactory\",\"EnumTranslation\",\"SynthesisStatus\",\"RecognitionStatus\",\"TranslationSynthesisEnd\",\"TranslationHypothesis\",\"TranslationPhrase\",\"TranslationServiceRecognizer\",\"SpeechDetected\",\"SpeechHypothesis\",\"SpeechKeyword\",\"SpeechServiceRecognizer\",\"TranscriptionServiceRecognizer\",\"DetailedSpeechPhrase\",\"SimpleSpeechPhrase\",\"AddedLmIntent\",\"IntentServiceRecognizer\",\"IntentResponse\",\"RequestSession\",\"SpeechContext\",\"DynamicGrammarBuilder\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./DialogServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceAdapter\", function() { return _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__[\"DialogServiceAdapter\"]; });\n\n/* harmony import */ var _AgentConfig__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./AgentConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AgentConfig\", function() { return _AgentConfig__WEBPACK_IMPORTED_MODULE_36__[\"AgentConfig\"]; });\n\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationManager\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationManager\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationConnectionConfig\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationConnectionConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationRecognizerFactory\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationRecognizerFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranscriberRecognizer\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"TranscriberRecognizer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationReceivedTranslationEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationReceivedTranslationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LockRoomEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"LockRoomEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MuteAllEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"MuteAllEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantAttributeEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ParticipantAttributeEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ParticipantEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantsListEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ParticipantsListEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorCommandTypes\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationTranslatorCommandTypes\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorMessageTypes\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"ConversationTranslatorMessageTypes\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"InternalParticipants\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__[\"InternalParticipants\"]; });\n\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MetadataType\", function() { return _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__[\"MetadataType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisAudioMetadata\", function() { return _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__[\"SynthesisAudioMetadata\"]; });\n\n/* harmony import */ var _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./SynthesisTurn */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisTurn\", function() { return _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__[\"SynthesisTurn\"]; });\n\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisAdapterBase\", function() { return _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__[\"SynthesisAdapterBase\"]; });\n\n/* harmony import */ var _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./SynthesisRestAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisRestAdapter\", function() { return _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_41__[\"SynthesisRestAdapter\"]; });\n\n/* harmony import */ var _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./SynthesizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisServiceType\", function() { return _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__[\"SynthesisServiceType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesizerConfig\", function() { return _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__[\"SynthesizerConfig\"]; });\n\n/* harmony import */ var _SynthesisContext__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./SynthesisContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisContext\", function() { return _SynthesisContext__WEBPACK_IMPORTED_MODULE_43__[\"SynthesisContext\"]; });\n\n/* harmony import */ var _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./SpeakerRecognitionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionConfig\", function() { return _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_44__[\"SpeakerRecognitionConfig\"]; });\n\n/* harmony import */ var _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./SpeakerIdMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerIdMessageAdapter\", function() { return _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_45__[\"SpeakerIdMessageAdapter\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Make sure not to export internal modules.\n//\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst OutputFormatPropertyName = \"OutputFormat\";\nconst CancellationErrorCodePropertyName = \"CancellationErrorCode\";\nconst ServicePropertiesPropertyName = \"ServiceProperties\";\nconst ForceDictationPropertyName = \"ForceDictation\";\nconst AutoDetectSourceLanguagesOpenRangeOptionName = \"OpenRange\";\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js ***!
  \*************************************************************************************************************/
/*! exports provided: HeaderNames */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"HeaderNames\", function() { return HeaderNames; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass HeaderNames {\n}\nHeaderNames.AuthKey = \"Ocp-Apim-Subscription-Key\";\nHeaderNames.Authorization = \"Authorization\";\nHeaderNames.ConnectionId = \"X-ConnectionId\";\nHeaderNames.ContentType = \"Content-Type\";\nHeaderNames.CustomCommandsAppId = \"X-CommandsAppId\";\nHeaderNames.Path = \"Path\";\nHeaderNames.RequestId = \"X-RequestId\";\nHeaderNames.RequestStreamId = \"X-StreamId\";\nHeaderNames.RequestTimestamp = \"X-Timestamp\";\n\n//# sourceMappingURL=HeaderNames.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js ***!
  \*****************************************************************************************************************/
/*! exports provided: AuthInfo */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AuthInfo\", function() { return AuthInfo; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass AuthInfo {\n    constructor(headerName, token) {\n        this.privHeaderName = headerName;\n        this.privToken = token;\n    }\n    get headerName() {\n        return this.privHeaderName;\n    }\n    get token() {\n        return this.privToken;\n    }\n}\n\n//# sourceMappingURL=IAuthentication.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js ***!
  \********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js ***!
  \*****************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=ISynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js ***!
  \*************************************************************************************************************************/
/*! exports provided: IntentConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentConnectionFactory\", function() { return IntentConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\nclass IntentConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"] {\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_IntentRegion);\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, \"wss://\" + region + \".sr.speech\" + hostSuffix);\n            endpoint = host + \"/speech/recognition/interactive/cognitiveservices/v1\";\n        }\n        const queryParams = {\n            format: \"simple\",\n            language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage),\n        };\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n    getSpeechRegionFromIntentRegion(intentRegion) {\n        switch (intentRegion) {\n            case \"West US\":\n            case \"US West\":\n            case \"westus\":\n                return \"uswest\";\n            case \"West US 2\":\n            case \"US West 2\":\n            case \"westus2\":\n                return \"uswest2\";\n            case \"South Central US\":\n            case \"US South Central\":\n            case \"southcentralus\":\n                return \"ussouthcentral\";\n            case \"West Central US\":\n            case \"US West Central\":\n            case \"westcentralus\":\n                return \"uswestcentral\";\n            case \"East US\":\n            case \"US East\":\n            case \"eastus\":\n                return \"useast\";\n            case \"East US 2\":\n            case \"US East 2\":\n            case \"eastus2\":\n                return \"useast2\";\n            case \"West Europe\":\n            case \"Europe West\":\n            case \"westeurope\":\n                return \"europewest\";\n            case \"North Europe\":\n            case \"Europe North\":\n            case \"northeurope\":\n                return \"europenorth\";\n            case \"Brazil South\":\n            case \"South Brazil\":\n            case \"southbrazil\":\n                return \"brazilsouth\";\n            case \"Australia East\":\n            case \"East Australia\":\n            case \"eastaustralia\":\n                return \"australiaeast\";\n            case \"Southeast Asia\":\n            case \"Asia Southeast\":\n            case \"southeastasia\":\n                return \"asiasoutheast\";\n            case \"East Asia\":\n            case \"Asia East\":\n            case \"eastasia\":\n                return \"asiaeast\";\n            default:\n                return intentRegion;\n        }\n    }\n}\n\n//# sourceMappingURL=IntentConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/*! exports provided: IntentServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentServiceRecognizer\", function() { return IntentServiceRecognizer; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass IntentServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n        this.privIntentRecognizer = recognizer;\n        this.privIntentDataSent = false;\n    }\n    setIntents(addedIntents, umbrellaIntent) {\n        this.privAddedLmIntents = addedIntents;\n        this.privUmbrellaIntent = umbrellaIntent;\n        this.privIntentDataSent = true;\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        let result;\n        let ev;\n        let processed = false;\n        const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n        }\n        switch (connectionMessage.path.toLowerCase()) {\n            case \"speech.hypothesis\":\n                const speechHypothesis = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechHypothesis\"].fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionResult\"](undefined, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n                this.privRequestSession.onHypothesis(result.offset);\n                ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionEventArgs\"](result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                if (!!this.privIntentRecognizer.recognizing) {\n                    try {\n                        this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                processed = true;\n                break;\n            case \"speech.phrase\":\n                const simple = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SimpleSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionResult\"](undefined, this.privRequestSession.requestId, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n                ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionEventArgs\"](result, result.offset, this.privRequestSession.sessionId);\n                const sendEvent = () => {\n                    if (!!this.privIntentRecognizer.recognized) {\n                        try {\n                            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    // report result to promise.\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                };\n                // If intent data was sent, the terminal result for this recognizer is an intent being found.\n                // If no intent data was sent, the terminal event is speech recognition being successful.\n                if (false === this.privIntentDataSent || _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].NoMatch === ev.result.reason) {\n                    // Advance the buffers.\n                    this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                    sendEvent();\n                }\n                else {\n                    // Squirrel away the args, when the response event arrives it will build upon them\n                    // and then return\n                    this.privPendingIntentArgs = ev;\n                }\n                processed = true;\n                break;\n            case \"response\":\n                // Response from LUIS\n                ev = this.privPendingIntentArgs;\n                this.privPendingIntentArgs = undefined;\n                if (undefined === ev) {\n                    if (\"\" === connectionMessage.textBody) {\n                        // This condition happens if there is nothing but silence in the\n                        // audio sent to the service.\n                        return;\n                    }\n                    // Odd... Not sure this can happen\n                    ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionEventArgs\"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionResult\"](), 0, this.privRequestSession.sessionId);\n                }\n                const intentResponse = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"IntentResponse\"].fromJSON(connectionMessage.textBody);\n                // If LUIS didn't return anything, send the existing event, else\n                // modify it to show the match.\n                // See if the intent found is in the list of intents asked for.\n                if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {\n                    let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];\n                    if (this.privUmbrellaIntent !== undefined) {\n                        addedIntent = this.privUmbrellaIntent;\n                    }\n                    if (!!addedIntent) {\n                        const intentId = addedIntent === undefined || addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;\n                        let reason = ev.result.reason;\n                        if (undefined !== intentId) {\n                            reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].RecognizedIntent;\n                        }\n                        // make sure, properties is set.\n                        const properties = (undefined !== ev.result.properties) ?\n                            ev.result.properties : new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n                        properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);\n                        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionEventArgs\"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionResult\"](intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);\n                    }\n                }\n                this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n                if (!!this.privIntentRecognizer.recognized) {\n                    try {\n                        this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n                        /* eslint-disable no-empty */\n                    }\n                    catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                    }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback) {\n                    try {\n                        this.privSuccessCallback(ev.result);\n                    }\n                    catch (e) {\n                        if (!!this.privErrorCallback) {\n                            this.privErrorCallback(e);\n                        }\n                    }\n                    // Only invoke the call back once.\n                    // and if it's successful don't invoke the\n                    // error after that.\n                    this.privSuccessCallback = undefined;\n                    this.privErrorCallback = undefined;\n                }\n                processed = true;\n                break;\n            default:\n                break;\n        }\n        const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        defferal.resolve(processed);\n        return defferal.promise;\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][errorCode]);\n        if (!!this.privIntentRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionCanceledEventArgs\"](cancellationReason, error, errorCode, undefined, undefined, sessionId);\n            try {\n                this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"IntentRecognitionResult\"](undefined, // Intent Id\n            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // LanguageDetectionConfidence\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n}\n\n//# sourceMappingURL=IntentServiceRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js ***!
  \*********************************************************************************************************************/
/*! exports provided: QueryParameterNames */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"QueryParameterNames\", function() { return QueryParameterNames; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass QueryParameterNames {\n}\nQueryParameterNames.BotId = \"botid\";\nQueryParameterNames.CustomSpeechDeploymentId = \"cid\";\nQueryParameterNames.CustomVoiceDeploymentId = \"deploymentId\";\nQueryParameterNames.EnableAudioLogging = \"storeAudio\";\nQueryParameterNames.EnableLanguageId = \"lidEnabled\";\nQueryParameterNames.EnableWordLevelTimestamps = \"wordLevelTimestamps\";\nQueryParameterNames.EndSilenceTimeoutMs = \"endSilenceTimeoutMs\";\nQueryParameterNames.SegmentationSilenceTimeoutMs = \"segmentationSilenceTimeoutMs\";\nQueryParameterNames.Format = \"format\";\nQueryParameterNames.InitialSilenceTimeoutMs = \"initialSilenceTimeoutMs\";\nQueryParameterNames.Language = \"language\";\nQueryParameterNames.Profanity = \"profanity\";\nQueryParameterNames.RequestBotStatusMessages = \"enableBotMessageStatus\";\nQueryParameterNames.StableIntermediateThreshold = \"stableIntermediateThreshold\";\nQueryParameterNames.StableTranslation = \"stableTranslation\";\nQueryParameterNames.TestHooks = \"testhooks\";\nQueryParameterNames.Postprocessing = \"postprocessing\";\n\n//# sourceMappingURL=QueryParameterNames.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SpeechRecognitionEvent, RecognitionTriggeredEvent, ListeningStartedEvent, ConnectingToServiceEvent, RecognitionStartedEvent, RecognitionCompletionStatus, RecognitionEndedEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionEvent\", function() { return SpeechRecognitionEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionTriggeredEvent\", function() { return RecognitionTriggeredEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ListeningStartedEvent\", function() { return ListeningStartedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectingToServiceEvent\", function() { return ConnectingToServiceEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionStartedEvent\", function() { return RecognitionStartedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionCompletionStatus\", function() { return RecognitionCompletionStatus; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionEndedEvent\", function() { return RecognitionEndedEvent; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechRecognitionEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, requestId, sessionId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n        this.privSessionId = sessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\nclass RecognitionTriggeredEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"RecognitionTriggeredEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass ListeningStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n        super(\"ListeningStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass ConnectingToServiceEvent extends SpeechRecognitionEvent {\n    constructor(requestId, authFetchEventid, sessionId) {\n        super(\"ConnectingToServiceEvent\", requestId, sessionId);\n        this.privAuthFetchEventid = authFetchEventid;\n    }\n    get authFetchEventid() {\n        return this.privAuthFetchEventid;\n    }\n}\nclass RecognitionStartedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {\n        super(\"RecognitionStartedEvent\", requestId, sessionId);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nvar RecognitionCompletionStatus;\n(function (RecognitionCompletionStatus) {\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceError\"] = 1] = \"AudioSourceError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceTimeout\"] = 2] = \"AudioSourceTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchError\"] = 3] = \"AuthTokenFetchError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchTimeout\"] = 4] = \"AuthTokenFetchTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnAuthorized\"] = 5] = \"UnAuthorized\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectTimeout\"] = 6] = \"ConnectTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectError\"] = 7] = \"ConnectError\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"ClientRecognitionActivityTimeout\"] = 8] = \"ClientRecognitionActivityTimeout\";\n    RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnknownError\"] = 9] = \"UnknownError\";\n})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));\nclass RecognitionEndedEvent extends SpeechRecognitionEvent {\n    constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {\n        super(\"RecognitionEndedEvent\", requestId, sessionId, status === RecognitionCompletionStatus.Success ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info : _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Error);\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privStatus = status;\n        this.privError = error;\n        this.privServiceTag = serviceTag;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n    get serviceTag() {\n        return this.privServiceTag;\n    }\n    get status() {\n        return this.privStatus;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=RecognitionEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js ***!
  \******************************************************************************************************************/
/*! exports provided: RecognitionMode, SpeechResultFormat, RecognizerConfig, SpeechServiceConfig, Context, System, OS, Device, connectivity, type */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionMode\", function() { return RecognitionMode; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechResultFormat\", function() { return SpeechResultFormat; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognizerConfig\", function() { return RecognizerConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechServiceConfig\", function() { return SpeechServiceConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Context\", function() { return Context; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"System\", function() { return System; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OS\", function() { return OS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Device\", function() { return Device; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"connectivity\", function() { return connectivity; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"type\", function() { return type; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nvar RecognitionMode;\n(function (RecognitionMode) {\n    RecognitionMode[RecognitionMode[\"Interactive\"] = 0] = \"Interactive\";\n    RecognitionMode[RecognitionMode[\"Conversation\"] = 1] = \"Conversation\";\n    RecognitionMode[RecognitionMode[\"Dictation\"] = 2] = \"Dictation\";\n})(RecognitionMode || (RecognitionMode = {}));\nvar SpeechResultFormat;\n(function (SpeechResultFormat) {\n    SpeechResultFormat[SpeechResultFormat[\"Simple\"] = 0] = \"Simple\";\n    SpeechResultFormat[SpeechResultFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(SpeechResultFormat || (SpeechResultFormat = {}));\nclass RecognizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));\n        this.privParameters = parameters;\n        this.privMaxRetryCount = parseInt(parameters.getProperty(\"SPEECH-Error-MaxRetryCount\", \"4\"), 10);\n        this.privLanguageIdPriority = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_ContinuousLanguageIdPriority, undefined);\n        this.privLanguageIdMode = this.privLanguageIdPriority === \"Latency\" ? \"DetectContinuous\" : \"DetectAtAudioStart\";\n        if (this.privLanguageIdMode === \"DetectAtAudioStart\") {\n            this.privLanguageIdPriority = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_AtStartLanguageIdPriority, undefined);\n        }\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get recognitionMode() {\n        return this.privRecognitionMode;\n    }\n    set recognitionMode(value) {\n        this.privRecognitionMode = value;\n        this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;\n        this.privSpeechServiceConfig.Recognition = RecognitionMode[value];\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n    get recognitionActivityTimeout() {\n        return this.privRecognitionActivityTimeout;\n    }\n    get isContinuousRecognition() {\n        return this.privRecognitionMode !== RecognitionMode.Interactive;\n    }\n    get languageIdPriority() {\n        return !!this.privLanguageIdPriority ? `Prioritize${this.privLanguageIdPriority}` : \"\";\n    }\n    get languageIdMode() {\n        return this.privLanguageIdMode;\n    }\n    get autoDetectSourceLanguages() {\n        return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages, undefined);\n    }\n    get recognitionEndpointVersion() {\n        return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_RecognitionEndpointVersion, undefined);\n    }\n    get sourceLanguageModels() {\n        const models = [];\n        let modelsExist = false;\n        if (this.autoDetectSourceLanguages !== undefined) {\n            for (const language of this.autoDetectSourceLanguages.split(\",\")) {\n                const customProperty = language + _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceConnection_EndpointId.toString();\n                const modelId = this.parameters.getProperty(customProperty, undefined);\n                if (modelId !== undefined) {\n                    models.push({ language, endpoint: modelId });\n                    modelsExist = true;\n                }\n                else {\n                    models.push({ language, endpoint: \"\" });\n                }\n            }\n        }\n        return modelsExist ? models : undefined;\n    }\n    get maxRetryCount() {\n        return this.privMaxRetryCount;\n    }\n}\n// The config is serialized and sent as the Speech.Config\nclass SpeechServiceConfig {\n    constructor(context) {\n        this.context = context;\n    }\n    serialize() {\n        return JSON.stringify(this, (key, value) => {\n            if (value && typeof value === \"object\") {\n                const replacement = {};\n                for (const k in value) {\n                    if (Object.hasOwnProperty.call(value, k)) {\n                        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n                        replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];\n                    }\n                }\n                return replacement;\n            }\n            return value;\n        });\n    }\n    get Context() {\n        return this.context;\n    }\n    get Recognition() {\n        return this.recognition;\n    }\n    set Recognition(value) {\n        this.recognition = value.toLowerCase();\n    }\n}\nclass Context {\n    constructor(os) {\n        this.system = new System();\n        this.os = os;\n    }\n}\nclass System {\n    constructor() {\n        // Note: below will be patched for official builds.\n        const SPEECHSDK_CLIENTSDK_VERSION = \"1.24.1\";\n        this.name = \"SpeechSDK\";\n        this.version = SPEECHSDK_CLIENTSDK_VERSION;\n        this.build = \"JavaScript\";\n        this.lang = \"JavaScript\";\n    }\n}\nclass OS {\n    constructor(platform, name, version) {\n        this.platform = platform;\n        this.name = name;\n        this.version = version;\n    }\n}\nclass Device {\n    constructor(manufacturer, model, version) {\n        this.manufacturer = manufacturer;\n        this.model = model;\n        this.version = version;\n    }\n}\nvar connectivity;\n(function (connectivity) {\n    connectivity[\"Bluetooth\"] = \"Bluetooth\";\n    connectivity[\"Wired\"] = \"Wired\";\n    connectivity[\"WiFi\"] = \"WiFi\";\n    connectivity[\"Cellular\"] = \"Cellular\";\n    connectivity[\"InBuilt\"] = \"InBuilt\";\n    connectivity[\"Unknown\"] = \"Unknown\";\n})(connectivity || (connectivity = {}));\nvar type;\n(function (type) {\n    type[\"Phone\"] = \"Phone\";\n    type[\"Speaker\"] = \"Speaker\";\n    type[\"Car\"] = \"Car\";\n    type[\"Headset\"] = \"Headset\";\n    type[\"Thermostat\"] = \"Thermostat\";\n    type[\"Microphones\"] = \"Microphones\";\n    type[\"Deskphone\"] = \"Deskphone\";\n    type[\"RemoteControl\"] = \"RemoteControl\";\n    type[\"Unknown\"] = \"Unknown\";\n    type[\"File\"] = \"File\";\n    type[\"Stream\"] = \"Stream\";\n})(type || (type = {}));\n\n//# sourceMappingURL=RecognizerConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js ***!
  \****************************************************************************************************************/
/*! exports provided: RequestSession */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RequestSession\", function() { return RequestSession; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony import */ var _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceTelemetryListener.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass RequestSession {\n    constructor(audioSourceId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privIsAudioNodeDetached = false;\n        this.privIsRecognizing = false;\n        this.privIsSpeechEnded = false;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privHypothesisReceived = false;\n        this.privBytesSent = 0;\n        this.privRecogNumber = 0;\n        this.privInTurn = false;\n        this.privConnectionAttempts = 0;\n        this.privAudioSourceId = audioSourceId;\n        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privAudioNodeId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSpeechEnded() {\n        return this.privIsSpeechEnded;\n    }\n    get isRecognizing() {\n        return this.privIsRecognizing;\n    }\n    get currentTurnAudioOffset() {\n        return this.privTurnStartAudioOffset;\n    }\n    get recogNumber() {\n        return this.privRecogNumber;\n    }\n    get numConnectionAttempts() {\n        return this.privConnectionAttempts;\n    }\n    // The number of bytes sent for the current connection.\n    // Counter is reset to 0 each time a connection is established.\n    get bytesSent() {\n        return this.privBytesSent;\n    }\n    listenForServiceTelemetry(eventSource) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));\n        }\n    }\n    startNewRecognition() {\n        this.privIsSpeechEnded = false;\n        this.privIsRecognizing = true;\n        this.privTurnStartAudioOffset = 0;\n        this.privLastRecoOffset = 0;\n        this.privRecogNumber++;\n        this.privServiceTelemetryListener = new _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__[\"ServiceTelemetryListener\"](this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionTriggeredEvent\"](this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n    }\n    onAudioSourceAttachCompleted(audioNode, isError) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privAudioNode = audioNode;\n            this.privIsAudioNodeDetached = false;\n            if (isError) {\n                yield this.onComplete();\n            }\n            else {\n                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ListeningStartedEvent\"](this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n            }\n        });\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.privSessionId = connectionId;\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectingToServiceEvent\"](this.privRequestId, this.privAuthFetchEventId, this.privSessionId));\n    }\n    onAuthCompleted(isError) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (isError) {\n                yield this.onComplete();\n            }\n        });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    onConnectionEstablishCompleted(statusCode, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (statusCode === 200) {\n                this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStartedEvent\"](this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));\n                if (!!this.privAudioNode) {\n                    this.privAudioNode.replay();\n                }\n                this.privTurnStartAudioOffset = this.privLastRecoOffset;\n                this.privBytesSent = 0;\n                return;\n            }\n            else if (statusCode === 403) {\n                yield this.onComplete();\n            }\n        });\n    }\n    onServiceTurnEndResponse(continuousRecognition) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privTurnDeferral.resolve();\n            if (!continuousRecognition || this.isSpeechEnded) {\n                yield this.onComplete();\n                this.privInTurn = false;\n            }\n            else {\n                // Start a new request set.\n                this.privTurnStartAudioOffset = this.privLastRecoOffset;\n                this.privAudioNode.replay();\n            }\n        });\n    }\n    onSpeechContext() {\n        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n    }\n    onServiceTurnStartResponse() {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n    }\n    onHypothesis(offset) {\n        if (!this.privHypothesisReceived) {\n            this.privHypothesisReceived = true;\n            this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));\n        }\n    }\n    onPhraseRecognized(offset) {\n        this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));\n        this.onServiceRecognized(offset);\n    }\n    onServiceRecognized(offset) {\n        this.privLastRecoOffset = offset;\n        this.privHypothesisReceived = false;\n        this.privAudioNode.shrinkBuffers(offset);\n        this.privConnectionAttempts = 0;\n    }\n    onAudioSent(bytesSent) {\n        this.privBytesSent += bytesSent;\n    }\n    onRetryConnection() {\n        this.privConnectionAttempts++;\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                // we should have completed by now. If we did not its an unknown error.\n                this.privIsDisposed = true;\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n                if (!!this.privServiceTelemetryListener) {\n                    this.privServiceTelemetryListener.dispose();\n                }\n                this.privIsRecognizing = false;\n            }\n        });\n    }\n    getTelemetry() {\n        if (this.privServiceTelemetryListener.hasTelemetry) {\n            return this.privServiceTelemetryListener.getTelemetry();\n        }\n        else {\n            return null;\n        }\n    }\n    onStopRecognizing() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.onComplete();\n        });\n    }\n    // Should be called with the audioNode for this session has indicated that it is out of speech.\n    onSpeechEnded() {\n        this.privIsSpeechEnded = true;\n    }\n    onEvent(event) {\n        if (!!this.privServiceTelemetryListener) {\n            this.privServiceTelemetryListener.onEvent(event);\n        }\n        _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Events\"].instance.onEvent(event);\n    }\n    onComplete() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privIsRecognizing) {\n                this.privIsRecognizing = false;\n                yield this.detachAudioNode();\n            }\n        });\n    }\n    detachAudioNode() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsAudioNodeDetached) {\n                this.privIsAudioNodeDetached = true;\n                if (this.privAudioNode) {\n                    yield this.privAudioNode.detach();\n                }\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=RequestSession.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \*****************************************************************************************************************************************/
/*! exports provided: ActivityPayloadResponse, MessageDataStreamType */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ActivityPayloadResponse\", function() { return ActivityPayloadResponse; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MessageDataStreamType\", function() { return MessageDataStreamType; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass ActivityPayloadResponse {\n    constructor(json) {\n        this.privActivityResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new ActivityPayloadResponse(json);\n    }\n    get conversationId() {\n        return this.privActivityResponse.conversationId;\n    }\n    get messageDataStreamType() {\n        return this.privActivityResponse.messageDataStreamType;\n    }\n    get messagePayload() {\n        return this.privActivityResponse.messagePayload;\n    }\n    get version() {\n        return this.privActivityResponse.version;\n    }\n}\nvar MessageDataStreamType;\n(function (MessageDataStreamType) {\n    MessageDataStreamType[MessageDataStreamType[\"None\"] = 0] = \"None\";\n    MessageDataStreamType[MessageDataStreamType[\"TextToSpeechAudio\"] = 1] = \"TextToSpeechAudio\";\n})(MessageDataStreamType || (MessageDataStreamType = {}));\n\n//# sourceMappingURL=ActivityResponsePayload.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \**************************************************************************************************************************************/
/*! exports provided: DetailedSpeechPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetailedSpeechPhrase\", function() { return DetailedSpeechPhrase; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DetailedSpeechPhrase {\n    constructor(json) {\n        this.privDetailedSpeechPhrase = JSON.parse(json);\n        this.privDetailedSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionStatus\"][this.privDetailedSpeechPhrase.RecognitionStatus];\n    }\n    static fromJSON(json) {\n        return new DetailedSpeechPhrase(json);\n    }\n    getJsonWithCorrectedOffsets(baseOffset) {\n        if (!!this.privDetailedSpeechPhrase.NBest) {\n            let firstWordOffset;\n            for (const phrase of this.privDetailedSpeechPhrase.NBest) {\n                if (!!phrase.Words && !!phrase.Words[0]) {\n                    firstWordOffset = phrase.Words[0].Offset;\n                    break;\n                }\n            }\n            if (!!firstWordOffset && firstWordOffset < baseOffset) {\n                const offset = baseOffset - firstWordOffset;\n                for (const details of this.privDetailedSpeechPhrase.NBest) {\n                    if (!!details.Words) {\n                        for (const word of details.Words) {\n                            word.Offset += offset;\n                        }\n                    }\n                }\n            }\n        }\n        return JSON.stringify(this.privDetailedSpeechPhrase);\n    }\n    get RecognitionStatus() {\n        return this.privDetailedSpeechPhrase.RecognitionStatus;\n    }\n    get NBest() {\n        return this.privDetailedSpeechPhrase.NBest;\n    }\n    get Duration() {\n        return this.privDetailedSpeechPhrase.Duration;\n    }\n    get Offset() {\n        return this.privDetailedSpeechPhrase.Offset;\n    }\n    get Language() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get Text() {\n        if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {\n            return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;\n        }\n        return this.privDetailedSpeechPhrase.DisplayText;\n    }\n    get SpeakerId() {\n        return this.privDetailedSpeechPhrase.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=DetailedSpeechPhrase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js ***!
  \***********************************************************************************************************************/
/*! exports provided: SynthesisStatus, RecognitionStatus */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisStatus\", function() { return SynthesisStatus; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionStatus\", function() { return RecognitionStatus; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class SynthesisStatus\n * @private\n */\nvar SynthesisStatus;\n(function (SynthesisStatus) {\n    /**\n     * The response contains valid audio data.\n     * @member SynthesisStatus.Success\n     */\n    SynthesisStatus[SynthesisStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * Indicates the end of audio data. No valid audio data is included in the message.\n     * @member SynthesisStatus.SynthesisEnd\n     */\n    SynthesisStatus[SynthesisStatus[\"SynthesisEnd\"] = 1] = \"SynthesisEnd\";\n    /**\n     * Indicates an error occurred during synthesis data processing.\n     * @member SynthesisStatus.Error\n     */\n    SynthesisStatus[SynthesisStatus[\"Error\"] = 2] = \"Error\";\n})(SynthesisStatus || (SynthesisStatus = {}));\nvar RecognitionStatus;\n(function (RecognitionStatus) {\n    RecognitionStatus[RecognitionStatus[\"Success\"] = 0] = \"Success\";\n    RecognitionStatus[RecognitionStatus[\"NoMatch\"] = 1] = \"NoMatch\";\n    RecognitionStatus[RecognitionStatus[\"InitialSilenceTimeout\"] = 2] = \"InitialSilenceTimeout\";\n    RecognitionStatus[RecognitionStatus[\"BabbleTimeout\"] = 3] = \"BabbleTimeout\";\n    RecognitionStatus[RecognitionStatus[\"Error\"] = 4] = \"Error\";\n    RecognitionStatus[RecognitionStatus[\"EndOfDictation\"] = 5] = \"EndOfDictation\";\n    RecognitionStatus[RecognitionStatus[\"TooManyRequests\"] = 6] = \"TooManyRequests\";\n    RecognitionStatus[RecognitionStatus[\"BadRequest\"] = 7] = \"BadRequest\";\n    RecognitionStatus[RecognitionStatus[\"Forbidden\"] = 8] = \"Forbidden\";\n})(RecognitionStatus || (RecognitionStatus = {}));\n\n//# sourceMappingURL=Enums.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js ***!
  \********************************************************************************************************************************/
/*! exports provided: IntentResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentResponse\", function() { return IntentResponse; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass IntentResponse {\n    constructor(json) {\n        if (json === \"\") {\n            this.privIntentResponse = {};\n        }\n        else {\n            this.privIntentResponse = JSON.parse(json);\n        }\n    }\n    static fromJSON(json) {\n        return new IntentResponse(json);\n    }\n    get query() {\n        return this.privIntentResponse.query;\n    }\n    get topScoringIntent() {\n        return this.privIntentResponse.topScoringIntent;\n    }\n    get entities() {\n        return this.privIntentResponse.entities;\n    }\n}\n\n//# sourceMappingURL=IntentResponse.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \************************************************************************************************************************************/
/*! exports provided: SimpleSpeechPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SimpleSpeechPhrase\", function() { return SimpleSpeechPhrase; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SimpleSpeechPhrase {\n    constructor(json) {\n        this.privSimpleSpeechPhrase = JSON.parse(json);\n        this.privSimpleSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionStatus\"][this.privSimpleSpeechPhrase.RecognitionStatus];\n    }\n    static fromJSON(json) {\n        return new SimpleSpeechPhrase(json);\n    }\n    get RecognitionStatus() {\n        return this.privSimpleSpeechPhrase.RecognitionStatus;\n    }\n    get DisplayText() {\n        return this.privSimpleSpeechPhrase.DisplayText;\n    }\n    get Offset() {\n        return this.privSimpleSpeechPhrase.Offset;\n    }\n    get Duration() {\n        return this.privSimpleSpeechPhrase.Duration;\n    }\n    get Language() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSimpleSpeechPhrase.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=SimpleSpeechPhrase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \********************************************************************************************************************************/
/*! exports provided: SpeechDetected */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechDetected\", function() { return SpeechDetected; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechDetected {\n    constructor(json) {\n        this.privSpeechStartDetected = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechDetected(json);\n    }\n    get Offset() {\n        return this.privSpeechStartDetected.Offset;\n    }\n}\n\n//# sourceMappingURL=SpeechDetected.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechHypothesis */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechHypothesis\", function() { return SpeechHypothesis; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechHypothesis {\n    constructor(json) {\n        this.privSpeechHypothesis = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechHypothesis(json);\n    }\n    get Text() {\n        return this.privSpeechHypothesis.Text;\n    }\n    get Offset() {\n        return this.privSpeechHypothesis.Offset;\n    }\n    get Duration() {\n        return this.privSpeechHypothesis.Duration;\n    }\n    get Language() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;\n    }\n    get LanguageDetectionConfidence() {\n        return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;\n    }\n    get SpeakerId() {\n        return this.privSpeechHypothesis.SpeakerId;\n    }\n}\n\n//# sourceMappingURL=SpeechHypothesis.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: SpeechKeyword */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechKeyword\", function() { return SpeechKeyword; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechKeyword {\n    constructor(json) {\n        this.privSpeechKeyword = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SpeechKeyword(json);\n    }\n    get Status() {\n        return this.privSpeechKeyword.Status;\n    }\n    get Text() {\n        return this.privSpeechKeyword.Text;\n    }\n    get Offset() {\n        return this.privSpeechKeyword.Offset;\n    }\n    get Duration() {\n        return this.privSpeechKeyword.Duration;\n    }\n}\n\n//# sourceMappingURL=SpeechKeyword.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \****************************************************************************************************************************************/
/*! exports provided: MetadataType, SynthesisAudioMetadata */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MetadataType\", function() { return MetadataType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisAudioMetadata\", function() { return SynthesisAudioMetadata; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar MetadataType;\n(function (MetadataType) {\n    MetadataType[\"WordBoundary\"] = \"WordBoundary\";\n    MetadataType[\"Bookmark\"] = \"Bookmark\";\n    MetadataType[\"Viseme\"] = \"Viseme\";\n    MetadataType[\"SentenceBoundary\"] = \"SentenceBoundary\";\n    MetadataType[\"SessionEnd\"] = \"SessionEnd\";\n})(MetadataType || (MetadataType = {}));\nclass SynthesisAudioMetadata {\n    constructor(json) {\n        this.privSynthesisAudioMetadata = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new SynthesisAudioMetadata(json);\n    }\n    get Metadata() {\n        return this.privSynthesisAudioMetadata.Metadata;\n    }\n}\n\n//# sourceMappingURL=SynthesisAudioMetadata.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \***************************************************************************************************************************************/
/*! exports provided: TranslationHypothesis */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationHypothesis\", function() { return TranslationHypothesis; });\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationHypothesis {\n    constructor(json) {\n        this.privTranslationHypothesis = JSON.parse(json);\n        this.privTranslationHypothesis.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__[\"TranslationStatus\"][this.privTranslationHypothesis.Translation.TranslationStatus];\n    }\n    static fromJSON(json) {\n        return new TranslationHypothesis(json);\n    }\n    get Duration() {\n        return this.privTranslationHypothesis.Duration;\n    }\n    get Offset() {\n        return this.privTranslationHypothesis.Offset;\n    }\n    get Text() {\n        return this.privTranslationHypothesis.Text;\n    }\n    get Translation() {\n        return this.privTranslationHypothesis.Translation;\n    }\n}\n\n//# sourceMappingURL=TranslationHypothesis.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: TranslationPhrase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationPhrase\", function() { return TranslationPhrase; });\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass TranslationPhrase {\n    constructor(phrase) {\n        this.privTranslationPhrase = phrase;\n        this.privTranslationPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"][this.privTranslationPhrase.RecognitionStatus];\n        if (this.privTranslationPhrase.Translation !== undefined) {\n            this.privTranslationPhrase.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_2__[\"TranslationStatus\"][this.privTranslationPhrase.Translation.TranslationStatus];\n        }\n    }\n    static fromJSON(json) {\n        return new TranslationPhrase(JSON.parse(json));\n    }\n    static fromTranslationResponse(translationResponse) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(translationResponse, \"translationResponse\");\n        const phrase = translationResponse.SpeechPhrase;\n        translationResponse.SpeechPhrase = undefined;\n        phrase.Translation = translationResponse;\n        phrase.Text = phrase.DisplayText;\n        return new TranslationPhrase(phrase);\n    }\n    get RecognitionStatus() {\n        return this.privTranslationPhrase.RecognitionStatus;\n    }\n    get Offset() {\n        return this.privTranslationPhrase.Offset;\n    }\n    get Duration() {\n        return this.privTranslationPhrase.Duration;\n    }\n    get Text() {\n        return this.privTranslationPhrase.Text;\n    }\n    get Translation() {\n        return this.privTranslationPhrase.Translation;\n    }\n}\n\n//# sourceMappingURL=TranslationPhrase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \*****************************************************************************************************************************************/
/*! exports provided: TranslationSynthesisEnd */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisEnd\", function() { return TranslationSynthesisEnd; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationSynthesisEnd {\n    constructor(json) {\n        this.privSynthesisEnd = JSON.parse(json);\n        this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisStatus\"][this.privSynthesisEnd.SynthesisStatus];\n    }\n    static fromJSON(json) {\n        return new TranslationSynthesisEnd(json);\n    }\n    get SynthesisStatus() {\n        return this.privSynthesisEnd.SynthesisStatus;\n    }\n    get FailureReason() {\n        return this.privSynthesisEnd.FailureReason;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisEnd.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: TurnStatusResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TurnStatusResponsePayload\", function() { return TurnStatusResponsePayload; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass TurnStatusResponsePayload {\n    constructor(json) {\n        this.privMessageStatusResponse = JSON.parse(json);\n    }\n    static fromJSON(json) {\n        return new TurnStatusResponsePayload(json);\n    }\n    get interactionId() {\n        return this.privMessageStatusResponse.interactionId;\n    }\n    get conversationId() {\n        return this.privMessageStatusResponse.conversationId;\n    }\n    get statusCode() {\n        // Payloads may contain a limited set of textual representations or a numeric status\n        // code. The textual values are here converted into numeric ones.\n        switch (this.privMessageStatusResponse.statusCode) {\n            case \"Success\":\n                return 200;\n            case \"Failed\":\n                return 400;\n            case \"TimedOut\":\n                return 429;\n            default:\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n                return this.privMessageStatusResponse.statusCode;\n        }\n    }\n}\n\n//# sourceMappingURL=TurnStatusPayload.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ServiceRecognizerBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServiceRecognizerBase\", function() { return ServiceRecognizerBase; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\nclass ServiceRecognizerBase {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        // A promise for a connection, but one that has not had the speech context sent yet.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionPromise = undefined;\n        this.privSetTimeout = setTimeout;\n        this.privIsLiveAudio = false;\n        this.recognizeOverride = undefined;\n        this.disconnectOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.sendPrePayloadJSONOverride = undefined;\n        this.postConnectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        if (!authentication) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"connectionFactory\");\n        }\n        if (!audioSource) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"audioSource\");\n        }\n        if (!recognizerConfig) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"recognizerConfig\");\n        }\n        this.privMustReportEndOfStream = false;\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privAudioSource = audioSource;\n        this.privRecognizerConfig = recognizerConfig;\n        this.privIsDisposed = false;\n        this.privRecognizer = recognizer;\n        this.privRequestSession = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"RequestSession\"](this.privAudioSource.id());\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privDynamicGrammar = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"DynamicGrammarBuilder\"]();\n        this.privSpeechContext = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"SpeechContext\"](this.privDynamicGrammar);\n        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"AgentConfig\"]();\n        if (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") {\n            this.privSetTimeout = _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Timeout\"].setTimeout;\n        }\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode === 1003 ||\n                    connectionClosedEvent.statusCode === 1007 ||\n                    connectionClosedEvent.statusCode === 1002 ||\n                    connectionClosedEvent.statusCode === 4000 ||\n                    this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {\n                    void this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n    }\n    get audioSource() {\n        return this.privAudioSource;\n    }\n    get speechContext() {\n        return this.privSpeechContext;\n    }\n    get dynamicGrammar() {\n        return this.privDynamicGrammar;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    set conversationTranslatorToken(token) {\n        this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_Token, token);\n    }\n    set authentication(auth) {\n        this.privAuthentication = this.authentication;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                try {\n                    const connection = yield this.privConnectionConfigurationPromise;\n                    yield connection.dispose(reason);\n                }\n                catch (error) {\n                    // The connection is in a bad state. But we're trying to kill it, so...\n                    return;\n                }\n            }\n        });\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    get recognitionMode() {\n        return this.privRecognizerConfig.recognitionMode;\n    }\n    recognize(recoMode, successCallback, errorCallBack) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.recognizeOverride !== undefined) {\n                yield this.recognizeOverride(recoMode, successCallback, errorCallBack);\n                return;\n            }\n            // Clear the existing configuration promise to force a re-transmission of config and context.\n            this.privConnectionConfigurationPromise = undefined;\n            this.privRecognizerConfig.recognitionMode = recoMode;\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallBack;\n            this.privRequestSession.startNewRecognition();\n            this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);\n            // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n            const conPromise = this.connectImpl();\n            let audioNode;\n            try {\n                const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);\n                const format = yield this.audioSource.format;\n                const deviceInfo = yield this.audioSource.deviceInfo;\n                this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === _Exports__WEBPACK_IMPORTED_MODULE_3__[\"type\"].Microphones;\n                audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ReplayableAudioNode\"](audioStreamNode, format.avgBytesPerSec);\n                yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n                this.privRecognizerConfig.SpeechServiceConfig.Context.audio = { source: deviceInfo };\n            }\n            catch (error) {\n                yield this.privRequestSession.onStopRecognizing();\n                throw error;\n            }\n            try {\n                yield conPromise;\n            }\n            catch (error) {\n                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].ConnectionFailure, error);\n                return;\n            }\n            const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SessionEventArgs\"](this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.sessionStarted) {\n                this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n            }\n            void this.receiveMessage();\n            const audioSendPromise = this.sendAudio(audioNode);\n            audioSendPromise.catch((error) => __awaiter(this, void 0, void 0, function* () {\n                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].RuntimeError, error);\n            }));\n            return;\n        });\n    }\n    stopRecognizing() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privRequestSession.isRecognizing) {\n                try {\n                    yield this.audioSource.turnOff();\n                    yield this.sendFinalAudio();\n                    yield this.privRequestSession.onStopRecognizing();\n                    yield this.privRequestSession.turnCompletionPromise;\n                }\n                finally {\n                    yield this.privRequestSession.dispose();\n                }\n            }\n            return;\n        });\n    }\n    connect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.connectImpl();\n            return Promise.resolve();\n        });\n    }\n    connectAsync(cb, err) {\n        this.connectImpl().then(() => {\n            try {\n                if (!!cb) {\n                    cb();\n                }\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n        }, (reason) => {\n            try {\n                if (!!err) {\n                    err(reason);\n                }\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n            }\n        });\n    }\n    disconnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError, \"Disconnecting\");\n            if (this.disconnectOverride !== undefined) {\n                yield this.disconnectOverride();\n            }\n            if (this.privConnectionPromise !== undefined) {\n                try {\n                    yield (yield this.privConnectionPromise).dispose();\n                }\n                catch (error) {\n                }\n            }\n            this.privConnectionPromise = undefined;\n        });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    sendMessage(message) {\n        return;\n    }\n    sendNetworkMessage(path, payload) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Text : _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Binary;\n            const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n            const connection = yield this.fetchConnection();\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](type, path, this.privRequestSession.requestId, contentType, payload));\n        });\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    sendTelemetryData() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const telemetryData = this.privRequestSession.getTelemetry();\n            if (ServiceRecognizerBase.telemetryDataEnabled !== true ||\n                this.privIsDisposed ||\n                null === telemetryData) {\n                return;\n            }\n            if (!!ServiceRecognizerBase.telemetryData) {\n                try {\n                    ServiceRecognizerBase.telemetryData(telemetryData);\n                    /* eslint-disable no-empty */\n                }\n                catch (_a) { }\n            }\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Text, \"telemetry\", this.privRequestSession.requestId, \"application/json\", telemetryData));\n        });\n    }\n    // Cancels recognition.\n    cancelRecognitionLocal(cancellationReason, errorCode, error) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privRequestSession.isRecognizing) {\n                yield this.privRequestSession.onStopRecognizing();\n                this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);\n            }\n        });\n    }\n    receiveMessage() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                if (this.privIsDisposed) {\n                    // We're done.\n                    return;\n                }\n                let connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.receiveMessageOverride !== undefined) {\n                    return this.receiveMessageOverride();\n                }\n                // indicates we are draining the queue and it came with no message;\n                if (!message) {\n                    if (!this.privRequestSession.isRecognizing) {\n                        return;\n                    }\n                    else {\n                        return this.receiveMessage();\n                    }\n                }\n                this.privServiceHasSentMessage = true;\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"].fromConnectionMessage(message);\n                if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {\n                    switch (connectionMessage.path.toLowerCase()) {\n                        case \"turn.start\":\n                            this.privMustReportEndOfStream = true;\n                            this.privRequestSession.onServiceTurnStartResponse();\n                            break;\n                        case \"speech.startdetected\":\n                            const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_3__[\"SpeechDetected\"].fromJSON(connectionMessage.textBody);\n                            const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionEventArgs\"](speechStartDetected.Offset, this.privRequestSession.sessionId);\n                            if (!!this.privRecognizer.speechStartDetected) {\n                                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n                            }\n                            break;\n                        case \"speech.enddetected\":\n                            let json;\n                            if (connectionMessage.textBody.length > 0) {\n                                json = connectionMessage.textBody;\n                            }\n                            else {\n                                // If the request was empty, the JSON returned is empty.\n                                json = \"{ Offset: 0 }\";\n                            }\n                            const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_3__[\"SpeechDetected\"].fromJSON(json);\n                            // Only shrink the buffers for continuous recognition.\n                            // For single shot, the speech.phrase message will come after the speech.end and it should own buffer shrink.\n                            if (this.privRecognizerConfig.isContinuousRecognition) {\n                                this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n                            }\n                            const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionEventArgs\"](speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n                            if (!!this.privRecognizer.speechEndDetected) {\n                                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n                            }\n                            break;\n                        case \"turn.end\":\n                            yield this.sendTelemetryData();\n                            if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {\n                                this.privMustReportEndOfStream = false;\n                                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].EndOfStream, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError, undefined);\n                            }\n                            const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"SessionEventArgs\"](this.privRequestSession.sessionId);\n                            yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);\n                            if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                                if (!!this.privRecognizer.sessionStopped) {\n                                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                                }\n                                return;\n                            }\n                            else {\n                                connection = yield this.fetchConnection();\n                                yield this.sendPrePayloadJSON(connection);\n                            }\n                            break;\n                        default:\n                            if (!(yield this.processTypeSpecificMessages(connectionMessage))) {\n                                // here are some messages that the derived class has not processed, dispatch them to connect class\n                                if (!!this.privServiceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ServiceEvent\"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                    }\n                }\n                return this.receiveMessage();\n            }\n            catch (error) {\n                return null;\n            }\n        });\n    }\n    sendSpeechContext(connection, generateNewRequestId) {\n        const speechContextJson = this.speechContext.toJSON();\n        if (generateNewRequestId) {\n            this.privRequestSession.onSpeechContext();\n        }\n        if (speechContextJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Text, \"speech.context\", this.privRequestSession.requestId, \"application/json\", speechContextJson));\n        }\n        return;\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    sendPrePayloadJSON(connection, generateNewRequestId = true) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.sendPrePayloadJSONOverride !== undefined) {\n                return this.sendPrePayloadJSONOverride(connection);\n            }\n            yield this.sendSpeechContext(connection, generateNewRequestId);\n            yield this.sendWaveHeader(connection);\n            return;\n        });\n    }\n    sendWaveHeader(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const format = yield this.audioSource.format;\n            // this.writeBufferToConsole(format.header);\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Binary, \"audio\", this.privRequestSession.requestId, \"audio/x-wav\", format.header));\n        });\n    }\n    // Establishes a websocket connection to the end point.\n    connectImpl() {\n        if (this.privConnectionPromise !== undefined) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionState\"].Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = undefined;\n                this.privServiceHasSentMessage = false;\n                return this.connectImpl();\n            });\n        }\n        this.privConnectionPromise = this.retryableConnect();\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        if (this.postConnectImplOverride !== undefined) {\n            return this.postConnectImplOverride(this.privConnectionPromise);\n        }\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {\n        requestSession.onSpeechContext();\n        // filter out anything that is not required for the service to work.\n        if (ServiceRecognizerBase.telemetryDataEnabled !== true) {\n            const withTelemetry = JSON.parse(SpeechServiceConfigJson);\n            const replacement = {\n                context: {\n                    system: withTelemetry.context.system,\n                },\n            };\n            SpeechServiceConfigJson = JSON.stringify(replacement);\n        }\n        if (this.privRecognizerConfig.parameters.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() === \"true\") {\n            const json = JSON.parse(SpeechServiceConfigJson);\n            json.context.DisableReferenceChannel = \"True\";\n            json.context.MicSpec = \"1_0_0\";\n            SpeechServiceConfigJson = JSON.stringify(json);\n        }\n        if (SpeechServiceConfigJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Text, \"speech.config\", requestSession.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n        return;\n    }\n    fetchConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                return this.privConnectionConfigurationPromise.then((connection) => {\n                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionState\"].Disconnected) {\n                        this.privConnectionId = null;\n                        this.privConnectionConfigurationPromise = undefined;\n                        this.privServiceHasSentMessage = false;\n                        return this.fetchConnection();\n                    }\n                    return this.privConnectionConfigurationPromise;\n                }, () => {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    this.privServiceHasSentMessage = false;\n                    return this.fetchConnection();\n                });\n            }\n            this.privConnectionConfigurationPromise = this.configureConnection();\n            return yield this.privConnectionConfigurationPromise;\n        });\n    }\n    sendAudio(audioStreamNode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const audioFormat = yield this.audioSource.format;\n            // The time we last sent data to the service.\n            let nextSendTime = Date.now();\n            // Max amount to send before we start to throttle\n            const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-TransmitLengthBeforThrottleMs\", \"5000\");\n            const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);\n            const startRecogNumber = this.privRequestSession.recogNumber;\n            const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {\n                // If speech is done, stop sending audio.\n                if (!this.privIsDisposed &&\n                    !this.privRequestSession.isSpeechEnded &&\n                    this.privRequestSession.isRecognizing &&\n                    this.privRequestSession.recogNumber === startRecogNumber) {\n                    const connection = yield this.fetchConnection();\n                    const audioStreamChunk = yield audioStreamNode.read();\n                    // we have a new audio chunk to upload.\n                    if (this.privRequestSession.isSpeechEnded) {\n                        // If service already recognized audio end then don't send any more audio\n                        return;\n                    }\n                    let payload;\n                    let sendDelay;\n                    if (!audioStreamChunk || audioStreamChunk.isEnd) {\n                        payload = null;\n                        sendDelay = 0;\n                    }\n                    else {\n                        payload = audioStreamChunk.buffer;\n                        this.privRequestSession.onAudioSent(payload.byteLength);\n                        if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {\n                            sendDelay = 0;\n                        }\n                        else {\n                            sendDelay = Math.max(0, nextSendTime - Date.now());\n                        }\n                    }\n                    if (0 !== sendDelay) {\n                        yield this.delay(sendDelay);\n                    }\n                    if (payload !== null) {\n                        nextSendTime = Date.now() + (payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2));\n                    }\n                    // Are we still alive?\n                    if (!this.privIsDisposed &&\n                        !this.privRequestSession.isSpeechEnded &&\n                        this.privRequestSession.isRecognizing &&\n                        this.privRequestSession.recogNumber === startRecogNumber) {\n                        connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Binary, \"audio\", this.privRequestSession.requestId, null, payload)).catch(() => {\n                            // eslint-disable-next-line @typescript-eslint/no-empty-function\n                            this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => { });\n                        });\n                        if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {\n                            // this.writeBufferToConsole(payload);\n                            // Regardless of success or failure, schedule the next upload.\n                            // If the underlying connection was broken, the next cycle will\n                            // get a new connection and re-transmit missing audio automatically.\n                            return readAndUploadCycle();\n                        }\n                        else {\n                            // the audio stream has been closed, no need to schedule next\n                            // read-upload cycle.\n                            if (!this.privIsLiveAudio) {\n                                this.privRequestSession.onSpeechEnded();\n                            }\n                        }\n                    }\n                }\n            });\n            return readAndUploadCycle();\n        });\n    }\n    retryableConnect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            let isUnAuthorized = false;\n            this.privAuthFetchEventId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n            const sessionId = this.privRequestSession.sessionId;\n            this.privConnectionId = (sessionId !== undefined) ? sessionId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n            this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);\n            let lastStatusCode = 0;\n            let lastReason = \"\";\n            while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {\n                // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer\n                // facing event when a connection fails to let them try and provide new auth information.\n                const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n                const auth = yield authPromise;\n                yield this.privRequestSession.onAuthCompleted(false);\n                // Create the connection\n                const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);\n                // Attach the telemetry handlers.\n                this.privRequestSession.listenForServiceTelemetry(connection.events);\n                // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n                // it'll stop sending events.\n                connection.events.attach((event) => {\n                    this.connectionEvents.onEvent(event);\n                });\n                const response = yield connection.open();\n                // 200 == everything is fine.\n                if (response.statusCode === 200) {\n                    yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);\n                    return Promise.resolve(connection);\n                }\n                else if (response.statusCode === 1006) {\n                    isUnAuthorized = true;\n                }\n                lastStatusCode = response.statusCode;\n                lastReason = response.reason;\n                this.privRequestSession.onRetryConnection();\n            }\n            yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);\n            return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);\n        });\n    }\n    delay(delayMs) {\n        return new Promise((resolve) => this.privSetTimeout(resolve, delayMs));\n    }\n    writeBufferToConsole(buffer) {\n        let out = \"Buffer Size: \";\n        if (null === buffer) {\n            out += \"null\";\n        }\n        else {\n            const readView = new Uint8Array(buffer);\n            out += `${buffer.byteLength}\\r\\n`;\n            for (let i = 0; i < buffer.byteLength; i++) {\n                out += readView[i].toString(16).padStart(2, \"0\") + \" \";\n                if (((i + 1) % 16) === 0) {\n                    // eslint-disable-next-line no-console\n                    console.info(out);\n                    out = \"\";\n                }\n            }\n        }\n        // eslint-disable-next-line no-console\n        console.info(out);\n    }\n    sendFinalAudio() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Binary, \"audio\", this.privRequestSession.requestId, null, null));\n            return;\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configureConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.connectImpl();\n            if (this.configConnectionOverride !== undefined) {\n                return this.configConnectionOverride(connection);\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n            yield this.sendPrePayloadJSON(connection, false);\n            return connection;\n        });\n    }\n}\nServiceRecognizerBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=ServiceRecognizerBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ServiceTelemetryListener */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServiceTelemetryListener\", function() { return ServiceTelemetryListener; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\nclass ServiceTelemetryListener {\n    constructor(requestId, audioSourceId, audioNodeId) {\n        this.privIsDisposed = false;\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privRequestId = requestId;\n        this.privAudioSourceId = audioSourceId;\n        this.privAudioNodeId = audioNodeId;\n        this.privReceivedMessages = {};\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n    }\n    phraseReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privPhraseLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    hypothesisReceived(audioReceivedTime) {\n        if (audioReceivedTime > 0) { // 0 indicates the time is unknown. Drop it.\n            this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);\n        }\n    }\n    onEvent(e) {\n        if (this.privIsDisposed) {\n            return;\n        }\n        if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionTriggeredEvent\"] && e.requestId === this.privRequestId) {\n            this.privListeningTriggerMetric = {\n                End: e.eventTime,\n                Name: \"ListeningTrigger\",\n                Start: e.eventTime,\n            };\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeAttachingEvent\"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeAttachedEvent\"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            this.privMicStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceErrorEvent\"] && e.audioSourceId === this.privAudioSourceId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeErrorEvent\"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Error: e.error,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeDetachedEvent\"] && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n            if (!this.privMicMetric) {\n                this.privMicMetric = {\n                    End: e.eventTime,\n                    Name: \"Microphone\",\n                    Start: this.privMicStartTime,\n                };\n            }\n        }\n        if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectingToServiceEvent\"] && e.requestId === this.privRequestId) {\n            this.privConnectionId = e.sessionId;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionStartEvent\"] && e.connectionId === this.privConnectionId) {\n            this.privConnectionStartTime = e.eventTime;\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionEstablishedEvent\"] && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionEstablishErrorEvent\"] && e.connectionId === this.privConnectionId) {\n            if (!this.privConnectionEstablishMetric) {\n                this.privConnectionEstablishMetric = {\n                    End: e.eventTime,\n                    Error: this.getConnectionError(e.statusCode),\n                    Id: this.privConnectionId,\n                    Name: \"Connection\",\n                    Start: this.privConnectionStartTime,\n                };\n            }\n        }\n        if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionMessageReceivedEvent\"] && e.connectionId === this.privConnectionId) {\n            if (e.message && e.message.headers && e.message.headers.path) {\n                if (!this.privReceivedMessages[e.message.headers.path]) {\n                    this.privReceivedMessages[e.message.headers.path] = new Array();\n                }\n                const maxMessagesToSend = 50;\n                if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {\n                    this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);\n                }\n            }\n        }\n    }\n    getTelemetry() {\n        const metrics = new Array();\n        if (this.privListeningTriggerMetric) {\n            metrics.push(this.privListeningTriggerMetric);\n        }\n        if (this.privMicMetric) {\n            metrics.push(this.privMicMetric);\n        }\n        if (this.privConnectionEstablishMetric) {\n            metrics.push(this.privConnectionEstablishMetric);\n        }\n        if (this.privPhraseLatencies.length > 0) {\n            metrics.push({\n                PhraseLatencyMs: this.privPhraseLatencies,\n            });\n        }\n        if (this.privHypothesisLatencies.length > 0) {\n            metrics.push({\n                FirstHypothesisLatencyMs: this.privHypothesisLatencies,\n            });\n        }\n        const telemetry = {\n            Metrics: metrics,\n            ReceivedMessages: this.privReceivedMessages,\n        };\n        const json = JSON.stringify(telemetry);\n        // We dont want to send the same telemetry again. So clean those out.\n        this.privReceivedMessages = {};\n        this.privListeningTriggerMetric = null;\n        this.privMicMetric = null;\n        this.privConnectionEstablishMetric = null;\n        this.privPhraseLatencies = [];\n        this.privHypothesisLatencies = [];\n        return json;\n    }\n    // Determines if there are any telemetry events to send to the service.\n    get hasTelemetry() {\n        return (Object.keys(this.privReceivedMessages).length !== 0 ||\n            this.privListeningTriggerMetric !== null ||\n            this.privMicMetric !== null ||\n            this.privConnectionEstablishMetric !== null ||\n            this.privPhraseLatencies.length !== 0 ||\n            this.privHypothesisLatencies.length !== 0);\n    }\n    dispose() {\n        this.privIsDisposed = true;\n    }\n    getConnectionError(statusCode) {\n        /*\n        -- Websocket status codes --\n        NormalClosure = 1000,\n        EndpointUnavailable = 1001,\n        ProtocolError = 1002,\n        InvalidMessageType = 1003,\n        Empty = 1005,\n        InvalidPayloadData = 1007,\n        PolicyViolation = 1008,\n        MessageTooBig = 1009,\n        MandatoryExtension = 1010,\n        InternalServerError = 1011\n        */\n        switch (statusCode) {\n            case 400:\n            case 1002:\n            case 1003:\n            case 1005:\n            case 1007:\n            case 1008:\n            case 1009: return \"BadRequest\";\n            case 401: return \"Unauthorized\";\n            case 403: return \"Forbidden\";\n            case 503:\n            case 1001: return \"ServerUnavailable\";\n            case 500:\n            case 1011: return \"ServerError\";\n            case 408:\n            case 504: return \"Timeout\";\n            default: return \"statuscode:\" + statusCode.toString();\n        }\n    }\n}\n\n//# sourceMappingURL=ServiceTelemetryListener.Internal.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeakerIdMessageAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerIdMessageAdapter\", function() { return SpeakerIdMessageAdapter; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SpeakerIdMessageAdapter\n */\nclass SpeakerIdMessageAdapter {\n    constructor(config) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Region, \"westus\");\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n            endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, `https://${region}.api.cognitive${hostSuffix}`);\n        }\n        this.privUri = `${endpoint}/speaker-recognition/{mode}/{dependency}/profiles`;\n        const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestConfigBase\"].requestOptions;\n        options.headers[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestConfigBase\"].configParams.subscriptionKey] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Key, undefined);\n        this.privApiVersion = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeakerRecognition_Api_Version, \"2021-09-05\");\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestMessageAdapter\"](options);\n    }\n    /**\n     * Sends create profile request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of voice profile to create.\n     * @param {string} lang - language/locale of voice profile\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing id of created profile.\n     */\n    createProfile(profileType, lang) {\n        const uri = this.getOperationUri(profileType);\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Post, uri, this.getQueryParams({}), { locale: lang });\n    }\n    /**\n     * Sends create enrollment request to endpoint.\n     * @function\n     * @param {VoiceProfile} profileType - voice profile for which to create new enrollment.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    createEnrollment(profile, audioSource) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \"/enrollments\";\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n        return audioSource.blob.then((result) => this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].File, uri, this.getQueryParams({ ignoreMinLength: \"true\" }), null, result));\n    }\n    /**\n     * Sends verification request to endpoint.\n     * @function\n     * @param {SpeakerVerificationModel} model - voice model to verify against.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    verifySpeaker(model, audioSource) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const uri = this.getOperationUri(model.voiceProfile.profileType) + \"/\" + model.voiceProfile.profileId + \":verify\";\n            try {\n                const result = yield audioSource.blob;\n                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].File, uri, this.getQueryParams({ ignoreMinLength: \"true\" }), null, result);\n            }\n            catch (e) {\n                return Promise.resolve({ data: e });\n            }\n        });\n    }\n    /**\n     * Sends identification request to endpoint.\n     * @function\n     * @param {SpeakerIdentificationModel} model - voice profiles against which to identify.\n     * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to enrollment request.\n     */\n    identifySpeaker(model, audioSource) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const uri = this.getOperationUri(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileType\"].TextIndependentIdentification) + \":identifySingleSpeaker\";\n            try {\n                const result = yield audioSource.blob;\n                return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].File, uri, this.getQueryParams({ profileIds: model.voiceProfileIds, ignoreMinLength: \"true\" }), null, result);\n            }\n            catch (e) {\n                return Promise.resolve({ data: e });\n            }\n        });\n    }\n    /**\n     * Sends profile status request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to check.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to status request\n     */\n    getProfileStatus(profile) {\n        const uri = `${this.getOperationUri(profile.profileType)}/${profile.profileId}`;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends get all profiles request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of profiles to return list of\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing all profiles\n     */\n    getProfiles(profileType) {\n        const uri = this.getOperationUri(profileType);\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends get activation/auth phrases request to endpoint.\n     * @function\n     * @param {VoiceProfileType} profileType - type of profiles to return phrases for\n     * @param {string} lang - language/locale of voice profile\n     * @public\n     * @returns {Promise<IRestResponse>} promised rest response containing list of valid phrases\n     */\n    getPhrases(profileType, lang) {\n        const uri = `${this.getOperationUri(profileType)}`.replace(\"profiles\", \"phrases\") + \"/\" + lang;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Get, uri, this.getQueryParams());\n    }\n    /**\n     * Sends delete profile request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to delete.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to deletion request\n     */\n    deleteProfile(profile) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Delete, uri, this.getQueryParams());\n    }\n    /**\n     * Sends reset profile request to endpoint.\n     * @function\n     * @param {VoiceProfile} profile - voice profile to reset enrollments for.\n     * @public\n     * @returns {Promise<IRestResponse>} rest response to reset request\n     */\n    resetProfile(profile) {\n        const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \":reset\";\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Post, uri, this.getQueryParams());\n    }\n    getOperationUri(profileType) {\n        const mode = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileType\"].TextIndependentIdentification ? \"identification\" : \"verification\";\n        const dependency = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileType\"].TextDependentVerification ? \"text-dependent\" : \"text-independent\";\n        return this.privUri.replace(\"{mode}\", mode).replace(\"{dependency}\", dependency);\n    }\n    getQueryParams(params = {}) {\n        params[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestConfigBase\"].configParams.apiVersion] = this.privApiVersion;\n        return params;\n    }\n}\n\n//# sourceMappingURL=SpeakerIdMessageAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js ***!
  \**************************************************************************************************************************/
/*! exports provided: SpeakerRecognitionConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionConfig\", function() { return SpeakerRecognitionConfig; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeakerRecognitionConfig {\n    constructor(context, parameters) {\n        this.privContext = context ? context : new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](null);\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get Context() {\n        return this.privContext;\n    }\n}\n\n//# sourceMappingURL=SpeakerRecognitionConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeechConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechConnectionFactory\", function() { return SpeechConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\nclass SpeechConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__[\"ConnectionFactoryBase\"] {\n    constructor() {\n        super(...arguments);\n        this.interactiveRelativeUri = \"/speech/recognition/interactive/cognitiveservices/v1\";\n        this.conversationRelativeUri = \"/speech/recognition/conversation/cognitiveservices/v1\";\n        this.dictationRelativeUri = \"/speech/recognition/dictation/cognitiveservices/v1\";\n        this.universalUri = \"/speech/universal/v\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, undefined);\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_3__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n        const queryParams = {};\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].CustomSpeechDeploymentId) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].CustomSpeechDeploymentId] = endpointId;\n            }\n        }\n        else if (language) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Language) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Language] = language;\n            }\n        }\n        if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Format) === -1) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormatPropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"].Simple]).toLowerCase();\n        }\n        if (config.autoDetectSourceLanguages !== undefined) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].EnableLanguageId] = \"true\";\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        if (!endpoint) {\n            switch (config.recognitionMode) {\n                case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionMode\"].Conversation:\n                    if (config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ForceDictationPropertyName\"], \"false\") === \"true\") {\n                        endpoint = host + this.dictationRelativeUri;\n                    }\n                    else {\n                        if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                        }\n                        else {\n                            endpoint = host + this.conversationRelativeUri;\n                        }\n                    }\n                    break;\n                case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionMode\"].Dictation:\n                    endpoint = host + this.dictationRelativeUri;\n                    break;\n                default:\n                    if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n                        endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n                    }\n                    else {\n                        endpoint = host + this.interactiveRelativeUri; // default is interactive\n                    }\n                    break;\n            }\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=SpeechConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechConnectionMessage\", function() { return SpeechConnectionMessage; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass SpeechConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionMessage\"] {\n    constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {\n        if (!path) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"path\");\n        }\n        if (!requestId) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"requestId\");\n        }\n        const headers = {};\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].Path] = path;\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].RequestId] = requestId;\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].RequestTimestamp] = new Date().toISOString();\n        if (contentType) {\n            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].ContentType] = contentType;\n        }\n        if (streamId) {\n            headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].RequestStreamId] = streamId;\n        }\n        if (additionalHeaders) {\n            for (const headerName in additionalHeaders) {\n                if (headerName) {\n                    headers[headerName] = additionalHeaders[headerName];\n                }\n            }\n        }\n        if (id) {\n            super(messageType, body, headers, id);\n        }\n        else {\n            super(messageType, body, headers);\n        }\n        this.privPath = path;\n        this.privRequestId = requestId;\n        this.privContentType = contentType;\n        this.privStreamId = streamId;\n        this.privAdditionalHeaders = additionalHeaders;\n    }\n    get path() {\n        return this.privPath;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get contentType() {\n        return this.privContentType;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    get additionalHeaders() {\n        return this.privAdditionalHeaders;\n    }\n    static fromConnectionMessage(message) {\n        let path = null;\n        let requestId = null;\n        let contentType = null;\n        // let requestTimestamp = null;\n        let streamId = null;\n        const additionalHeaders = {};\n        if (message.headers) {\n            for (const headerName in message.headers) {\n                if (headerName) {\n                    if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].Path.toLowerCase()) {\n                        path = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].RequestId.toLowerCase()) {\n                        requestId = message.headers[headerName];\n                        // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {\n                        //  requestTimestamp = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].ContentType.toLowerCase()) {\n                        contentType = message.headers[headerName];\n                    }\n                    else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_1__[\"HeaderNames\"].RequestStreamId.toLowerCase()) {\n                        streamId = message.headers[headerName];\n                    }\n                    else {\n                        additionalHeaders[headerName] = message.headers[headerName];\n                    }\n                }\n            }\n        }\n        return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);\n    }\n}\n\n//# sourceMappingURL=SpeechConnectionMessage.Internal.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechContext */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechContext\", function() { return SpeechContext; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the speech.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SpeechContext {\n    constructor(dynamicGrammar) {\n        this.privContext = {};\n        this.privDynamicGrammar = dynamicGrammar;\n    }\n    /**\n     * Adds a section to the speech.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * @Internal\n     * This is only used by pronunciation assessment config.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    setPronunciationAssessmentParams(params) {\n        if (this.privContext.phraseDetection === undefined) {\n            this.privContext.phraseDetection = {\n                enrichment: {\n                    pronunciationAssessment: {}\n                }\n            };\n        }\n        this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);\n        this.setWordLevelTimings();\n        this.privContext.phraseOutput.detailed.options.push(\"PronunciationAssessment\");\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"SNR\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"SNR\");\n        }\n    }\n    setWordLevelTimings() {\n        if (this.privContext.phraseOutput === undefined) {\n            this.privContext.phraseOutput = {\n                detailed: {\n                    options: []\n                },\n                format: {}\n            };\n        }\n        if (this.privContext.phraseOutput.detailed === undefined) {\n            this.privContext.phraseOutput.detailed = {\n                options: []\n            };\n        }\n        this.privContext.phraseOutput.format = \"Detailed\";\n        if (this.privContext.phraseOutput.detailed.options.indexOf(\"WordTimings\") === -1) {\n            this.privContext.phraseOutput.detailed.options.push(\"WordTimings\");\n        }\n    }\n    toJSON() {\n        const dgi = this.privDynamicGrammar.generateGrammarObject();\n        this.setSection(\"dgi\", dgi);\n        const ret = JSON.stringify(this.privContext);\n        return ret;\n    }\n}\n\n//# sourceMappingURL=SpeechContext.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js ***!
  \*************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=SpeechServiceInterfaces.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/*! exports provided: SpeechServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechServiceRecognizer\", function() { return SpeechServiceRecognizer; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n// eslint-disable-next-line max-classes-per-file\nclass SpeechServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);\n        this.privSpeechRecognizer = speechRecognizer;\n        const phraseDetection = {};\n        const speechSegmentationTimeout = recognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].Speech_SegmentationSilenceTimeoutMs, undefined);\n        if (speechSegmentationTimeout !== undefined) {\n            const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);\n            phraseDetection.mode = \"INTERACTIVE\";\n            phraseDetection.INTERACTIVE = {\n                segmentation: {\n                    mode: \"Custom\",\n                    segmentationSilenceTimeoutMs\n                }\n            };\n        }\n        if (recognizerConfig.autoDetectSourceLanguages !== undefined) {\n            const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(\",\");\n            this.privSpeechContext.setSection(\"languageId\", {\n                Priority: recognizerConfig.languageIdPriority,\n                languages: sourceLanguages,\n                mode: recognizerConfig.languageIdMode,\n                onSuccess: { action: \"Recognize\" },\n                onUnknown: { action: \"None\" }\n            });\n            this.privSpeechContext.setSection(\"phraseOutput\", {\n                interimResults: {\n                    resultType: \"Auto\"\n                },\n                phraseResults: {\n                    resultType: \"Always\"\n                }\n            });\n            const customModels = recognizerConfig.sourceLanguageModels;\n            if (customModels !== undefined) {\n                phraseDetection.customModels = customModels;\n                phraseDetection.onInterim = { action: \"None\" };\n                phraseDetection.onSuccess = { action: \"None\" };\n            }\n        }\n        const isEmpty = (obj) => {\n            // eslint-disable-next-line guard-for-in, brace-style\n            for (const x in obj) {\n                return false;\n            }\n            return true;\n        };\n        if (!isEmpty(phraseDetection)) {\n            this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n        }\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let result;\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]();\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n            let processed = false;\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"speech.hypothesis\":\n                case \"speech.fragment\":\n                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechHypothesis\"].fromJSON(connectionMessage.textBody);\n                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, // Speaker Id\n                    undefined, connectionMessage.textBody, resultProps);\n                    this.privRequestSession.onHypothesis(offset);\n                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionEventArgs\"](result, hypothesis.Duration, this.privRequestSession.sessionId);\n                    if (!!this.privSpeechRecognizer.recognizing) {\n                        try {\n                            this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    processed = true;\n                    break;\n                case \"speech.phrase\":\n                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"SimpleSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"EnumTranslation\"].implTranslateRecognitionResult(simple.RecognitionStatus);\n                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n                    if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].Canceled === resultReason) {\n                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"EnumTranslation\"].implTranslateCancelResult(simple.RecognitionStatus);\n                        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"EnumTranslation\"].implTranslateCancelErrorCode(simple.RecognitionStatus);\n                        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_1__[\"EnumTranslation\"].implTranslateErrorDetails(cancellationErrorCode));\n                    }\n                    else {\n                        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].InitialSilenceTimeout)) {\n                            if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormatPropertyName\"]) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormat\"].Simple]) {\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, // Speaker Id\n                                undefined, connectionMessage.textBody, resultProps);\n                            }\n                            else {\n                                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"DetailedSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionStatus\"].Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined, // Speaker Id\n                                undefined, offsetCorrectedJson, resultProps);\n                            }\n                            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionEventArgs\"](result, result.offset, this.privRequestSession.sessionId);\n                            if (!!this.privSpeechRecognizer.recognized) {\n                                try {\n                                    this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                        }\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCode\"][errorCode]);\n        if (!!this.privSpeechRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionCanceledEventArgs\"](cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n}\n\n//# sourceMappingURL=SpeechServiceRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: SpeechSynthesisConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisConnectionFactory\", function() { return SpeechSynthesisConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass SpeechSynthesisConnectionFactory {\n    constructor() {\n        this.synthesisUri = \"/cognitiveservices/websocket/v1\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Region, undefined);\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_EndpointId, undefined);\n        const hostPrefix = (endpointId === undefined) ? \"tts\" : \"voice\";\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, \"wss://\" + region + \".\" + hostPrefix + \".speech\" + hostSuffix);\n        const queryParams = {};\n        if (!endpoint) {\n            endpoint = host + this.synthesisUri;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        if (endpointId !== undefined) {\n            headers[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].CustomVoiceDeploymentId] = endpointId;\n        }\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromParameters(config.parameters), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js ***!
  \**********************************************************************************************************************/
/*! exports provided: SynthesisAdapterBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisAdapterBase\", function() { return SynthesisAdapterBase; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass SynthesisAdapterBase {\n    constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {\n        this.speakOverride = undefined;\n        this.receiveMessageOverride = undefined;\n        this.connectImplOverride = undefined;\n        this.configConnectionOverride = undefined;\n        // A promise for a configured connection.\n        // Do not consume directly, call fetchConnection instead.\n        this.privConnectionConfigurationPromise = undefined;\n        if (!authentication) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"authentication\");\n        }\n        if (!connectionFactory) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"connectionFactory\");\n        }\n        if (!synthesizerConfig) {\n            throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"synthesizerConfig\");\n        }\n        this.privAuthentication = authentication;\n        this.privConnectionFactory = connectionFactory;\n        this.privSynthesizerConfig = synthesizerConfig;\n        this.privIsDisposed = false;\n        this.privSpeechSynthesizer = speechSynthesizer;\n        this.privSessionAudioDestination = audioDestination;\n        this.privSynthesisTurn = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisTurn\"]();\n        this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventSource\"]();\n        this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventSource\"]();\n        this.privSynthesisContext = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisContext\"](this.privSpeechSynthesizer);\n        this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"AgentConfig\"]();\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                const connectionClosedEvent = connectionEvent;\n                if (connectionClosedEvent.statusCode !== 1000) {\n                    this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n                }\n            }\n        });\n    }\n    get synthesisContext() {\n        return this.privSynthesisContext;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n    get connectionEvents() {\n        return this.privConnectionEvents;\n    }\n    get serviceEvents() {\n        return this.privServiceEvents;\n    }\n    set activityTemplate(messagePayload) {\n        this.privActivityTemplate = messagePayload;\n    }\n    get activityTemplate() {\n        return this.privActivityTemplate;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n        this.privSynthesisTurn.audioOutputFormat = format;\n        if (this.privSessionAudioDestination !== undefined) {\n            this.privSessionAudioDestination.format = format;\n        }\n        if (this.synthesisContext !== undefined) {\n            this.synthesisContext.audioOutputFormat = format;\n        }\n    }\n    static addHeader(audio, format) {\n        if (!format.hasHeader) {\n            return audio;\n        }\n        format.updateHeader(audio.byteLength);\n        const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);\n        tmp.set(new Uint8Array(format.header), 0);\n        tmp.set(new Uint8Array(audio), format.header.byteLength);\n        return tmp.buffer;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privIsDisposed = true;\n            if (this.privSessionAudioDestination !== undefined) {\n                this.privSessionAudioDestination.close();\n            }\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                const connection = yield this.privConnectionConfigurationPromise;\n                yield connection.dispose(reason);\n            }\n        });\n    }\n    connect() {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.connectImpl();\n        });\n    }\n    sendNetworkMessage(path, payload) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text : _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary;\n            const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n            const connection = yield this.fetchConnection();\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"](type, path, this.privSynthesisTurn.requestId, contentType, payload));\n        });\n    }\n    Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let ssml;\n            if (isSSML) {\n                ssml = text;\n            }\n            else {\n                ssml = this.privSpeechSynthesizer.buildSsml(text);\n            }\n            if (this.speakOverride !== undefined) {\n                return this.speakOverride(ssml, requestId, successCallback, errorCallBack);\n            }\n            this.privSuccessCallback = successCallback;\n            this.privErrorCallback = errorCallBack;\n            this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);\n            try {\n                yield this.connectImpl();\n                const connection = yield this.fetchConnection();\n                yield this.sendSynthesisContext(connection);\n                yield this.sendSsmlMessage(connection, ssml, requestId);\n                const synthesisStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisEventArgs\"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisResult\"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].SynthesizingAudioStarted));\n                if (!!this.privSpeechSynthesizer.synthesisStarted) {\n                    this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);\n                }\n                void this.receiveMessage();\n            }\n            catch (e) {\n                this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].ConnectionFailure, e);\n                return Promise.reject(e);\n            }\n        });\n    }\n    // Cancels synthesis.\n    cancelSynthesis(requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][errorCode]);\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisResult\"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled, undefined, error, properties);\n        if (!!this.privSpeechSynthesizer.SynthesisCanceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisEventArgs\"](result);\n            try {\n                this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n    // Cancels synthesis.\n    cancelSynthesisLocal(cancellationReason, errorCode, error) {\n        if (!!this.privSynthesisTurn.isSynthesizing) {\n            this.privSynthesisTurn.onStopSynthesizing();\n            this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    processTypeSpecificMessages(connectionMessage) {\n        return true;\n    }\n    receiveMessage() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.receiveMessageOverride !== undefined) {\n                    return this.receiveMessageOverride();\n                }\n                if (this.privIsDisposed) {\n                    // We're done.\n                    return;\n                }\n                // indicates we are draining the queue and it came with no message;\n                if (!message) {\n                    if (!this.privSynthesisTurn.isSynthesizing) {\n                        return;\n                    }\n                    else {\n                        return this.receiveMessage();\n                    }\n                }\n                const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"].fromConnectionMessage(message);\n                if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {\n                    switch (connectionMessage.path.toLowerCase()) {\n                        case \"turn.start\":\n                            this.privSynthesisTurn.onServiceTurnStartResponse();\n                            break;\n                        case \"response\":\n                            this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);\n                            break;\n                        case \"audio\":\n                            if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase()\n                                && !!connectionMessage.binaryBody) {\n                                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);\n                                if (!!this.privSpeechSynthesizer.synthesizing) {\n                                    try {\n                                        const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);\n                                        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisEventArgs\"](new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisResult\"](this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].SynthesizingAudio, audioWithHeader));\n                                        this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);\n                                    }\n                                    catch (error) {\n                                        // Not going to let errors in the event handler\n                                        // trip things up.\n                                    }\n                                }\n                                if (this.privSessionAudioDestination !== undefined) {\n                                    this.privSessionAudioDestination.write(connectionMessage.binaryBody);\n                                }\n                            }\n                            break;\n                        case \"audio.metadata\":\n                            const metadataList = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisAudioMetadata\"].fromJSON(connectionMessage.textBody).Metadata;\n                            for (const metadata of metadataList) {\n                                switch (metadata.Type) {\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].WordBoundary:\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].SentenceBoundary:\n                                        this.privSynthesisTurn.onTextBoundaryEvent(metadata);\n                                        const wordBoundaryEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisWordBoundaryEventArgs\"](metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].WordBoundary\n                                            ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);\n                                        if (!!this.privSpeechSynthesizer.wordBoundary) {\n                                            try {\n                                                this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);\n                                            }\n                                            catch (error) {\n                                                // Not going to let errors in the event handler\n                                                // trip things up.\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].Bookmark:\n                                        const bookmarkEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisBookmarkEventArgs\"](metadata.Data.Offset, metadata.Data.Bookmark);\n                                        if (!!this.privSpeechSynthesizer.bookmarkReached) {\n                                            try {\n                                                this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);\n                                            }\n                                            catch (error) {\n                                                // Not going to let errors in the event handler\n                                                // trip things up.\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].Viseme:\n                                        this.privSynthesisTurn.onVisemeMetadataReceived(metadata);\n                                        if (metadata.Data.IsLastAnimation) {\n                                            const visemeEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisVisemeEventArgs\"](metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());\n                                            if (!!this.privSpeechSynthesizer.visemeReceived) {\n                                                try {\n                                                    this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);\n                                                }\n                                                catch (error) {\n                                                    // Not going to let errors in the event handler\n                                                    // trip things up.\n                                                }\n                                            }\n                                        }\n                                        break;\n                                    case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].SessionEnd:\n                                        this.privSynthesisTurn.onSessionEnd(metadata);\n                                        break;\n                                }\n                            }\n                            break;\n                        case \"turn.end\":\n                            this.privSynthesisTurn.onServiceTurnEndResponse();\n                            let result;\n                            try {\n                                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisResult\"](this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].SynthesizingAudioCompleted, audioBuffer, undefined, undefined, this.privSynthesisTurn.audioDuration);\n                                if (!!this.privSuccessCallback) {\n                                    this.privSuccessCallback(result);\n                                }\n                            }\n                            catch (error) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(error);\n                                }\n                            }\n                            if (this.privSpeechSynthesizer.synthesisCompleted) {\n                                try {\n                                    this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechSynthesisEventArgs\"](result));\n                                }\n                                catch (e) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            break;\n                        default:\n                            if (!this.processTypeSpecificMessages(connectionMessage)) {\n                                // here are some messages that the derived class has not processed, dispatch them to connect class\n                                if (!!this.privServiceEvents) {\n                                    this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServiceEvent\"](connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                                }\n                            }\n                    }\n                }\n                return this.receiveMessage();\n            }\n            catch (e) {\n                // TODO: What goes here?\n            }\n        });\n    }\n    sendSynthesisContext(connection) {\n        const synthesisContextJson = this.synthesisContext.toJSON();\n        if (synthesisContextJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, \"synthesis.context\", this.privSynthesisTurn.requestId, \"application/json\", synthesisContextJson));\n        }\n        return;\n    }\n    connectImpl(isUnAuthorized = false) {\n        if (this.privConnectionPromise != null) {\n            return this.privConnectionPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionState\"].Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionPromise = null;\n                    return this.connectImpl();\n                }\n                return this.privConnectionPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionPromise = null;\n                return this.connectImpl();\n            });\n        }\n        this.privAuthFetchEventId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privConnectionId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);\n        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n        this.privConnectionPromise = authPromise.then((result) => __awaiter(this, void 0, void 0, function* () {\n            this.privSynthesisTurn.onAuthCompleted(false);\n            const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);\n            // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n            // it'll stop sending events.\n            connection.events.attach((event) => {\n                this.connectionEvents.onEvent(event);\n            });\n            const response = yield connection.open();\n            if (response.statusCode === 200) {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.resolve(connection);\n            }\n            else if (response.statusCode === 403 && !isUnAuthorized) {\n                return this.connectImpl(true);\n            }\n            else {\n                this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n                return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);\n            }\n        }), (error) => {\n            this.privSynthesisTurn.onAuthCompleted(true);\n            throw new Error(error);\n        });\n        // Attach an empty handler to allow the promise to run in the background while\n        // other startup events happen. It'll eventually be awaited on.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.privConnectionPromise.catch(() => { });\n        return this.privConnectionPromise;\n    }\n    sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {\n        if (SpeechServiceConfigJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, \"speech.config\", this.privSynthesisTurn.requestId, \"application/json\", SpeechServiceConfigJson));\n        }\n    }\n    sendSsmlMessage(connection, ssml, requestId) {\n        return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, \"ssml\", requestId, \"application/ssml+xml\", ssml));\n    }\n    fetchConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privConnectionConfigurationPromise !== undefined) {\n                return this.privConnectionConfigurationPromise.then((connection) => {\n                    if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionState\"].Disconnected) {\n                        this.privConnectionId = null;\n                        this.privConnectionConfigurationPromise = undefined;\n                        return this.fetchConnection();\n                    }\n                    return this.privConnectionConfigurationPromise;\n                }, () => {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigurationPromise = undefined;\n                    return this.fetchConnection();\n                });\n            }\n            this.privConnectionConfigurationPromise = this.configureConnection();\n            return yield this.privConnectionConfigurationPromise;\n        });\n    }\n    // Takes an established websocket connection to the endpoint and sends speech configuration information.\n    configureConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.connectImpl();\n            if (this.configConnectionOverride !== undefined) {\n                return this.configConnectionOverride(connection);\n            }\n            yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());\n            return connection;\n        });\n    }\n}\nSynthesisAdapterBase.telemetryDataEnabled = true;\n\n//# sourceMappingURL=SynthesisAdapterBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js ***!
  \******************************************************************************************************************/
/*! exports provided: SynthesisContext */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisContext\", function() { return SynthesisContext; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SynthesisContext {\n    constructor(speechSynthesizer) {\n        this.privContext = {};\n        this.privSpeechSynthesizer = speechSynthesizer;\n    }\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    setSection(sectionName, value) {\n        this.privContext[sectionName] = value;\n    }\n    /**\n     * Sets the audio output format for synthesis context generation.\n     * @param format {AudioOutputFormatImpl} the output format\n     */\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    toJSON() {\n        const synthesisSection = this.buildSynthesisContext();\n        this.setSection(\"synthesis\", synthesisSection);\n        return JSON.stringify(this.privContext);\n    }\n    buildSynthesisContext() {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"].SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n            }\n        };\n    }\n}\n\n//# sourceMappingURL=SynthesisContext.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js ***!
  \*****************************************************************************************************************/
/*! exports provided: SpeechSynthesisEvent, SynthesisTriggeredEvent, ConnectingToSynthesisServiceEvent, SynthesisStartedEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisEvent\", function() { return SpeechSynthesisEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisTriggeredEvent\", function() { return SynthesisTriggeredEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectingToSynthesisServiceEvent\", function() { return ConnectingToSynthesisServiceEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisStartedEvent\", function() { return SynthesisStartedEvent; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechSynthesisEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, requestId, eventType = _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n        this.privRequestId = requestId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n}\nclass SynthesisTriggeredEvent extends SpeechSynthesisEvent {\n    constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {\n        super(\"SynthesisTriggeredEvent\", requestId);\n        this.privSessionAudioDestinationId = sessionAudioDestinationId;\n        this.privTurnAudioDestinationId = turnAudioDestinationId;\n    }\n    get audioSessionDestinationId() {\n        return this.privSessionAudioDestinationId;\n    }\n    get audioTurnDestinationId() {\n        return this.privTurnAudioDestinationId;\n    }\n}\nclass ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"ConnectingToSynthesisServiceEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\nclass SynthesisStartedEvent extends SpeechSynthesisEvent {\n    constructor(requestId, authFetchEventId) {\n        super(\"SynthesisStartedEvent\", requestId);\n        this.privAuthFetchEventId = authFetchEventId;\n    }\n    get authFetchEventId() {\n        return this.privAuthFetchEventId;\n    }\n}\n\n//# sourceMappingURL=SynthesisEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js ***!
  \**********************************************************************************************************************/
/*! exports provided: SynthesisRestAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisRestAdapter\", function() { return SynthesisRestAdapter; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SynthesisRestAdapter\n */\nclass SynthesisRestAdapter {\n    constructor(config, authentication) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Region, \"westus\");\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n            endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);\n        }\n        this.privUri = `${endpoint}/cognitiveservices/voices/list`;\n        const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestConfigBase\"].requestOptions;\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestMessageAdapter\"](options);\n        this.privAuthentication = authentication;\n    }\n    /**\n     * Sends list voices request to endpoint.\n     * @function\n     * @public\n     * @param connectionId - guid for connectionId\n     * @returns {Promise<IRestResponse>} rest response to status request\n     */\n    getVoicesList(connectionId) {\n        this.privRestAdapter.setHeaders(_HeaderNames__WEBPACK_IMPORTED_MODULE_3__[\"HeaderNames\"].ConnectionId, connectionId);\n        return this.privAuthentication.fetch(connectionId).then((authInfo) => {\n            this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);\n            return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Get, this.privUri);\n        });\n    }\n}\n\n//# sourceMappingURL=SynthesisRestAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js ***!
  \***************************************************************************************************************/
/*! exports provided: SynthesisTurn */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisTurn\", function() { return SynthesisTurn; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SynthesisEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\nclass SynthesisTurn {\n    constructor() {\n        this.privIsDisposed = false;\n        this.privIsSynthesizing = false;\n        this.privIsSynthesisEnded = false;\n        this.privBytesReceived = 0;\n        this.privInTurn = false;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        // We're not in a turn, so resolve.\n        this.privTurnDeferral.resolve();\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get streamId() {\n        return this.privStreamId;\n    }\n    set streamId(value) {\n        this.privStreamId = value;\n    }\n    get audioOutputFormat() {\n        return this.privAudioOutputFormat;\n    }\n    set audioOutputFormat(format) {\n        this.privAudioOutputFormat = format;\n    }\n    get turnCompletionPromise() {\n        return this.privTurnDeferral.promise;\n    }\n    get isSynthesisEnded() {\n        return this.privIsSynthesisEnded;\n    }\n    get isSynthesizing() {\n        return this.privIsSynthesizing;\n    }\n    get currentTextOffset() {\n        return this.privTextOffset;\n    }\n    get currentSentenceOffset() {\n        return this.privSentenceOffset;\n    }\n    // The number of bytes received for current turn\n    get bytesReceived() {\n        return this.privBytesReceived;\n    }\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n    getAllReceivedAudio() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privReceivedAudio) {\n                return Promise.resolve(this.privReceivedAudio);\n            }\n            if (!this.privIsSynthesisEnded) {\n                return null;\n            }\n            yield this.readAllAudioFromStream();\n            return Promise.resolve(this.privReceivedAudio);\n        });\n    }\n    getAllReceivedAudioWithHeader() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privReceivedAudioWithHeader) {\n                return this.privReceivedAudioWithHeader;\n            }\n            if (!this.privIsSynthesisEnded) {\n                return null;\n            }\n            if (this.audioOutputFormat.hasHeader) {\n                const audio = yield this.getAllReceivedAudio();\n                this.privReceivedAudioWithHeader = _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_3__[\"SynthesisAdapterBase\"].addHeader(audio, this.audioOutputFormat);\n                return this.privReceivedAudioWithHeader;\n            }\n            else {\n                return this.getAllReceivedAudio();\n            }\n        });\n    }\n    startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n        this.privIsSynthesisEnded = false;\n        this.privIsSynthesizing = true;\n        this.privRequestId = requestId;\n        this.privRawText = rawText;\n        this.privIsSSML = isSSML;\n        this.privAudioOutputStream = new _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__[\"PullAudioOutputStreamImpl\"]();\n        this.privAudioOutputStream.format = this.privAudioOutputFormat;\n        this.privReceivedAudio = null;\n        this.privReceivedAudioWithHeader = null;\n        this.privBytesReceived = 0;\n        this.privTextOffset = 0;\n        this.privNextSearchTextIndex = 0;\n        this.privSentenceOffset = 0;\n        this.privNextSearchSentenceIndex = 0;\n        this.privPartialVisemeAnimation = \"\";\n        if (audioDestination !== undefined) {\n            this.privTurnAudioDestination = audioDestination;\n            this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n        }\n        this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__[\"SynthesisTriggeredEvent\"](this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n    }\n    onPreConnectionStart(authFetchEventId) {\n        this.privAuthFetchEventId = authFetchEventId;\n        this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__[\"ConnectingToSynthesisServiceEvent\"](this.privRequestId, this.privAuthFetchEventId));\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__[\"SynthesisStartedEvent\"](this.requestId, this.privAuthFetchEventId));\n            this.privBytesReceived = 0;\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceResponseMessage(responseJson) {\n        const response = JSON.parse(responseJson);\n        this.streamId = response.audio.streamId;\n    }\n    onServiceTurnEndResponse() {\n        this.privInTurn = false;\n        this.privTurnDeferral.resolve();\n        this.onComplete();\n    }\n    onServiceTurnStartResponse() {\n        if (!!this.privTurnDeferral && !!this.privInTurn) {\n            // What? How are we starting a turn with another not done?\n            this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n            // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            this.privTurnDeferral.promise.then().catch(() => { });\n        }\n        this.privInTurn = true;\n        this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n    }\n    onAudioChunkReceived(data) {\n        if (this.isSynthesizing) {\n            this.privAudioOutputStream.write(data);\n            this.privBytesReceived += data.byteLength;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.write(data);\n            }\n        }\n    }\n    onTextBoundaryEvent(metadata) {\n        this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n    }\n    onVisemeMetadataReceived(metadata) {\n        if (metadata.Data.AnimationChunk !== undefined) {\n            this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n        }\n    }\n    onSessionEnd(metadata) {\n        this.privAudioDuration = metadata.Data.Offset;\n    }\n    dispose() {\n        if (!this.privIsDisposed) {\n            // we should have completed by now. If we did not its an unknown error.\n            this.privIsDisposed = true;\n        }\n    }\n    onStopSynthesizing() {\n        this.onComplete();\n    }\n    /**\n     * Gets the viseme animation string (merged from animation chunk), and clears the internal\n     * partial animation.\n     */\n    getAndClearVisemeAnimation() {\n        const animation = this.privPartialVisemeAnimation;\n        this.privPartialVisemeAnimation = \"\";\n        return animation;\n    }\n    onEvent(event) {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Events\"].instance.onEvent(event);\n    }\n    /**\n     * Check if the text is an XML(SSML) tag\n     * @param text\n     * @private\n     */\n    static isXmlTag(text) {\n        return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n    }\n    updateTextOffset(text, type) {\n        if (type === _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_2__[\"MetadataType\"].WordBoundary) {\n            this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n            if (this.privTextOffset >= 0) {\n                this.privNextSearchTextIndex = this.privTextOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n        else {\n            this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n            if (this.privSentenceOffset >= 0) {\n                this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n                if (this.privIsSSML) {\n                    if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n                        this.updateTextOffset(text, type);\n                    }\n                }\n            }\n        }\n    }\n    onComplete() {\n        if (this.privIsSynthesizing) {\n            this.privIsSynthesizing = false;\n            this.privIsSynthesisEnded = true;\n            this.privAudioOutputStream.close();\n            this.privInTurn = false;\n            if (this.privTurnAudioDestination !== undefined) {\n                this.privTurnAudioDestination.close();\n                this.privTurnAudioDestination = undefined;\n            }\n        }\n    }\n    readAllAudioFromStream() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privIsSynthesisEnded) {\n                this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n                try {\n                    yield this.privAudioOutputStream.read(this.privReceivedAudio);\n                }\n                catch (e) {\n                    this.privReceivedAudio = new ArrayBuffer(0);\n                }\n            }\n        });\n    }\n    /**\n     * Check if current idx is in XML(SSML) tag\n     * @param idx\n     * @private\n     */\n    withinXmlTag(idx) {\n        return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n    }\n}\n\n//# sourceMappingURL=SynthesisTurn.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SynthesisServiceType, SynthesizerConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisServiceType\", function() { return SynthesisServiceType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesizerConfig\", function() { return SynthesizerConfig; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar SynthesisServiceType;\n(function (SynthesisServiceType) {\n    SynthesisServiceType[SynthesisServiceType[\"Standard\"] = 0] = \"Standard\";\n    SynthesisServiceType[SynthesisServiceType[\"Custom\"] = 1] = \"Custom\";\n})(SynthesisServiceType || (SynthesisServiceType = {}));\nclass SynthesizerConfig {\n    constructor(speechServiceConfig, parameters) {\n        this.privSynthesisServiceType = SynthesisServiceType.Standard;\n        this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechServiceConfig\"](new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](null));\n        this.privParameters = parameters;\n    }\n    get parameters() {\n        return this.privParameters;\n    }\n    get synthesisServiceType() {\n        return this.privSynthesisServiceType;\n    }\n    set synthesisServiceType(value) {\n        this.privSynthesisServiceType = value;\n    }\n    get SpeechServiceConfig() {\n        return this.privSpeechServiceConfig;\n    }\n}\n\n//# sourceMappingURL=SynthesizerConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranscriberConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranscriberConnectionFactory\", function() { return TranscriberConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass TranscriberConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"] {\n    constructor() {\n        super(...arguments);\n        this.multiaudioRelativeUri = \"/speech/recognition/multiaudio\";\n    }\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Region, \"centralus\");\n        const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n        const hostDefault = \"wss://transcribe.\" + region + \".cts.speech\" + hostSuffix + this.multiaudioRelativeUri;\n        const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, hostDefault);\n        const queryParams = {};\n        const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_EndpointId, undefined);\n        const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, undefined);\n        if (endpointId) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].CustomSpeechDeploymentId) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].CustomSpeechDeploymentId] = endpointId;\n            }\n        }\n        else if (language) {\n            if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Language) === -1) {\n                queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Language] = language;\n            }\n        }\n        const wordLevelTimings = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase() === \"true\";\n        const detailed = config.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormatPropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"].Simple]) !== _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"].Simple];\n        if (wordLevelTimings || detailed) {\n            queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].Format] = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"].Detailed].toLowerCase();\n        }\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        if (!endpoint) {\n            endpoint = host;\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=TranscriberConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationConnectionConfig\", function() { return ConversationConnectionConfig; });\n/* harmony import */ var _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/RestConfigBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionConfig extends _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__[\"RestConfigBase\"] {\n    static get host() {\n        return ConversationConnectionConfig.privHost;\n    }\n    static get apiVersion() {\n        return ConversationConnectionConfig.privApiVersion;\n    }\n    static get clientAppId() {\n        return ConversationConnectionConfig.privClientAppId;\n    }\n    static get defaultLanguageCode() {\n        return ConversationConnectionConfig.privDefaultLanguageCode;\n    }\n    static get restPath() {\n        return ConversationConnectionConfig.privRestPath;\n    }\n    static get webSocketPath() {\n        return ConversationConnectionConfig.privWebSocketPath;\n    }\n    static get speechHost() {\n        return ConversationConnectionConfig.privSpeechHost;\n    }\n    static get speechPath() {\n        return ConversationConnectionConfig.privSpeechPath;\n    }\n    static get transcriptionEventKeys() {\n        return ConversationConnectionConfig.privTranscriptionEventKeys;\n    }\n}\nConversationConnectionConfig.privHost = \"dev.microsofttranslator.com\";\nConversationConnectionConfig.privRestPath = \"/capito/room\";\nConversationConnectionConfig.privApiVersion = \"2.0\";\nConversationConnectionConfig.privDefaultLanguageCode = \"en-US\";\nConversationConnectionConfig.privClientAppId = \"FC539C22-1767-4F1F-84BC-B4D811114F15\";\nConversationConnectionConfig.privWebSocketPath = \"/capito/translate\";\nConversationConnectionConfig.privSpeechHost = \"{region}.s2s.speech.microsoft.com\";\nConversationConnectionConfig.privSpeechPath = \"/speech/translation/cognitiveservices/v1\";\nConversationConnectionConfig.privTranscriptionEventKeys = [\"iCalUid\", \"callId\", \"organizer\", \"FLAC\", \"MTUri\", \"DifferentiateGuestSpeakers\", \"audiorecording\", \"Threadid\", \"OrganizerMri\", \"OrganizerTenantId\", \"UserToken\"];\n\n//# sourceMappingURL=ConversationConnectionConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \*********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationConnectionFactory\", function() { return ConversationConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n/**\n * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.\n * The conversation must already have been started or joined.\n */\nclass ConversationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_4__[\"ConnectionFactoryBase\"] {\n    create(config, authInfo, connectionId) {\n        const endpointHost = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Host, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].host);\n        const correlationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_CorrelationId, Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createGuid\"])());\n        const endpoint = `wss://${endpointHost}${_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].webSocketPath}`;\n        const token = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Token, undefined);\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(token, \"token\");\n        const queryParams = {};\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].configParams.apiVersion] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].apiVersion;\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].configParams.token] = token;\n        queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_5__[\"ConversationConnectionConfig\"].configParams.correlationId] = correlationId;\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, {}, new _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__[\"ConversationWebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=ConversationConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \*********************************************************************************************************************************************/
/*! exports provided: ConversationConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationConnectionMessage\", function() { return ConversationConnectionMessage; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionMessage\"] {\n    constructor(messageType, body, headers, id) {\n        super(messageType, body, headers, id);\n        const json = JSON.parse(this.textBody);\n        if (json.type !== undefined) {\n            this.privConversationMessageType = json.type;\n        }\n    }\n    get conversationMessageType() {\n        return this.privConversationMessageType;\n    }\n}\n\n//# sourceMappingURL=ConversationConnectionMessage.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ConversationManager */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationManager\", function() { return ConversationManager; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\nclass ConversationManager {\n    constructor() {\n        //\n        this.privRequestParams = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].configParams;\n        this.privErrors = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].restErrors;\n        this.privHost = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].host;\n        this.privApiVersion = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].apiVersion;\n        this.privRestPath = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].restPath;\n        this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestMessageAdapter\"]({});\n    }\n    /**\n     * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.\n     * @param args\n     * @param conversationCode\n     * @param callback\n     * @param errorCallback\n     */\n    createOrJoin(args, conversationCode, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(args, \"args\");\n            const languageCode = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].defaultLanguageCode);\n            const nickname = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_Name, \"conversation_host\");\n            const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_Host, this.privHost);\n            const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_CorrelationId);\n            const subscriptionKey = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key);\n            const subscriptionRegion = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region);\n            const authToken = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(languageCode, \"languageCode\");\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(nickname, \"nickname\");\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(endpointHost, \"endpointHost\");\n            const queryParams = {};\n            queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n            queryParams[this.privRequestParams.languageCode] = languageCode;\n            queryParams[this.privRequestParams.nickname] = nickname;\n            const headers = {};\n            if (correlationId) {\n                headers[this.privRequestParams.correlationId] = correlationId;\n            }\n            headers[this.privRequestParams.clientAppId] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionConfig\"].clientAppId;\n            if (conversationCode !== undefined) {\n                queryParams[this.privRequestParams.roomId] = conversationCode;\n            }\n            else {\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);\n                headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;\n                if (subscriptionKey) {\n                    headers[this.privRequestParams.subscriptionKey] = subscriptionKey;\n                }\n                else if (authToken) {\n                    headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;\n                }\n                else {\n                    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);\n                }\n            }\n            const config = {};\n            config.headers = headers;\n            this.privRestAdapter.options = config;\n            const endpoint = `https://${endpointHost}${this.privRestPath}`;\n            // TODO: support a proxy and certificate validation\n            this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Post, endpoint, queryParams, null).then((response) => {\n                const requestId = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestMessageAdapter\"].extractHeaderValue(this.privRequestParams.requestId, response.headers);\n                if (!response.ok) {\n                    if (!!err) {\n                        // get the error\n                        let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace(\"{status}\", response.status.toString());\n                        let errMessageRaw;\n                        try {\n                            errMessageRaw = JSON.parse(response.data);\n                            errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;\n                        }\n                        catch (e) {\n                            errorMessage += ` [${response.data}]`;\n                        }\n                        if (requestId) {\n                            errorMessage += ` ${requestId}`;\n                        }\n                        err(errorMessage);\n                    }\n                    return;\n                }\n                const conversation = JSON.parse(response.data);\n                if (conversation) {\n                    conversation.requestId = requestId;\n                }\n                if (!!cb) {\n                    try {\n                        cb(conversation);\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(e);\n                        }\n                    }\n                    cb = undefined;\n                }\n                // eslint-disable-next-line @typescript-eslint/no-empty-function\n            }).catch(() => { });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.\n     * @param args\n     * @param sessionToken\n     * @param callback\n     */\n    leave(args, sessionToken) {\n        return new Promise((resolve, reject) => {\n            try {\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n                _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace(\"{arg}\", \"token\"));\n                const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_Host, this.privHost);\n                const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].ConversationTranslator_CorrelationId);\n                const queryParams = {};\n                queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n                queryParams[this.privRequestParams.sessionToken] = sessionToken;\n                const headers = {};\n                if (correlationId) {\n                    headers[this.privRequestParams.correlationId] = correlationId;\n                }\n                const config = {};\n                config.headers = headers;\n                this.privRestAdapter.options = config;\n                const endpoint = `https://${endpointHost}${this.privRestPath}`;\n                // TODO: support a proxy and certificate validation\n                this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RestRequestType\"].Delete, endpoint, queryParams, null).then((response) => {\n                    if (!response.ok) {\n                        // ignore errors on delete\n                    }\n                    resolve();\n                    // eslint-disable-next-line @typescript-eslint/no-empty-function\n                }).catch(() => { });\n            }\n            catch (error) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    reject(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    reject(error);\n                }\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=ConversationManager.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \******************************************************************************************************************************************/
/*! exports provided: ConversationRequestSession */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationRequestSession\", function() { return ConversationRequestSession; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n/**\n * Placeholder class for the Conversation Request Session. Based off RequestSession.\n * TODO: define what telemetry is required.\n */\nclass ConversationRequestSession {\n    constructor(sessionId) {\n        this.privIsDisposed = false;\n        this.privDetachables = new Array();\n        this.privSessionId = sessionId;\n        this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privRequestCompletionDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n    get requestId() {\n        return this.privRequestId;\n    }\n    get completionPromise() {\n        return this.privRequestCompletionDeferral.promise;\n    }\n    onPreConnectionStart(authFetchEventId, connectionId) {\n        this.privSessionId = connectionId;\n    }\n    onAuthCompleted(isError) {\n        if (isError) {\n            this.onComplete();\n        }\n    }\n    onConnectionEstablishCompleted(statusCode) {\n        if (statusCode === 200) {\n            return;\n        }\n        else if (statusCode === 403) {\n            this.onComplete();\n        }\n    }\n    onServiceTurnEndResponse(continuousRecognition) {\n        if (!continuousRecognition) {\n            this.onComplete();\n        }\n        else {\n            this.privRequestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        }\n    }\n    dispose() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                // we should have completed by now. If we did not its an unknown error.\n                this.privIsDisposed = true;\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n            }\n        });\n    }\n    onComplete() {\n        //\n    }\n}\n\n//# sourceMappingURL=ConversationRequestSession.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \******************************************************************************************************************************************/
/*! exports provided: ConversationServiceAdapter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationServiceAdapter\", function() { return ConversationServiceAdapter; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n/* harmony import */ var _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationRequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js\");\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n\n/**\n * The service adapter handles sending and receiving messages to the Conversation Translator websocket.\n */\nclass ConversationServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);\n        this.privConnectionConfigPromise = undefined;\n        this.privLastPartialUtteranceId = \"\";\n        this.privConversationServiceConnector = conversationServiceConnector;\n        this.privConversationAuthentication = authentication;\n        this.receiveMessageOverride = () => this.receiveConversationMessageOverride();\n        this.recognizeOverride = () => this.noOp();\n        this.postConnectImplOverride = (connection) => this.conversationConnectImpl(connection);\n        this.configConnectionOverride = () => this.configConnection();\n        this.disconnectOverride = () => this.privDisconnect();\n        this.privConversationRequestSession = new _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_4__[\"ConversationRequestSession\"](Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])());\n        this.privConversationConnectionFactory = connectionFactory;\n        this.privConversationIsDisposed = false;\n    }\n    isDisposed() {\n        return super.isDisposed() || this.privConversationIsDisposed;\n    }\n    dispose(reason) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privConversationIsDisposed = true;\n            if (this.privConnectionConfigPromise !== undefined) {\n                const connection = yield this.privConnectionConfigPromise;\n                yield connection.dispose(reason);\n            }\n            yield _super.dispose.call(this, reason);\n        });\n    }\n    sendMessage(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            return connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, message));\n        });\n    }\n    sendMessageAsync(message) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const connection = yield this.fetchConnection();\n            yield connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__[\"ConversationConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, message));\n        });\n    }\n    privDisconnect() {\n        if (this.terminateMessageLoop) {\n            return;\n        }\n        this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].NoError, \"Disconnecting\");\n        this.terminateMessageLoop = true;\n        return Promise.resolve();\n    }\n    // eslint-disable-next-line @typescript-eslint/require-await\n    processTypeSpecificMessages() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return true;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        this.terminateMessageLoop = true;\n        const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConversationTranslationCanceledEventArgs\"](cancellationReason, error, errorCode, undefined, sessionId);\n        try {\n            if (!!this.privConversationServiceConnector.canceled) {\n                this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);\n            }\n        }\n        catch (_a) {\n            // continue on error\n        }\n    }\n    noOp() {\n        // operation not supported\n        return;\n    }\n    /**\n     * Establishes a websocket connection to the end point.\n     */\n    conversationConnectImpl(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privConnectionLoop = this.startMessageLoop();\n            return connection;\n        });\n    }\n    /**\n     * Process incoming websocket messages\n     */\n    receiveConversationMessageOverride() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.isDisposed() || this.terminateMessageLoop) {\n                return Promise.resolve();\n            }\n            // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n            const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n            try {\n                const connection = yield this.fetchConnection();\n                const message = yield connection.read();\n                if (this.isDisposed() || this.terminateMessageLoop) {\n                    // We're done.\n                    communicationCustodian.resolve();\n                    return Promise.resolve();\n                }\n                if (!message) {\n                    return this.receiveConversationMessageOverride();\n                }\n                const sessionId = this.privConversationRequestSession.sessionId;\n                let sendFinal = false;\n                try {\n                    switch (message.conversationMessageType.toLowerCase()) {\n                        case \"info\":\n                        case \"participant_command\":\n                        case \"command\":\n                            const commandPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__[\"CommandResponsePayload\"].fromJSON(message.textBody);\n                            switch (commandPayload.command.toLowerCase()) {\n                                /**\n                                 * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.\n                                 * The consuming client must wait for this message to arrive\n                                 * before starting to send their own data.\n                                 */\n                                case \"participantlist\":\n                                    const participantsPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__[\"ParticipantsListPayloadResponse\"].fromJSON(message.textBody);\n                                    const participantsResult = participantsPayload.participants.map((p) => {\n                                        const participant = {\n                                            avatar: p.avatar,\n                                            displayName: p.nickname,\n                                            id: p.participantId,\n                                            isHost: p.ishost,\n                                            isMuted: p.ismuted,\n                                            isUsingTts: p.usetts,\n                                            preferredLanguage: p.locale\n                                        };\n                                        return participant;\n                                    });\n                                    if (!!this.privConversationServiceConnector.participantsListReceived) {\n                                        this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantsListEventArgs\"](participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).\n                                 * This is sent at the start of the Conversation\n                                 */\n                                case \"settranslatetolanguages\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantAttributeEventArgs\"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorCommandTypes\"].setTranslateToLanguages, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetProfanityFiltering' lets the client set the level of profanity filtering.\n                                 * If sent by the participant the setting will effect only their own profanity level.\n                                 * If sent by the host, the setting will effect all participants including the host.\n                                 * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'\n                                 */\n                                case \"setprofanityfiltering\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantAttributeEventArgs\"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorCommandTypes\"].setProfanityFiltering, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetMute' is sent if the participant has been muted by the host.\n                                 * Check the 'participantId' to determine if the current user has been muted.\n                                 */\n                                case \"setmute\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantAttributeEventArgs\"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorCommandTypes\"].setMute, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetMuteAll' is sent if the Conversation has been muted by the host.\n                                 */\n                                case \"setmuteall\":\n                                    if (!!this.privConversationServiceConnector.muteAllCommandReceived) {\n                                        this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"MuteAllEventArgs\"](commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.\n                                 */\n                                case \"roomexpirationwarning\":\n                                    if (!!this.privConversationServiceConnector.conversationExpiration) {\n                                        this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConversationExpirationEventArgs\"](commandPayload.value, this.privConversationRequestSession.sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.\n                                 */\n                                case \"setusetts\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantAttributeEventArgs\"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorCommandTypes\"].setUseTTS, commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'SetLockState' is set if the host has locked or unlocked the Conversation.\n                                 */\n                                case \"setlockstate\":\n                                    if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {\n                                        this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"LockRoomEventArgs\"](commandPayload.value, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'ChangeNickname' is received if a user changes their display name.\n                                 * Any cached particpiants list should be updated to reflect the display name.\n                                 */\n                                case \"changenickname\":\n                                    if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                                        this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantAttributeEventArgs\"](commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorCommandTypes\"].changeNickname, commandPayload.nickname, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'JoinSession' is sent when a user joins the Conversation.\n                                 */\n                                case \"joinsession\":\n                                    const joinParticipantPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__[\"ParticipantPayloadResponse\"].fromJSON(message.textBody);\n                                    const joiningParticipant = {\n                                        avatar: joinParticipantPayload.avatar,\n                                        displayName: joinParticipantPayload.nickname,\n                                        id: joinParticipantPayload.participantId,\n                                        isHost: joinParticipantPayload.ishost,\n                                        isMuted: joinParticipantPayload.ismuted,\n                                        isUsingTts: joinParticipantPayload.usetts,\n                                        preferredLanguage: joinParticipantPayload.locale,\n                                    };\n                                    if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {\n                                        this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantEventArgs\"](joiningParticipant, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'LeaveSession' is sent when a user leaves the Conversation'.\n                                 */\n                                case \"leavesession\":\n                                    const leavingParticipant = {\n                                        id: commandPayload.participantId\n                                    };\n                                    if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {\n                                        this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ParticipantEventArgs\"](leavingParticipant, sessionId));\n                                    }\n                                    break;\n                                /**\n                                 * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).\n                                 * Check the 'ParticipantId' to check whether the message is for the current user.\n                                 */\n                                case \"disconnectsession\":\n                                    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n                                    const disconnectParticipant = {\n                                        id: commandPayload.participantId\n                                    };\n                                    break;\n                                case \"token\":\n                                    const token = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CognitiveTokenAuthentication\"](() => {\n                                        const authorizationToken = commandPayload.token;\n                                        return Promise.resolve(authorizationToken);\n                                    }, () => {\n                                        const authorizationToken = commandPayload.token;\n                                        return Promise.resolve(authorizationToken);\n                                    });\n                                    this.authentication = token;\n                                    break;\n                                /**\n                                 * Message not recognized.\n                                 */\n                                default:\n                                    break;\n                            }\n                            break;\n                        /**\n                         * 'partial' (or 'hypothesis') represents a unfinalized speech message.\n                         */\n                        case \"partial\":\n                        /**\n                         * 'final' (or 'phrase') represents a finalized speech message.\n                         */\n                        case \"final\":\n                            const speechPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__[\"SpeechResponsePayload\"].fromJSON(message.textBody);\n                            const speechResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConversationTranslationResult\"](speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, undefined, undefined, speechPayload.recognition, undefined, undefined, message.textBody, undefined);\n                            if (speechPayload.isFinal) {\n                                // check the length, sometimes empty finals are returned\n                                if (speechResult.text !== undefined && speechResult.text.length > 0) {\n                                    sendFinal = true;\n                                }\n                                else if (speechPayload.id === this.privLastPartialUtteranceId) {\n                                    // send final as normal. We had a non-empty partial for this same utterance\n                                    // so sending the empty final is important\n                                    sendFinal = true;\n                                }\n                                else {\n                                    // suppress unneeded final\n                                }\n                                if (sendFinal) {\n                                    if (!!this.privConversationServiceConnector.translationReceived) {\n                                        this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ConversationReceivedTranslationEventArgs\"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorMessageTypes\"].final, speechResult, sessionId));\n                                    }\n                                }\n                            }\n                            else if (speechResult.text !== undefined) {\n                                this.privLastPartialUtteranceId = speechPayload.id;\n                                if (!!this.privConversationServiceConnector.translationReceived) {\n                                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ConversationReceivedTranslationEventArgs\"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorMessageTypes\"].partial, speechResult, sessionId));\n                                }\n                            }\n                            break;\n                        /**\n                         * \"translated_message\" is a text message or instant message (IM).\n                         */\n                        case \"translated_message\":\n                            const textPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_7__[\"TextResponsePayload\"].fromJSON(message.textBody);\n                            const textResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConversationTranslationResult\"](textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);\n                            if (!!this.privConversationServiceConnector.translationReceived) {\n                                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ConversationReceivedTranslationEventArgs\"](_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslatorMessageTypes\"].instantMessage, textResult, sessionId));\n                            }\n                            break;\n                        default:\n                            // ignore any unsupported message types\n                            break;\n                    }\n                }\n                catch (e) {\n                    // continue\n                }\n                return this.receiveConversationMessageOverride();\n            }\n            catch (e) {\n                this.terminateMessageLoop = true;\n            }\n            return communicationCustodian.promise;\n        });\n    }\n    startMessageLoop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.isDisposed()) {\n                return Promise.resolve();\n            }\n            this.terminateMessageLoop = false;\n            const messageRetrievalPromise = this.receiveConversationMessageOverride();\n            try {\n                const r = yield messageRetrievalPromise;\n                return r;\n            }\n            catch (error) {\n                this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : \"\", this.privRequestSession ? this.privRequestSession.requestId : \"\", _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].RuntimeError, error);\n                return null;\n            }\n        });\n    }\n    // Takes an established websocket connection to the endpoint\n    configConnection() {\n        if (this.isDisposed()) {\n            return Promise.resolve(undefined);\n        }\n        if (this.privConnectionConfigPromise !== undefined) {\n            return this.privConnectionConfigPromise.then((connection) => {\n                if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionState\"].Disconnected) {\n                    this.privConnectionId = null;\n                    this.privConnectionConfigPromise = undefined;\n                    return this.configConnection();\n                }\n                return this.privConnectionConfigPromise;\n            }, () => {\n                this.privConnectionId = null;\n                this.privConnectionConfigPromise = undefined;\n                return this.configConnection();\n            });\n        }\n        if (this.terminateMessageLoop) {\n            return Promise.resolve(undefined);\n        }\n        this.privConnectionConfigPromise = this.connectImpl().then((connection) => connection);\n        return this.privConnectionConfigPromise;\n    }\n    getTranslations(serviceResultTranslations) {\n        let translations;\n        if (undefined !== serviceResultTranslations) {\n            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Translations\"]();\n            for (const translation of serviceResultTranslations) {\n                translations.set(translation.lang, translation.translation);\n            }\n        }\n        return translations;\n    }\n}\n\n//# sourceMappingURL=ConversationServiceAdapter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \***********************************************************************************************************************************************/
/*! exports provided: MuteAllEventArgs, LockRoomEventArgs, ParticipantEventArgs, ParticipantAttributeEventArgs, ParticipantsListEventArgs, ConversationReceivedTranslationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MuteAllEventArgs\", function() { return MuteAllEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LockRoomEventArgs\", function() { return LockRoomEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantEventArgs\", function() { return ParticipantEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantAttributeEventArgs\", function() { return ParticipantAttributeEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantsListEventArgs\", function() { return ParticipantsListEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationReceivedTranslationEventArgs\", function() { return ConversationReceivedTranslationEventArgs; });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass MuteAllEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(isMuted, sessionId) {\n        super(sessionId);\n        this.privIsMuted = isMuted;\n    }\n    get isMuted() {\n        return this.privIsMuted;\n    }\n}\nclass LockRoomEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(isLocked, sessionId) {\n        super(sessionId);\n        this.privIsLocked = isLocked;\n    }\n    get isMuted() {\n        return this.privIsLocked;\n    }\n}\nclass ParticipantEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(participant, sessionId) {\n        super(sessionId);\n        this.privParticipant = participant;\n    }\n    get participant() {\n        return this.privParticipant;\n    }\n}\nclass ParticipantAttributeEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(participantId, key, value, sessionId) {\n        super(sessionId);\n        this.privKey = key;\n        this.privValue = value;\n        this.privParticipantId = participantId;\n    }\n    get value() {\n        return this.privValue;\n    }\n    get key() {\n        return this.privKey;\n    }\n    get id() {\n        return this.privParticipantId;\n    }\n}\nclass ParticipantsListEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {\n        super(sessionId);\n        this.privRoomId = conversationId;\n        this.privSessionToken = token;\n        this.privTranslateTo = translateTo;\n        this.privProfanityFilter = profanityFilter;\n        this.privRoomProfanityFilter = roomProfanityFilter;\n        this.privIsRoomLocked = isRoomLocked;\n        this.privIsRoomLocked = isMuteAll;\n        this.privParticipants = participants;\n    }\n    get sessionToken() {\n        return this.privSessionToken;\n    }\n    get conversationId() {\n        return this.privRoomId;\n    }\n    get translateTo() {\n        return this.privTranslateTo;\n    }\n    get profanityFilter() {\n        return this.privProfanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privRoomProfanityFilter;\n    }\n    get isRoomLocked() {\n        return this.privIsRoomLocked;\n    }\n    get isMuteAll() {\n        return this.privIsMuteAll;\n    }\n    get participants() {\n        return this.privParticipants;\n    }\n}\nclass ConversationReceivedTranslationEventArgs {\n    constructor(command, payload, sessionId) {\n        this.privPayload = payload;\n        this.privCommand = command;\n        this.privSessionId = sessionId;\n    }\n    get payload() {\n        return this.privPayload;\n    }\n    get command() {\n        return this.privCommand;\n    }\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\n\n//# sourceMappingURL=ConversationTranslatorEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \************************************************************************************************************************************************/
/*! exports provided: InternalParticipants, ConversationTranslatorMessageTypes, ConversationTranslatorCommandTypes */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"InternalParticipants\", function() { return InternalParticipants; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorMessageTypes\", function() { return ConversationTranslatorMessageTypes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorCommandTypes\", function() { return ConversationTranslatorCommandTypes; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/** Users participating in the conversation */\nclass InternalParticipants {\n    constructor(participants = [], meId) {\n        this.participants = participants;\n        this.meId = meId;\n    }\n    /**\n     * Add or update a participant\n     * @param value\n     */\n    addOrUpdateParticipant(value) {\n        if (value === undefined) {\n            return;\n        }\n        const exists = this.getParticipantIndex(value.id);\n        if (exists > -1) {\n            this.participants.splice(exists, 1, value);\n        }\n        else {\n            this.participants.push(value);\n        }\n        // ensure it was added ok\n        return this.getParticipant(value.id);\n    }\n    /**\n     * Find the participant's position in the participants list.\n     * @param id\n     */\n    getParticipantIndex(id) {\n        return this.participants.findIndex((p) => p.id === id);\n    }\n    /**\n     * Find the participant by id.\n     * @param id\n     */\n    getParticipant(id) {\n        return this.participants.find((p) => p.id === id);\n    }\n    /**\n     * Remove a participant from the participants list.\n     */\n    deleteParticipant(id) {\n        this.participants = this.participants.filter((p) => p.id !== id);\n    }\n    /**\n     * Helper to return the conversation host.\n     */\n    get host() {\n        return this.participants.find((p) => p.isHost === true);\n    }\n    /**\n     * Helper to return the current user.\n     */\n    get me() {\n        return this.getParticipant(this.meId);\n    }\n}\n/**\n * List of command message types\n */\nconst ConversationTranslatorMessageTypes = {\n    command: \"command\",\n    final: \"final\",\n    info: \"info\",\n    instantMessage: \"instant_message\",\n    keepAlive: \"keep_alive\",\n    partial: \"partial\",\n    participantCommand: \"participant_command\",\n    translatedMessage: \"translated_message\"\n};\n/**\n * List of command types\n */\nconst ConversationTranslatorCommandTypes = {\n    changeNickname: \"ChangeNickname\",\n    disconnectSession: \"DisconnectSession\",\n    ejectParticipant: \"EjectParticipant\",\n    instant_message: \"instant_message\",\n    joinSession: \"JoinSession\",\n    leaveSession: \"LeaveSession\",\n    participantList: \"ParticipantList\",\n    roomExpirationWarning: \"RoomExpirationWarning\",\n    setLockState: \"SetLockState\",\n    setMute: \"SetMute\",\n    setMuteAll: \"SetMuteAll\",\n    setProfanityFiltering: \"SetProfanityFiltering\",\n    setTranslateToLanguages: \"SetTranslateToLanguages\",\n    setUseTTS: \"SetUseTTS\"\n};\n\n//# sourceMappingURL=ConversationTranslatorInterfaces.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \************************************************************************************************************************************************/
/*! exports provided: ConversationRecognizerFactory, ConversationTranslatorRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationRecognizerFactory\", function() { return ConversationRecognizerFactory; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorRecognizer\", function() { return ConversationTranslatorRecognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js\");\n/* harmony import */ var _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n\n\nclass ConversationRecognizerFactory {\n    static fromConfig(conversation, speechConfig, audioConfig) {\n        return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);\n    }\n}\n/**\n * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.\n * Based off the recognizers in the SDK folder.\n */\nclass ConversationTranslatorRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__[\"Recognizer\"] {\n    constructor(conversation, speechConfig, audioConfig) {\n        const serviceConfigImpl = speechConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(serviceConfigImpl, \"speechConfig\");\n        const conversationImpl = conversation;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(conversationImpl, \"conversationImpl\");\n        super(audioConfig, serviceConfigImpl.properties, new _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[\"ConversationConnectionFactory\"]());\n        this.privConversation = conversationImpl;\n        this.privIsDisposed = false;\n        this.privProperties = serviceConfigImpl.properties.clone();\n        this.privConnection = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__[\"Connection\"].fromRecognizer(this);\n        this.privSetTimeout = (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Timeout\"].setTimeout : setTimeout;\n        this.privClearTimeout = (typeof (Blob) !== \"undefined\" && typeof (Worker) !== \"undefined\") ? _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Timeout\"].clearTimeout : clearTimeout;\n    }\n    set connected(cb) {\n        this.privConnection.connected = cb;\n    }\n    set disconnected(cb) {\n        this.privConnection.disconnected = cb;\n    }\n    /**\n     * Return the speech language used by the recognizer\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechRecognitionLanguage;\n    }\n    /**\n     * Return the properties for the recognizer\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    /**\n     * Connect to the recognizer\n     * @param token\n     */\n    connect(token, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n            this.privReco.conversationTranslatorToken = token;\n            this.resetConversationTimeout();\n            this.privReco.connectAsync(cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n        }\n    }\n    /**\n     * Disconnect from the recognizer\n     */\n    disconnect(cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            if (this.privTimeoutToken !== undefined) {\n                // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                this.privClearTimeout(this.privTimeoutToken);\n            }\n            this.privReco.disconnect().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"BackgroundEvent\"](reason));\n            });\n        }\n    }\n    /**\n     * Send the mute all participants command to the websocket\n     * @param conversationId\n     * @param participantId\n     * @param isMuted\n     */\n    sendRequest(command, cb, err) {\n        try {\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            this.sendMessage(command, cb, err);\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the recognizer.\n            this.dispose(true).catch((reason) => {\n                _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"BackgroundEvent\"](reason));\n            });\n        }\n    }\n    /**\n     * Close and dispose the recognizer\n     */\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privIsDisposed) {\n                if (!!this.privConnection) {\n                    this.privConnection.closeConnection();\n                    this.privConnection.close();\n                }\n                this.privConnection = undefined;\n                yield this.dispose(true);\n            }\n        });\n    }\n    /**\n     * Dispose the recognizer\n     * @param disposing\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privIsDisposed) {\n                return;\n            }\n            if (disposing) {\n                if (this.privTimeoutToken !== undefined) {\n                    // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n                    this.privClearTimeout(this.privTimeoutToken);\n                }\n                this.privIsDisposed = true;\n                if (!!this.privConnection) {\n                    this.privConnection.closeConnection();\n                    this.privConnection.close();\n                    this.privConnection = undefined;\n                }\n                yield _super.dispose.call(this, disposing);\n            }\n        });\n    }\n    /**\n     * Create the config for the recognizer\n     * @param speechConfig\n     */\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognizerConfig\"](speechConfig, this.privProperties);\n    }\n    /**\n     * Create the service recognizer.\n     * The audio source is redundnant here but is required by the implementation.\n     * @param authentication\n     * @param connectionFactory\n     * @param audioConfig\n     * @param recognizerConfig\n     */\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioSource = audioConfig;\n        return new _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_5__[\"ConversationServiceAdapter\"](authentication, connectionFactory, audioSource, recognizerConfig, this);\n    }\n    sendMessage(msg, cb, err) {\n        const withAsync = this.privReco;\n        const PromiseToEmptyCallback = (promise, cb, err) => {\n            if (promise !== undefined) {\n                promise.then(() => {\n                    try {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(`'Unhandled error on promise callback: ${e}'`);\n                        }\n                    }\n                }, (reason) => {\n                    try {\n                        if (!!err) {\n                            err(reason);\n                        }\n                        // eslint-disable-next-line no-empty\n                    }\n                    catch (error) { }\n                });\n            }\n            else {\n                if (!!err) {\n                    err(\"Null promise\");\n                }\n            }\n        };\n        PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);\n        this.resetConversationTimeout();\n    }\n    resetConversationTimeout() {\n        if (this.privTimeoutToken !== undefined) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            this.privClearTimeout(this.privTimeoutToken);\n        }\n        this.privTimeoutToken = this.privSetTimeout(() => {\n            this.sendRequest(this.privConversation.getKeepAlive());\n        }, 60000);\n    }\n}\n\n//# sourceMappingURL=ConversationTranslatorRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
/*!*****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \*****************************************************************************************************************************************************/
/*! exports provided: ConversationWebsocketMessageFormatter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationWebsocketMessageFormatter\", function() { return ConversationWebsocketMessageFormatter; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.\n */\nclass ConversationWebsocketMessageFormatter {\n    /**\n     * Format incoming messages: text (speech partial/final, IM) or binary (tts)\n     */\n    toConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n                const incomingMessage = new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__[\"ConversationConnectionMessage\"](message.messageType, message.textContent, {}, message.id);\n                deferral.resolve(incomingMessage);\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary) {\n                deferral.resolve(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_1__[\"ConversationConnectionMessage\"](message.messageType, message.binaryContent, undefined, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    /**\n     * Format outgoing messages: text (commands or IM)\n     */\n    fromConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n                const payload = `${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RawWebsocketMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n}\n\n//# sourceMappingURL=ConversationWebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js ***!
  \***********************************************************************************************************************/
/*! exports provided: ConversationManager, ConversationConnectionConfig, ConversationRecognizerFactory, TranscriberRecognizer, ConversationReceivedTranslationEventArgs, LockRoomEventArgs, MuteAllEventArgs, ParticipantAttributeEventArgs, ParticipantEventArgs, ParticipantsListEventArgs, ConversationTranslatorCommandTypes, ConversationTranslatorMessageTypes, InternalParticipants */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _ConversationManager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationManager\", function() { return _ConversationManager__WEBPACK_IMPORTED_MODULE_0__[\"ConversationManager\"]; });\n\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationConnectionConfig\", function() { return _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__[\"ConversationConnectionConfig\"]; });\n\n/* harmony import */ var _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationTranslatorRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationRecognizerFactory\", function() { return _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__[\"ConversationRecognizerFactory\"]; });\n\n/* harmony import */ var _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./TranscriberRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranscriberRecognizer\", function() { return _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__[\"TranscriberRecognizer\"]; });\n\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationReceivedTranslationEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"ConversationReceivedTranslationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LockRoomEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"LockRoomEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MuteAllEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"MuteAllEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantAttributeEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"ParticipantAttributeEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"ParticipantEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantsListEventArgs\", function() { return _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"ParticipantsListEventArgs\"]; });\n\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorCommandTypes\", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__[\"ConversationTranslatorCommandTypes\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslatorMessageTypes\", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__[\"ConversationTranslatorMessageTypes\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"InternalParticipants\", function() { return _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__[\"InternalParticipants\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
/*!******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \******************************************************************************************************************************************************/
/*! exports provided: CommandResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CommandResponsePayload\", function() { return CommandResponsePayload; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseCommandResponse = (json) => JSON.parse(json);\nclass CommandResponsePayload {\n    constructor(json) {\n        this.privCommandResponse = parseCommandResponse(json);\n    }\n    get type() {\n        return this.privCommandResponse.type;\n    }\n    get command() {\n        return this.privCommandResponse.command;\n    }\n    get id() {\n        return this.privCommandResponse.id;\n    }\n    get nickname() {\n        return this.privCommandResponse.nickname;\n    }\n    get participantId() {\n        return this.privCommandResponse.participantId;\n    }\n    get roomid() {\n        return this.privCommandResponse.roomid;\n    }\n    get value() {\n        return this.privCommandResponse.value;\n    }\n    get token() {\n        return this.privCommandResponse.token;\n    }\n    static fromJSON(json) {\n        return new CommandResponsePayload(json);\n    }\n}\n\n//# sourceMappingURL=CommandResponsePayload.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js ***!
  \***************************************************************************************************************************************/
/*! exports provided: CommandResponsePayload, ParticipantsListPayloadResponse, ParticipantPayloadResponse, SpeechResponsePayload, TextResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _CommandResponsePayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CommandResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CommandResponsePayload\", function() { return _CommandResponsePayload__WEBPACK_IMPORTED_MODULE_0__[\"CommandResponsePayload\"]; });\n\n/* harmony import */ var _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ParticipantResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantsListPayloadResponse\", function() { return _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__[\"ParticipantsListPayloadResponse\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantPayloadResponse\", function() { return _ParticipantResponsePayload__WEBPACK_IMPORTED_MODULE_1__[\"ParticipantPayloadResponse\"]; });\n\n/* harmony import */ var _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TranslationResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechResponsePayload\", function() { return _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__[\"SpeechResponsePayload\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TextResponsePayload\", function() { return _TranslationResponsePayload__WEBPACK_IMPORTED_MODULE_2__[\"TextResponsePayload\"]; });\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/*! exports provided: ParticipantsListPayloadResponse, ParticipantPayloadResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantsListPayloadResponse\", function() { return ParticipantsListPayloadResponse; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantPayloadResponse\", function() { return ParticipantPayloadResponse; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseListResponse = (json) => JSON.parse(json);\nconst parseParticipantResponse = (json) => JSON.parse(json);\nclass ParticipantsListPayloadResponse {\n    constructor(json) {\n        this.privParticipantsPayloadResponse = parseListResponse(json);\n    }\n    get roomid() {\n        return this.privParticipantsPayloadResponse.roomid;\n    }\n    get id() {\n        return this.privParticipantsPayloadResponse.id;\n    }\n    get command() {\n        return this.privParticipantsPayloadResponse.command;\n    }\n    get participants() {\n        return this.privParticipantsPayloadResponse.participants;\n    }\n    get token() {\n        return this.privParticipantsPayloadResponse.token;\n    }\n    get translateTo() {\n        return this.privParticipantsPayloadResponse.translateTo;\n    }\n    get profanityFilter() {\n        return this.privParticipantsPayloadResponse.profanityFilter;\n    }\n    get roomProfanityFilter() {\n        return this.privParticipantsPayloadResponse.roomProfanityFilter;\n    }\n    get roomLocked() {\n        return this.privParticipantsPayloadResponse.roomLocked;\n    }\n    get muteAll() {\n        return this.privParticipantsPayloadResponse.muteAll;\n    }\n    get type() {\n        return this.privParticipantsPayloadResponse.type;\n    }\n    static fromJSON(json) {\n        return new ParticipantsListPayloadResponse(json);\n    }\n}\nclass ParticipantPayloadResponse {\n    constructor(json) {\n        this.privParticipantPayloadResponse = parseParticipantResponse(json);\n    }\n    get nickname() {\n        return this.privParticipantPayloadResponse.nickname;\n    }\n    get locale() {\n        return this.privParticipantPayloadResponse.locale;\n    }\n    get usetts() {\n        return this.privParticipantPayloadResponse.usetts;\n    }\n    get ismuted() {\n        return this.privParticipantPayloadResponse.ismuted;\n    }\n    get ishost() {\n        return this.privParticipantPayloadResponse.ishost;\n    }\n    get participantId() {\n        return this.privParticipantPayloadResponse.participantId;\n    }\n    get avatar() {\n        return this.privParticipantPayloadResponse.avatar;\n    }\n    static fromJSON(json) {\n        return new ParticipantPayloadResponse(json);\n    }\n}\n\n//# sourceMappingURL=ParticipantResponsePayload.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/*! exports provided: SpeechResponsePayload, TextResponsePayload */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechResponsePayload\", function() { return SpeechResponsePayload; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TextResponsePayload\", function() { return TextResponsePayload; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseSpeechResponse = (json) => JSON.parse(json);\nconst parseTextResponse = (json) => JSON.parse(json);\nclass SpeechResponsePayload {\n    constructor(json) {\n        this.privSpeechResponse = parseSpeechResponse(json);\n    }\n    get recognition() {\n        return this.privSpeechResponse.recognition;\n    }\n    get translations() {\n        return this.privSpeechResponse.translations;\n    }\n    get id() {\n        return this.privSpeechResponse.id;\n    }\n    get language() {\n        return this.privSpeechResponse.language;\n    }\n    get nickname() {\n        return this.privSpeechResponse.nickname;\n    }\n    get participantId() {\n        return this.privSpeechResponse.participantId;\n    }\n    get roomid() {\n        return this.privSpeechResponse.roomid;\n    }\n    get timestamp() {\n        return this.privSpeechResponse.timestamp;\n    }\n    get type() {\n        return this.privSpeechResponse.type;\n    }\n    get isFinal() {\n        return this.privSpeechResponse.type === \"final\";\n    }\n    static fromJSON(json) {\n        return new SpeechResponsePayload(json);\n    }\n}\nclass TextResponsePayload {\n    constructor(json) {\n        this.privTextResponse = parseTextResponse(json);\n    }\n    get originalText() {\n        return this.privTextResponse.originalText;\n    }\n    get translations() {\n        return this.privTextResponse.translations;\n    }\n    get id() {\n        return this.privTextResponse.id;\n    }\n    get language() {\n        return this.privTextResponse.language;\n    }\n    get nickname() {\n        return this.privTextResponse.nickname;\n    }\n    get participantId() {\n        return this.privTextResponse.participantId;\n    }\n    get roomid() {\n        return this.privTextResponse.roomid;\n    }\n    get timestamp() {\n        return this.privTextResponse.timestamp;\n    }\n    get type() {\n        return this.privTextResponse.type;\n    }\n    static fromJSON(json) {\n        return new TextResponsePayload(json);\n    }\n}\n\n//# sourceMappingURL=TranslationResponsePayload.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \*************************************************************************************************************************************/
/*! exports provided: TranscriberRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranscriberRecognizer\", function() { return TranscriberRecognizer; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass TranscriberRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Recognizer\"] {\n    /**\n     * TranscriberRecognizer constructor.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer\n     */\n    constructor(speechTranslationConfig, audioConfig) {\n        const speechTranslationConfigImpl = speechTranslationConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(speechTranslationConfigImpl, \"speechTranslationConfig\");\n        const audioConfigImpl = audioConfig;\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(audioConfigImpl, \"audioConfigImpl\");\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechTranslationConfigImpl.properties, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"TranscriberConnectionFactory\"]());\n        this.privDisposedRecognizer = false;\n    }\n    get speechRecognitionLanguage() {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get authorizationToken() {\n        return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(token) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    set conversation(c) {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(c, \"Conversation\");\n        this.privConversation = c;\n    }\n    getConversationInfo() {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation, \"Conversation\");\n        return this.privConversation.conversationInfo;\n    }\n    startContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"marshalPromiseToCallbacks\"])(this.startContinuousRecognitionAsyncImpl(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"RecognitionMode\"].Conversation), cb, err);\n    }\n    stopContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"marshalPromiseToCallbacks\"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privDisposedRecognizer) {\n                yield this.dispose(true);\n            }\n        });\n    }\n    // Push async join/leave conversation message via serviceRecognizer\n    pushConversationEvent(conversationInfo, command) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const reco = (this.privReco);\n            _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(reco, \"serviceRecognizer\");\n            yield reco.sendSpeechEventAsync(conversationInfo, command);\n        });\n    }\n    enforceAudioGating() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const audioConfigImpl = this.audioConfig;\n            const format = yield audioConfigImpl.format;\n            const channels = format.channels;\n            if (channels === 1) {\n                if (this.properties.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() !== \"true\") {\n                    throw new Error(\"Single channel audio configuration for ConversationTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details\");\n                }\n            }\n            else if (channels !== 8) {\n                throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);\n            }\n            return;\n        });\n    }\n    connectCallbacks(transcriber) {\n        this.canceled = (s, e) => {\n            if (!!transcriber.canceled) {\n                transcriber.canceled(transcriber, e);\n            }\n        };\n        this.recognizing = (s, e) => {\n            if (!!transcriber.transcribing) {\n                transcriber.transcribing(transcriber, e);\n            }\n        };\n        this.recognized = (s, e) => {\n            if (!!transcriber.transcribed) {\n                transcriber.transcribed(transcriber, e);\n            }\n        };\n        this.sessionStarted = (s, e) => {\n            if (!!transcriber.sessionStarted) {\n                transcriber.sessionStarted(transcriber, e);\n            }\n        };\n        this.sessionStopped = (s, e) => {\n            if (!!transcriber.sessionStopped) {\n                transcriber.sessionStopped(transcriber, e);\n            }\n        };\n    }\n    disconnectCallbacks() {\n        this.canceled = undefined;\n        this.recognizing = undefined;\n        this.recognized = undefined;\n        this.sessionStarted = undefined;\n        this.sessionStopped = undefined;\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member ConversationTranscriber.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedRecognizer) {\n                return;\n            }\n            if (disposing) {\n                this.privDisposedRecognizer = true;\n                yield this.implRecognizerStop();\n            }\n            yield _super.dispose.call(this, disposing);\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"RecognizerConfig\"](speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"TranscriptionServiceRecognizer\"](authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\n\n//# sourceMappingURL=TranscriberRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \********************************************************************************************************************************/
/*! exports provided: TranscriptionServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranscriptionServiceRecognizer\", function() { return TranscriptionServiceRecognizer; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranscriptionServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);\n        this.privTranscriberRecognizer = transcriber;\n        this.sendPrePayloadJSONOverride = (connection) => this.sendTranscriptionStartJSON(connection);\n        if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_RequestWordLevelTimestamps) === \"true\") {\n            this.privSpeechContext.setWordLevelTimings();\n        }\n    }\n    sendSpeechEventAsync(info, command) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privRequestSession.isRecognizing) {\n                const connection = yield this.fetchConnection();\n                yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));\n            }\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let result;\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n            resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n            let processed = false;\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"speech.hypothesis\":\n                case \"speech.fragment\":\n                    const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechHypothesis\"].fromJSON(connectionMessage.textBody);\n                    const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n                    result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, connectionMessage.textBody, resultProps);\n                    this.privRequestSession.onHypothesis(offset);\n                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionEventArgs\"](result, hypothesis.Duration, this.privRequestSession.sessionId);\n                    if (!!this.privTranscriberRecognizer.recognizing) {\n                        try {\n                            this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    processed = true;\n                    break;\n                case \"speech.phrase\":\n                    const simple = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SimpleSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateRecognitionResult(simple.RecognitionStatus);\n                    this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n                    if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled === resultReason) {\n                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateCancelResult(simple.RecognitionStatus);\n                        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateCancelErrorCode(simple.RecognitionStatus);\n                        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateErrorDetails(cancellationErrorCode));\n                    }\n                    else {\n                        if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionStatus\"].InitialSilenceTimeout)) {\n                            if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormatPropertyName\"]) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"][_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"OutputFormat\"].Simple]) {\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, connectionMessage.textBody, resultProps);\n                            }\n                            else {\n                                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"DetailedSpeechPhrase\"].fromJSON(connectionMessage.textBody);\n                                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionResult\"](this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, offsetCorrectedJson, resultProps);\n                            }\n                            const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionEventArgs\"](result, result.offset, this.privRequestSession.sessionId);\n                            if (!!this.privTranscriberRecognizer.recognized) {\n                                try {\n                                    this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                        }\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][errorCode]);\n        if (!!this.privTranscriberRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ConversationTranscriptionCanceledEventArgs\"](cancellationReason, error, errorCode, undefined, sessionId);\n            try {\n                this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechRecognitionResult\"](requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled, undefined, // Text\n            undefined, // Duration\n            undefined, // Offset\n            undefined, // Language\n            undefined, // Language Detection Confidence\n            undefined, // Speaker Id\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                this.privSuccessCallback = undefined;\n                /* eslint-disable no-empty */\n            }\n            catch (_b) { }\n        }\n    }\n    // Encapsulated for derived service recognizers that need to send additional JSON\n    sendTranscriptionStartJSON(connection) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.sendSpeechContext(connection, true);\n            const info = this.privTranscriberRecognizer.getConversationInfo();\n            const payload = this.createSpeechEventPayload(info, \"start\");\n            yield this.sendSpeechEvent(connection, payload);\n            yield this.sendWaveHeader(connection);\n            return;\n        });\n    }\n    sendSpeechEvent(connection, payload) {\n        const speechEventJson = JSON.stringify(payload);\n        if (speechEventJson) {\n            return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_3__[\"SpeechConnectionMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, \"speech.event\", this.privRequestSession.requestId, \"application/json\", speechEventJson));\n        }\n        return;\n    }\n    createSpeechEventPayload(info, command) {\n        const eventDict = { id: \"meeting\", name: command, meeting: info.conversationProperties };\n        eventDict.meeting.id = info.id;\n        eventDict.meeting.attendees = info.participants;\n        eventDict.meeting.record = info.conversationProperties.audiorecording === \"on\" ? \"true\" : \"false\";\n        return eventDict;\n    }\n}\n\n//# sourceMappingURL=TranscriptionServiceRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranslationConnectionFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationConnectionFactory\", function() { return TranslationConnectionFactory; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass TranslationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"] {\n    create(config, authInfo, connectionId) {\n        let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Endpoint, undefined);\n        if (!endpoint) {\n            const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Region, undefined);\n            const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionFactoryBase\"].getHostSuffix(region);\n            const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Host, \"wss://\" + region + \".s2s.speech\" + hostSuffix);\n            endpoint = host + \"/speech/translation/cognitiveservices/v1\";\n        }\n        const queryParams = {\n            from: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage),\n            to: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages),\n        };\n        this.setCommonUrlParams(config, queryParams, endpoint);\n        this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_TranslationRequestStablePartialResult, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_5__[\"QueryParameterNames\"].StableTranslation, config, queryParams, endpoint);\n        const voiceName = \"voice\";\n        const featureName = \"features\";\n        if (config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {\n            queryParams[voiceName] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice);\n            queryParams[featureName] = \"texttospeech\";\n        }\n        const headers = {};\n        if (authInfo.token !== undefined && authInfo.token !== \"\") {\n            headers[authInfo.headerName] = authInfo.token;\n        }\n        headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_4__[\"HeaderNames\"].ConnectionId] = connectionId;\n        config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_Url, endpoint);\n        const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n        return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"WebsocketConnection\"](endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"WebsocketMessageFormatter\"](), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ProxyInfo\"].fromRecognizerConfig(config), enableCompression, connectionId);\n    }\n}\n\n//# sourceMappingURL=TranslationConnectionFactory.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js ***!
  \******************************************************************************************************************************/
/*! exports provided: TranslationServiceRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationServiceRecognizer\", function() { return TranslationServiceRecognizer; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranslationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ServiceRecognizerBase\"] {\n    constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {\n        super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);\n        this.privTranslationRecognizer = translationRecognizer;\n        this.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                this.privTranslationRecognizer.onConnection();\n            }\n            else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                void this.privTranslationRecognizer.onDisconnection();\n            }\n        });\n    }\n    processTypeSpecificMessages(connectionMessage) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n            let processed = false;\n            const handleTranslationPhrase = (translatedPhrase) => __awaiter(this, void 0, void 0, function* () {\n                this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);\n                if (translatedPhrase.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionStatus\"].Success) {\n                    // OK, the recognition was successful. How'd the translation do?\n                    const result = this.fireEventForResult(translatedPhrase, resultProps);\n                    if (!!this.privTranslationRecognizer.recognized) {\n                        try {\n                            this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    // report result to promise.\n                    if (!!this.privSuccessCallback) {\n                        try {\n                            this.privSuccessCallback(result.result);\n                        }\n                        catch (e) {\n                            if (!!this.privErrorCallback) {\n                                this.privErrorCallback(e);\n                            }\n                        }\n                        // Only invoke the call back once.\n                        // and if it's successful don't invoke the\n                        // error after that.\n                        this.privSuccessCallback = undefined;\n                        this.privErrorCallback = undefined;\n                    }\n                }\n                else {\n                    const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);\n                    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionResult\"](undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, undefined, connectionMessage.textBody, resultProps);\n                    if (reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled) {\n                        const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateCancelResult(translatedPhrase.RecognitionStatus);\n                        const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);\n                        yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"EnumTranslation\"].implTranslateErrorDetails(cancellationErrorCode));\n                    }\n                    else {\n                        if (!(this.privRequestSession.isSpeechEnded && reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].NoMatch && translatedPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionStatus\"].InitialSilenceTimeout)) {\n                            const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionEventArgs\"](result, result.offset, this.privRequestSession.sessionId);\n                            if (!!this.privTranslationRecognizer.recognized) {\n                                try {\n                                    this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                        }\n                        // report result to promise.\n                        if (!!this.privSuccessCallback) {\n                            try {\n                                this.privSuccessCallback(result);\n                            }\n                            catch (e) {\n                                if (!!this.privErrorCallback) {\n                                    this.privErrorCallback(e);\n                                }\n                            }\n                            // Only invoke the call back once.\n                            // and if it's successful don't invoke the\n                            // error after that.\n                            this.privSuccessCallback = undefined;\n                            this.privErrorCallback = undefined;\n                        }\n                    }\n                    processed = true;\n                }\n            });\n            if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n                resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n            }\n            switch (connectionMessage.path.toLowerCase()) {\n                case \"translation.hypothesis\":\n                    const result = this.fireEventForResult(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationHypothesis\"].fromJSON(connectionMessage.textBody), resultProps);\n                    this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);\n                    if (!!this.privTranslationRecognizer.recognizing) {\n                        try {\n                            this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);\n                            /* eslint-disable no-empty */\n                        }\n                        catch (error) {\n                            // Not going to let errors in the event handler\n                            // trip things up.\n                        }\n                    }\n                    processed = true;\n                    break;\n                case \"translation.response\":\n                    const phrase = JSON.parse(connectionMessage.textBody);\n                    if (!!phrase.SpeechPhrase) {\n                        yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationPhrase\"].fromTranslationResponse(phrase));\n                    }\n                    break;\n                case \"translation.phrase\":\n                    yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationPhrase\"].fromJSON(connectionMessage.textBody));\n                    break;\n                case \"translation.synthesis\":\n                    this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);\n                    processed = true;\n                    break;\n                case \"translation.synthesis.end\":\n                    const synthEnd = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationSynthesisEnd\"].fromJSON(connectionMessage.textBody);\n                    switch (synthEnd.SynthesisStatus) {\n                        case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisStatus\"].Error:\n                            if (!!this.privTranslationRecognizer.synthesizing) {\n                                const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationSynthesisResult\"](_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled, undefined);\n                                const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationSynthesisEventArgs\"](result, this.privRequestSession.sessionId);\n                                try {\n                                    this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            if (!!this.privTranslationRecognizer.canceled) {\n                                // And raise a canceled event to send the rich(er) error message back.\n                                const canceledResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionCanceledEventArgs\"](this.privRequestSession.sessionId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error, synthEnd.FailureReason, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].ServiceError, null);\n                                try {\n                                    this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);\n                                    /* eslint-disable no-empty */\n                                }\n                                catch (error) {\n                                    // Not going to let errors in the event handler\n                                    // trip things up.\n                                }\n                            }\n                            break;\n                        case _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SynthesisStatus\"].Success:\n                            this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);\n                            break;\n                        default:\n                            break;\n                    }\n                    processed = true;\n                    break;\n                default:\n                    break;\n            }\n            return processed;\n        });\n    }\n    // Cancels recognition.\n    cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCodePropertyName\"], _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][errorCode]);\n        if (!!this.privTranslationRecognizer.canceled) {\n            const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionCanceledEventArgs\"](sessionId, cancellationReason, error, errorCode, undefined);\n            try {\n                this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (_a) { }\n        }\n        if (!!this.privSuccessCallback) {\n            const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionResult\"](undefined, // Translations\n            requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled, undefined, // Text\n            undefined, // Druation\n            undefined, // Offset\n            error, undefined, // Json\n            properties);\n            try {\n                this.privSuccessCallback(result);\n                /* eslint-disable no-empty */\n                this.privSuccessCallback = undefined;\n            }\n            catch (_b) { }\n        }\n    }\n    fireEventForResult(serviceResult, properties) {\n        let translations;\n        if (undefined !== serviceResult.Translation.Translations) {\n            translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Translations\"]();\n            for (const translation of serviceResult.Translation.Translations) {\n                translations.set(translation.Language, translation.Text || translation.DisplayText);\n            }\n        }\n        let resultReason;\n        if (serviceResult instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"TranslationPhrase\"]) {\n            if (serviceResult.Translation.TranslationStatus === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"TranslationStatus\"].Success) {\n                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].TranslatedSpeech;\n            }\n            else {\n                resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].RecognizedSpeech;\n            }\n        }\n        else {\n            resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].TranslatingSpeech;\n        }\n        const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionResult\"](translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);\n        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationRecognitionEventArgs\"](result, offset, this.privRequestSession.sessionId);\n        return ev;\n    }\n    sendSynthesisAudio(audio, sessionId) {\n        const reason = (undefined === audio) ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].SynthesizingAudioCompleted : _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].SynthesizingAudio;\n        const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationSynthesisResult\"](reason, audio);\n        const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__[\"TranslationSynthesisEventArgs\"](result, sessionId);\n        if (!!this.privTranslationRecognizer.synthesizing) {\n            try {\n                this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                /* eslint-disable no-empty */\n            }\n            catch (error) {\n                // Not going to let errors in the event handler\n                // trip things up.\n            }\n        }\n    }\n}\n\n//# sourceMappingURL=TranslationServiceRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js ***!
  \*******************************************************************************************************************/
/*! exports provided: TranslationStatus */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationStatus\", function() { return TranslationStatus; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation status.\n * @class TranslationStatus\n */\nvar TranslationStatus;\n(function (TranslationStatus) {\n    /**\n     * @member TranslationStatus.Success\n     */\n    TranslationStatus[TranslationStatus[\"Success\"] = 0] = \"Success\";\n    /**\n     * @member TranslationStatus.Error\n     */\n    TranslationStatus[TranslationStatus[\"Error\"] = 1] = \"Error\";\n})(TranslationStatus || (TranslationStatus = {}));\n\n//# sourceMappingURL=TranslationStatus.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js ***!
  \***************************************************************************************************************************/
/*! exports provided: WebsocketMessageFormatter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"WebsocketMessageFormatter\", function() { return WebsocketMessageFormatter; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst CRLF = \"\\r\\n\";\nclass WebsocketMessageFormatter {\n    toConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n                const textMessage = message.textContent;\n                let headers = {};\n                let body = null;\n                if (textMessage) {\n                    const headerBodySplit = textMessage.split(\"\\r\\n\\r\\n\");\n                    if (headerBodySplit && headerBodySplit.length > 0) {\n                        headers = this.parseHeaders(headerBodySplit[0]);\n                        if (headerBodySplit.length > 1) {\n                            body = headerBodySplit[1];\n                        }\n                    }\n                }\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionMessage\"](message.messageType, body, headers, message.id));\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary) {\n                const binaryMessage = message.binaryContent;\n                let headers = {};\n                let body = null;\n                if (!binaryMessage || binaryMessage.byteLength < 2) {\n                    throw new Error(\"Invalid binary message format. Header length missing.\");\n                }\n                const dataView = new DataView(binaryMessage);\n                const headerLength = dataView.getInt16(0);\n                if (binaryMessage.byteLength < headerLength + 2) {\n                    throw new Error(\"Invalid binary message format. Header content missing.\");\n                }\n                let headersString = \"\";\n                for (let i = 0; i < headerLength; i++) {\n                    headersString += String.fromCharCode((dataView).getInt8(i + 2));\n                }\n                headers = this.parseHeaders(headersString);\n                if (binaryMessage.byteLength > headerLength + 2) {\n                    body = binaryMessage.slice(2 + headerLength);\n                }\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConnectionMessage\"](message.messageType, body, headers, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. Error: ${e}`);\n        }\n        return deferral.promise;\n    }\n    fromConnectionMessage(message) {\n        const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Deferred\"]();\n        try {\n            if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n                const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : \"\"}`;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RawWebsocketMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text, payload, message.id));\n            }\n            else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary) {\n                const headersString = this.makeHeaders(message);\n                const content = message.binaryBody;\n                const headerBuffer = this.stringToArrayBuffer(headersString);\n                const headerInt8Array = new Int8Array(headerBuffer);\n                const headerLength = headerInt8Array.byteLength;\n                const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));\n                payloadInt8Array[0] = ((headerLength >> 8) & 0xff);\n                payloadInt8Array[1] = headerLength & 0xff;\n                payloadInt8Array.set(headerInt8Array, 2);\n                if (content) {\n                    const bodyInt8Array = new Int8Array(content);\n                    payloadInt8Array.set(bodyInt8Array, 2 + headerLength);\n                }\n                const payload = payloadInt8Array.buffer;\n                deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RawWebsocketMessage\"](_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary, payload, message.id));\n            }\n        }\n        catch (e) {\n            deferral.reject(`Error formatting the message. ${e}`);\n        }\n        return deferral.promise;\n    }\n    makeHeaders(message) {\n        let headersString = \"\";\n        if (message.headers) {\n            for (const header in message.headers) {\n                if (header) {\n                    headersString += `${header}: ${message.headers[header]}${CRLF}`;\n                }\n            }\n        }\n        return headersString;\n    }\n    parseHeaders(headersString) {\n        const headers = {};\n        if (headersString) {\n            const headerMatches = headersString.match(/[^\\r\\n]+/g);\n            if (headers) {\n                for (const header of headerMatches) {\n                    if (header) {\n                        const separatorIndex = header.indexOf(\":\");\n                        const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;\n                        const headerValue = separatorIndex > 0 && header.length > (separatorIndex + 1) ?\n                            header.substr(separatorIndex + 1).trim() :\n                            \"\";\n                        headers[headerName] = headerValue;\n                    }\n                }\n            }\n        }\n        return headers;\n    }\n    stringToArrayBuffer(str) {\n        const buffer = new ArrayBuffer(str.length);\n        const view = new DataView(buffer);\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(i, str.charCodeAt(i));\n        }\n        return buffer;\n    }\n}\n\n//# sourceMappingURL=WebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js ***!
  \************************************************************************************************************/
/*! exports provided: AudioSourceEvent, AudioSourceInitializingEvent, AudioSourceReadyEvent, AudioSourceOffEvent, AudioSourceErrorEvent, AudioStreamNodeEvent, AudioStreamNodeAttachingEvent, AudioStreamNodeAttachedEvent, AudioStreamNodeDetachedEvent, AudioStreamNodeErrorEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceEvent\", function() { return AudioSourceEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceInitializingEvent\", function() { return AudioSourceInitializingEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceReadyEvent\", function() { return AudioSourceReadyEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceOffEvent\", function() { return AudioSourceOffEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceErrorEvent\", function() { return AudioSourceErrorEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeEvent\", function() { return AudioStreamNodeEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeAttachingEvent\", function() { return AudioStreamNodeAttachingEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeAttachedEvent\", function() { return AudioStreamNodeAttachedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeDetachedEvent\", function() { return AudioStreamNodeDetachedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeErrorEvent\", function() { return AudioStreamNodeErrorEvent; });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass AudioSourceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, audioSourceId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n        this.privAudioSourceId = audioSourceId;\n    }\n    get audioSourceId() {\n        return this.privAudioSourceId;\n    }\n}\nclass AudioSourceInitializingEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceInitializingEvent\", audioSourceId);\n    }\n}\nclass AudioSourceReadyEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceReadyEvent\", audioSourceId);\n    }\n}\nclass AudioSourceOffEvent extends AudioSourceEvent {\n    constructor(audioSourceId) {\n        super(\"AudioSourceOffEvent\", audioSourceId);\n    }\n}\nclass AudioSourceErrorEvent extends AudioSourceEvent {\n    constructor(audioSourceId, error) {\n        super(\"AudioSourceErrorEvent\", audioSourceId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\nclass AudioStreamNodeEvent extends AudioSourceEvent {\n    constructor(eventName, audioSourceId, audioNodeId) {\n        super(eventName, audioSourceId);\n        this.privAudioNodeId = audioNodeId;\n    }\n    get audioNodeId() {\n        return this.privAudioNodeId;\n    }\n}\nclass AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachingEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeAttachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId) {\n        super(\"AudioStreamNodeDetachedEvent\", audioSourceId, audioNodeId);\n    }\n}\nclass AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {\n    constructor(audioSourceId, audioNodeId, error) {\n        super(\"AudioStreamNodeErrorEvent\", audioSourceId, audioNodeId);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=AudioSourceEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js ***!
  \**********************************************************************************************************/
/*! exports provided: BackgroundEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BackgroundEvent\", function() { return BackgroundEvent; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass BackgroundEvent extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(error) {\n        super(\"BackgroundEvent\", _Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Error);\n        this.privError = error;\n    }\n    get error() {\n        return this.privError;\n    }\n}\n\n//# sourceMappingURL=BackgroundError.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js ***!
  \*******************************************************************************************************************/
/*! exports provided: ChunkedArrayBufferStream */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ChunkedArrayBufferStream\", function() { return ChunkedArrayBufferStream; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ChunkedArrayBufferStream extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"Stream\"] {\n    constructor(targetChunkSize, streamId) {\n        super(streamId);\n        this.privTargetChunkSize = targetChunkSize;\n        this.privNextBufferReadyBytes = 0;\n    }\n    writeStreamChunk(chunk) {\n        // No pending write, and the buffer is the right size so write it.\n        if (chunk.isEnd ||\n            (0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize)) {\n            super.writeStreamChunk(chunk);\n            return;\n        }\n        let bytesCopiedFromBuffer = 0;\n        while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {\n            // Fill the next buffer.\n            if (undefined === this.privNextBufferToWrite) {\n                this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);\n                this.privNextBufferStartTime = chunk.timeReceived;\n            }\n            // Find out how many bytes we can copy into the read buffer.\n            const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);\n            const targetView = new Uint8Array(this.privNextBufferToWrite);\n            const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));\n            targetView.set(sourceView, this.privNextBufferReadyBytes);\n            this.privNextBufferReadyBytes += bytesToCopy;\n            bytesCopiedFromBuffer += bytesToCopy;\n            // Are we ready to write?\n            if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {\n                super.writeStreamChunk({\n                    buffer: this.privNextBufferToWrite,\n                    isEnd: false,\n                    timeReceived: this.privNextBufferStartTime,\n                });\n                this.privNextBufferReadyBytes = 0;\n                this.privNextBufferToWrite = undefined;\n            }\n        }\n    }\n    close() {\n        // Send whatever is pending, then close the base class.\n        if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {\n            super.writeStreamChunk({\n                buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),\n                isEnd: false,\n                timeReceived: this.privNextBufferStartTime,\n            });\n        }\n        super.close();\n    }\n}\n\n//# sourceMappingURL=ChunkedArrayBufferStream.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js ***!
  \***********************************************************************************************************/
/*! exports provided: ServiceEvent, ConnectionEvent, ConnectionStartEvent, ConnectionEstablishedEvent, ConnectionClosedEvent, ConnectionErrorEvent, ConnectionEstablishErrorEvent, ConnectionMessageReceivedEvent, ConnectionMessageSentEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServiceEvent\", function() { return ServiceEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEvent\", function() { return ConnectionEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionStartEvent\", function() { return ConnectionStartEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEstablishedEvent\", function() { return ConnectionEstablishedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionClosedEvent\", function() { return ConnectionClosedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionErrorEvent\", function() { return ConnectionErrorEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEstablishErrorEvent\", function() { return ConnectionEstablishErrorEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageReceivedEvent\", function() { return ConnectionMessageReceivedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageSentEvent\", function() { return ConnectionMessageSentEvent; });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ServiceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, jsonstring, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n        this.privJsonResult = jsonstring;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n}\nclass ConnectionEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, connectionId, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n        this.privConnectionId = connectionId;\n    }\n    get connectionId() {\n        return this.privConnectionId;\n    }\n}\nclass ConnectionStartEvent extends ConnectionEvent {\n    constructor(connectionId, uri, headers) {\n        super(\"ConnectionStartEvent\", connectionId);\n        this.privUri = uri;\n        this.privHeaders = headers;\n    }\n    get uri() {\n        return this.privUri;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n}\nclass ConnectionEstablishedEvent extends ConnectionEvent {\n    constructor(connectionId) {\n        super(\"ConnectionEstablishedEvent\", connectionId);\n    }\n}\nclass ConnectionClosedEvent extends ConnectionEvent {\n    constructor(connectionId, statusCode, reason) {\n        super(\"ConnectionClosedEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug);\n        this.privReason = reason;\n        this.privStatusCode = statusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nclass ConnectionErrorEvent extends ConnectionEvent {\n    constructor(connectionId, message, type) {\n        super(\"ConnectionErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug);\n        this.privMessage = message;\n        this.privType = type;\n    }\n    get message() {\n        return this.privMessage;\n    }\n    get type() {\n        return this.privType;\n    }\n}\nclass ConnectionEstablishErrorEvent extends ConnectionEvent {\n    constructor(connectionId, statuscode, reason) {\n        super(\"ConnectionEstablishErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Error);\n        this.privStatusCode = statuscode;\n        this.privReason = reason;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n}\nclass ConnectionMessageReceivedEvent extends ConnectionEvent {\n    constructor(connectionId, networkReceivedTimeISO, message) {\n        super(\"ConnectionMessageReceivedEvent\", connectionId);\n        this.privNetworkReceivedTime = networkReceivedTimeISO;\n        this.privMessage = message;\n    }\n    get networkReceivedTime() {\n        return this.privNetworkReceivedTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\nclass ConnectionMessageSentEvent extends ConnectionEvent {\n    constructor(connectionId, networkSentTimeISO, message) {\n        super(\"ConnectionMessageSentEvent\", connectionId);\n        this.privNetworkSentTime = networkSentTimeISO;\n        this.privMessage = message;\n    }\n    get networkSentTime() {\n        return this.privNetworkSentTime;\n    }\n    get message() {\n        return this.privMessage;\n    }\n}\n\n//# sourceMappingURL=ConnectionEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js ***!
  \************************************************************************************************************/
/*! exports provided: MessageType, ConnectionMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MessageType\", function() { return MessageType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessage\", function() { return ConnectionMessage; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-return */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nvar MessageType;\n(function (MessageType) {\n    MessageType[MessageType[\"Text\"] = 0] = \"Text\";\n    MessageType[MessageType[\"Binary\"] = 1] = \"Binary\";\n})(MessageType || (MessageType = {}));\nclass ConnectionMessage {\n    constructor(messageType, body, headers, id) {\n        this.privBody = null;\n        if (messageType === MessageType.Text && body && !(typeof (body) === \"string\")) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Payload must be a string\");\n        }\n        if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Payload must be ArrayBuffer\");\n        }\n        this.privMessageType = messageType;\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        this.privBody = body;\n        this.privHeaders = headers ? headers : {};\n        this.privId = id ? id : Object(_Guid__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        switch (this.messageType) {\n            case MessageType.Binary:\n                this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;\n                break;\n            case MessageType.Text:\n                this.privSize = this.textBody.length;\n        }\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get headers() {\n        return this.privHeaders;\n    }\n    get body() {\n        return this.privBody;\n    }\n    get textBody() {\n        if (this.privMessageType === MessageType.Binary) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Not supported for binary message\");\n        }\n        return this.privBody;\n    }\n    get binaryBody() {\n        if (this.privMessageType === MessageType.Text) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Not supported for text message\");\n        }\n        return this.privBody;\n    }\n    get id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js ***!
  \*****************************************************************************************************************/
/*! exports provided: ConnectionOpenResponse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionOpenResponse\", function() { return ConnectionOpenResponse; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ConnectionOpenResponse {\n    constructor(statusCode, reason) {\n        this.privStatusCode = statusCode;\n        this.privReason = reason;\n    }\n    get statusCode() {\n        return this.privStatusCode;\n    }\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=ConnectionOpenResponse.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js ***!
  \*******************************************************************************************************/
/*! exports provided: DialogEvent, SendingAgentContextMessageEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogEvent\", function() { return DialogEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SendingAgentContextMessageEvent\", function() { return SendingAgentContextMessageEvent; });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DialogEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, eventType = _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Info) {\n        super(eventName, eventType);\n    }\n}\nclass SendingAgentContextMessageEvent extends DialogEvent {\n    constructor(agentConfig) {\n        super(\"SendingAgentContextMessageEvent\");\n        this.privAgentConfig = agentConfig;\n    }\n    get agentConfig() {\n        return this.privAgentConfig;\n    }\n}\n\n//# sourceMappingURL=DialogEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js ***!
  \************************************************************************************************/
/*! exports provided: ArgumentNullError, InvalidOperationError, ObjectDisposedError */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ArgumentNullError\", function() { return ArgumentNullError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"InvalidOperationError\", function() { return InvalidOperationError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ObjectDisposedError\", function() { return ObjectDisposedError; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n/**\n * The error that is thrown when an argument passed in is null.\n *\n * @export\n * @class ArgumentNullError\n * @extends {Error}\n */\nclass ArgumentNullError extends Error {\n    /**\n     * Creates an instance of ArgumentNullError.\n     *\n     * @param {string} argumentName - Name of the argument that is null\n     *\n     * @memberOf ArgumentNullError\n     */\n    constructor(argumentName) {\n        super(argumentName);\n        this.name = \"ArgumentNull\";\n        this.message = argumentName;\n    }\n}\n/**\n * The error that is thrown when an invalid operation is performed in the code.\n *\n * @export\n * @class InvalidOperationError\n * @extends {Error}\n */\nclass InvalidOperationError extends Error {\n    /**\n     * Creates an instance of InvalidOperationError.\n     *\n     * @param {string} error - The error\n     *\n     * @memberOf InvalidOperationError\n     */\n    constructor(error) {\n        super(error);\n        this.name = \"InvalidOperation\";\n        this.message = error;\n    }\n}\n/**\n * The error that is thrown when an object is disposed.\n *\n * @export\n * @class ObjectDisposedError\n * @extends {Error}\n */\nclass ObjectDisposedError extends Error {\n    /**\n     * Creates an instance of ObjectDisposedError.\n     *\n     * @param {string} objectName - The object that is disposed\n     * @param {string} error - The error\n     *\n     * @memberOf ObjectDisposedError\n     */\n    constructor(objectName, error) {\n        super(error);\n        this.name = objectName + \"ObjectDisposed\";\n        this.message = error;\n    }\n}\n\n//# sourceMappingURL=Error.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js ***!
  \******************************************************************************************************/
/*! exports provided: EventSource */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"EventSource\", function() { return EventSource; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EventSource {\n    constructor(metadata) {\n        this.privEventListeners = {};\n        this.privIsDisposed = false;\n        this.privConsoleListener = undefined;\n        this.privMetadata = metadata;\n    }\n    onEvent(event) {\n        if (this.isDisposed()) {\n            throw (new _Error__WEBPACK_IMPORTED_MODULE_0__[\"ObjectDisposedError\"](\"EventSource\"));\n        }\n        if (this.metadata) {\n            for (const paramName in this.metadata) {\n                if (paramName) {\n                    if (event.metadata) {\n                        if (!event.metadata[paramName]) {\n                            event.metadata[paramName] = this.metadata[paramName];\n                        }\n                    }\n                }\n            }\n        }\n        for (const eventId in this.privEventListeners) {\n            if (eventId && this.privEventListeners[eventId]) {\n                this.privEventListeners[eventId](event);\n            }\n        }\n    }\n    attach(onEventCallback) {\n        const id = Object(_Guid__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        this.privEventListeners[id] = onEventCallback;\n        return {\n            detach: () => {\n                delete this.privEventListeners[id];\n                return Promise.resolve();\n            },\n        };\n    }\n    attachListener(listener) {\n        return this.attach((e) => listener.onEvent(e));\n    }\n    attachConsoleListener(listener) {\n        if (!!this.privConsoleListener) {\n            void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous\n        }\n        this.privConsoleListener = this.attach((e) => listener.onEvent(e));\n        return this.privConsoleListener;\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        this.privEventListeners = null;\n        this.privIsDisposed = true;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\n\n//# sourceMappingURL=EventSource.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js ***!
  \*************************************************************************************************/
/*! exports provided: Events */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Events\", function() { return Events; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./EventSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass Events {\n    static setEventSource(eventSource) {\n        if (!eventSource) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"ArgumentNullError\"](\"eventSource\");\n        }\n        Events.privInstance = eventSource;\n    }\n    static get instance() {\n        return Events.privInstance;\n    }\n}\nEvents.privInstance = new _EventSource__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n\n//# sourceMappingURL=Events.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioSourceEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceInitializingEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceInitializingEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceReadyEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceReadyEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceOffEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceOffEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioSourceErrorEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioSourceErrorEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeAttachingEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeAttachingEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeAttachedEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeAttachedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeDetachedEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeDetachedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamNodeErrorEvent\", function() { return _AudioSourceEvents__WEBPACK_IMPORTED_MODULE_0__[\"AudioStreamNodeErrorEvent\"]; });\n\n/* harmony import */ var _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServiceEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ServiceEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionStartEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionStartEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEstablishedEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionEstablishedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionClosedEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionClosedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionErrorEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionErrorEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEstablishErrorEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionEstablishErrorEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageReceivedEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionMessageReceivedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageSentEvent\", function() { return _ConnectionEvents__WEBPACK_IMPORTED_MODULE_1__[\"ConnectionMessageSentEvent\"]; });\n\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MessageType\", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__[\"MessageType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessage\", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessage\"]; });\n\n/* harmony import */ var _ConnectionOpenResponse__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConnectionOpenResponse */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionOpenResponse\", function() { return _ConnectionOpenResponse__WEBPACK_IMPORTED_MODULE_3__[\"ConnectionOpenResponse\"]; });\n\n/* harmony import */ var _DialogEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./DialogEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogEvent\", function() { return _DialogEvents__WEBPACK_IMPORTED_MODULE_4__[\"DialogEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SendingAgentContextMessageEvent\", function() { return _DialogEvents__WEBPACK_IMPORTED_MODULE_4__[\"SendingAgentContextMessageEvent\"]; });\n\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ArgumentNullError\", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__[\"ArgumentNullError\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"InvalidOperationError\", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__[\"InvalidOperationError\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ObjectDisposedError\", function() { return _Error__WEBPACK_IMPORTED_MODULE_5__[\"ObjectDisposedError\"]; });\n\n/* harmony import */ var _Events__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Events */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Events\", function() { return _Events__WEBPACK_IMPORTED_MODULE_6__[\"Events\"]; });\n\n/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./EventSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"EventSource\", function() { return _EventSource__WEBPACK_IMPORTED_MODULE_7__[\"EventSource\"]; });\n\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createGuid\", function() { return _Guid__WEBPACK_IMPORTED_MODULE_8__[\"createGuid\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createNoDashGuid\", function() { return _Guid__WEBPACK_IMPORTED_MODULE_8__[\"createNoDashGuid\"]; });\n\n/* harmony import */ var _IAudioSource__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./IAudioSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js\");\n/* harmony import */ var _IAudioSource__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_IAudioSource__WEBPACK_IMPORTED_MODULE_9__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IAudioSource__WEBPACK_IMPORTED_MODULE_9__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IAudioSource__WEBPACK_IMPORTED_MODULE_9__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IConnection__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./IConnection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionState\", function() { return _IConnection__WEBPACK_IMPORTED_MODULE_10__[\"ConnectionState\"]; });\n\n/* harmony import */ var _IDetachable__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IDetachable */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js\");\n/* harmony import */ var _IDetachable__WEBPACK_IMPORTED_MODULE_11___default = /*#__PURE__*/__webpack_require__.n(_IDetachable__WEBPACK_IMPORTED_MODULE_11__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDetachable__WEBPACK_IMPORTED_MODULE_11__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDetachable__WEBPACK_IMPORTED_MODULE_11__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IDictionary__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./IDictionary */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js\");\n/* harmony import */ var _IDictionary__WEBPACK_IMPORTED_MODULE_12___default = /*#__PURE__*/__webpack_require__.n(_IDictionary__WEBPACK_IMPORTED_MODULE_12__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDictionary__WEBPACK_IMPORTED_MODULE_12__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDictionary__WEBPACK_IMPORTED_MODULE_12__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IDisposable__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./IDisposable */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js\");\n/* harmony import */ var _IDisposable__WEBPACK_IMPORTED_MODULE_13___default = /*#__PURE__*/__webpack_require__.n(_IDisposable__WEBPACK_IMPORTED_MODULE_13__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IDisposable__WEBPACK_IMPORTED_MODULE_13__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IDisposable__WEBPACK_IMPORTED_MODULE_13__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IEventSource__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IEventSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js\");\n/* harmony import */ var _IEventSource__WEBPACK_IMPORTED_MODULE_14___default = /*#__PURE__*/__webpack_require__.n(_IEventSource__WEBPACK_IMPORTED_MODULE_14__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IEventSource__WEBPACK_IMPORTED_MODULE_14__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IEventSource__WEBPACK_IMPORTED_MODULE_14__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./IErrorMessages */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js\");\n/* harmony import */ var _IErrorMessages__WEBPACK_IMPORTED_MODULE_15___default = /*#__PURE__*/__webpack_require__.n(_IErrorMessages__WEBPACK_IMPORTED_MODULE_15__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IErrorMessages__WEBPACK_IMPORTED_MODULE_15__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _ITimer__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./ITimer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js\");\n/* harmony import */ var _ITimer__WEBPACK_IMPORTED_MODULE_16___default = /*#__PURE__*/__webpack_require__.n(_ITimer__WEBPACK_IMPORTED_MODULE_16__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _ITimer__WEBPACK_IMPORTED_MODULE_16__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _ITimer__WEBPACK_IMPORTED_MODULE_16__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./IWebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js\");\n/* harmony import */ var _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17___default = /*#__PURE__*/__webpack_require__.n(_IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_17__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./List */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"List\", function() { return _List__WEBPACK_IMPORTED_MODULE_18__[\"List\"]; });\n\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"EventType\", function() { return _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__[\"EventType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PlatformEvent\", function() { return _PlatformEvent__WEBPACK_IMPORTED_MODULE_19__[\"PlatformEvent\"]; });\n\n/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./Promise */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PromiseState\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"PromiseState\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PromiseResult\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"PromiseResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PromiseResultEventSource\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"PromiseResultEventSource\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Deferred\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"Deferred\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Sink\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"Sink\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"marshalPromiseToCallbacks\", function() { return _Promise__WEBPACK_IMPORTED_MODULE_20__[\"marshalPromiseToCallbacks\"]; });\n\n/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./Queue */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Queue\", function() { return _Queue__WEBPACK_IMPORTED_MODULE_21__[\"Queue\"]; });\n\n/* harmony import */ var _RawWebsocketMessage__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./RawWebsocketMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RawWebsocketMessage\", function() { return _RawWebsocketMessage__WEBPACK_IMPORTED_MODULE_22__[\"RawWebsocketMessage\"]; });\n\n/* harmony import */ var _RiffPcmEncoder__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./RiffPcmEncoder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RiffPcmEncoder\", function() { return _RiffPcmEncoder__WEBPACK_IMPORTED_MODULE_23__[\"RiffPcmEncoder\"]; });\n\n/* harmony import */ var _Stream__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./Stream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Stream\", function() { return _Stream__WEBPACK_IMPORTED_MODULE_24__[\"Stream\"]; });\n\n/* harmony import */ var _common_speech_TranslationStatus__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../common.speech/TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationStatus\", function() { return _common_speech_TranslationStatus__WEBPACK_IMPORTED_MODULE_25__[\"TranslationStatus\"]; });\n\n/* harmony import */ var _ChunkedArrayBufferStream__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./ChunkedArrayBufferStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ChunkedArrayBufferStream\", function() { return _ChunkedArrayBufferStream__WEBPACK_IMPORTED_MODULE_26__[\"ChunkedArrayBufferStream\"]; });\n\n/* harmony import */ var _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./IAudioDestination */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js\");\n/* harmony import */ var _IAudioDestination__WEBPACK_IMPORTED_MODULE_27___default = /*#__PURE__*/__webpack_require__.n(_IAudioDestination__WEBPACK_IMPORTED_MODULE_27__);\n/* harmony reexport (unknown) */ for(var __WEBPACK_IMPORT_KEY__ in _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__) if([\"TranslationStatus\",\"AudioSourceEvent\",\"AudioSourceInitializingEvent\",\"AudioSourceReadyEvent\",\"AudioSourceOffEvent\",\"AudioSourceErrorEvent\",\"AudioStreamNodeEvent\",\"AudioStreamNodeAttachingEvent\",\"AudioStreamNodeAttachedEvent\",\"AudioStreamNodeDetachedEvent\",\"AudioStreamNodeErrorEvent\",\"ServiceEvent\",\"ConnectionEvent\",\"ConnectionStartEvent\",\"ConnectionEstablishedEvent\",\"ConnectionClosedEvent\",\"ConnectionErrorEvent\",\"ConnectionEstablishErrorEvent\",\"ConnectionMessageReceivedEvent\",\"ConnectionMessageSentEvent\",\"MessageType\",\"ConnectionMessage\",\"ConnectionOpenResponse\",\"DialogEvent\",\"SendingAgentContextMessageEvent\",\"ArgumentNullError\",\"InvalidOperationError\",\"ObjectDisposedError\",\"Events\",\"EventSource\",\"createGuid\",\"createNoDashGuid\",\"ConnectionState\",\"List\",\"EventType\",\"PlatformEvent\",\"PromiseState\",\"PromiseResult\",\"PromiseResultEventSource\",\"Deferred\",\"Sink\",\"marshalPromiseToCallbacks\",\"Queue\",\"RawWebsocketMessage\",\"RiffPcmEncoder\",\"Stream\",\"ChunkedArrayBufferStream\",\"default\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) (function(key) { __webpack_require__.d(__webpack_exports__, key, function() { return _IAudioDestination__WEBPACK_IMPORTED_MODULE_27__[key]; }) }(__WEBPACK_IMPORT_KEY__));\n/* harmony import */ var _Timeout__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./Timeout */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Timeout\", function() { return _Timeout__WEBPACK_IMPORTED_MODULE_28__[\"Timeout\"]; });\n\n/* harmony import */ var _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./OCSPEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPMemoryCacheHitEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPMemoryCacheHitEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheMissEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheMissEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPDiskCacheHitEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPDiskCacheHitEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateNeededEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheUpdateNeededEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPMemoryCacheStoreEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPMemoryCacheStoreEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPDiskCacheStoreEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPDiskCacheStoreEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateCompleteEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheUpdateCompleteEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPStapleReceivedEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPStapleReceivedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPWSUpgradeStartedEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPWSUpgradeStartedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheEntryExpiredEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheEntryExpiredEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheEntryNeedsRefreshEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheEntryNeedsRefreshEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheHitEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheHitEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPVerificationFailedEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPVerificationFailedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheFetchErrorEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheFetchErrorEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPResponseRetrievedEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPResponseRetrievedEvent\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateErrorEvent\", function() { return _OCSPEvents__WEBPACK_IMPORTED_MODULE_29__[\"OCSPCacheUpdateErrorEvent\"]; });\n\n/* harmony import */ var _BackgroundError__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./BackgroundError */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BackgroundEvent\", function() { return _BackgroundError__WEBPACK_IMPORTED_MODULE_30__[\"BackgroundEvent\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js ***!
  \***********************************************************************************************/
/*! exports provided: createGuid, createNoDashGuid */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createGuid\", function() { return createGuid; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createNoDashGuid\", function() { return createNoDashGuid; });\n/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/esm-browser/index.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst createGuid = () => Object(uuid__WEBPACK_IMPORTED_MODULE_0__[\"v4\"])();\nconst createNoDashGuid = () => createGuid().replace(new RegExp(\"-\", \"g\"), \"\").toUpperCase();\n\n\n//# sourceMappingURL=Guid.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js ***!
  \************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IAudioDestination.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioDestination.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js ***!
  \*******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IAudioSource.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js ***!
  \******************************************************************************************************/
/*! exports provided: ConnectionState */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionState\", function() { return ConnectionState; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar ConnectionState;\n(function (ConnectionState) {\n    ConnectionState[ConnectionState[\"None\"] = 0] = \"None\";\n    ConnectionState[ConnectionState[\"Connected\"] = 1] = \"Connected\";\n    ConnectionState[ConnectionState[\"Connecting\"] = 2] = \"Connecting\";\n    ConnectionState[ConnectionState[\"Disconnected\"] = 3] = \"Disconnected\";\n})(ConnectionState || (ConnectionState = {}));\n\n//# sourceMappingURL=IConnection.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IDetachable.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDetachable.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IDictionary.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDictionary.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js ***!
  \******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IDisposable.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IDisposable.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js ***!
  \*********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("\n\n//# sourceMappingURL=IErrorMessages.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IErrorMessages.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js ***!
  \*******************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IEventSource.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IEventSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js ***!
  \*************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=ITimer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ITimer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js ***!
  \*********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceMappingURL=IWebsocketMessageFormatter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IWebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js ***!
  \***********************************************************************************************/
/*! exports provided: List */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"List\", function() { return List; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass List {\n    constructor(list) {\n        this.privSubscriptionIdCounter = 0;\n        this.privAddSubscriptions = {};\n        this.privRemoveSubscriptions = {};\n        this.privDisposedSubscriptions = {};\n        this.privDisposeReason = null;\n        this.privList = [];\n        // copy the list rather than taking as is.\n        if (list) {\n            for (const item of list) {\n                this.privList.push(item);\n            }\n        }\n    }\n    get(itemIndex) {\n        this.throwIfDisposed();\n        return this.privList[itemIndex];\n    }\n    first() {\n        return this.get(0);\n    }\n    last() {\n        return this.get(this.length() - 1);\n    }\n    add(item) {\n        this.throwIfDisposed();\n        this.insertAt(this.privList.length, item);\n    }\n    insertAt(index, item) {\n        this.throwIfDisposed();\n        if (index === 0) {\n            this.privList.unshift(item);\n        }\n        else if (index === this.privList.length) {\n            this.privList.push(item);\n        }\n        else {\n            this.privList.splice(index, 0, item);\n        }\n        this.triggerSubscriptions(this.privAddSubscriptions);\n    }\n    removeFirst() {\n        this.throwIfDisposed();\n        return this.removeAt(0);\n    }\n    removeLast() {\n        this.throwIfDisposed();\n        return this.removeAt(this.length() - 1);\n    }\n    removeAt(index) {\n        this.throwIfDisposed();\n        return this.remove(index, 1)[0];\n    }\n    remove(index, count) {\n        this.throwIfDisposed();\n        const removedElements = this.privList.splice(index, count);\n        this.triggerSubscriptions(this.privRemoveSubscriptions);\n        return removedElements;\n    }\n    clear() {\n        this.throwIfDisposed();\n        this.remove(0, this.length());\n    }\n    length() {\n        this.throwIfDisposed();\n        return this.privList.length;\n    }\n    onAdded(addedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privAddSubscriptions[subscriptionId] = addedCallback;\n        return {\n            detach: () => {\n                delete this.privAddSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onRemoved(removedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privRemoveSubscriptions[subscriptionId] = removedCallback;\n        return {\n            detach: () => {\n                delete this.privRemoveSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    onDisposed(disposedCallback) {\n        this.throwIfDisposed();\n        const subscriptionId = this.privSubscriptionIdCounter++;\n        this.privDisposedSubscriptions[subscriptionId] = disposedCallback;\n        return {\n            detach: () => {\n                delete this.privDisposedSubscriptions[subscriptionId];\n                return Promise.resolve();\n            },\n        };\n    }\n    join(seperator) {\n        this.throwIfDisposed();\n        return this.privList.join(seperator);\n    }\n    toArray() {\n        const cloneCopy = Array();\n        this.privList.forEach((val) => {\n            cloneCopy.push(val);\n        });\n        return cloneCopy;\n    }\n    any(callback) {\n        this.throwIfDisposed();\n        if (callback) {\n            return this.where(callback).length() > 0;\n        }\n        else {\n            return this.length() > 0;\n        }\n    }\n    all(callback) {\n        this.throwIfDisposed();\n        return this.where(callback).length() === this.length();\n    }\n    forEach(callback) {\n        this.throwIfDisposed();\n        for (let i = 0; i < this.length(); i++) {\n            callback(this.privList[i], i);\n        }\n    }\n    select(callback) {\n        this.throwIfDisposed();\n        const selectList = [];\n        for (let i = 0; i < this.privList.length; i++) {\n            selectList.push(callback(this.privList[i], i));\n        }\n        return new List(selectList);\n    }\n    where(callback) {\n        this.throwIfDisposed();\n        const filteredList = new List();\n        for (let i = 0; i < this.privList.length; i++) {\n            if (callback(this.privList[i], i)) {\n                filteredList.add(this.privList[i]);\n            }\n        }\n        return filteredList;\n    }\n    orderBy(compareFn) {\n        this.throwIfDisposed();\n        const clonedArray = this.toArray();\n        const orderedArray = clonedArray.sort(compareFn);\n        return new List(orderedArray);\n    }\n    orderByDesc(compareFn) {\n        this.throwIfDisposed();\n        return this.orderBy((a, b) => compareFn(b, a));\n    }\n    clone() {\n        this.throwIfDisposed();\n        return new List(this.toArray());\n    }\n    concat(list) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(list.toArray()));\n    }\n    concatArray(array) {\n        this.throwIfDisposed();\n        return new List(this.privList.concat(array));\n    }\n    isDisposed() {\n        return this.privList == null;\n    }\n    dispose(reason) {\n        if (!this.isDisposed()) {\n            this.privDisposeReason = reason;\n            this.privList = null;\n            this.privAddSubscriptions = null;\n            this.privRemoveSubscriptions = null;\n            this.triggerSubscriptions(this.privDisposedSubscriptions);\n        }\n    }\n    throwIfDisposed() {\n        if (this.isDisposed()) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"ObjectDisposedError\"](\"List\", this.privDisposeReason);\n        }\n    }\n    triggerSubscriptions(subscriptions) {\n        if (subscriptions) {\n            for (const subscriptionId in subscriptions) {\n                if (subscriptionId) {\n                    subscriptions[subscriptionId]();\n                }\n            }\n        }\n    }\n}\n\n//# sourceMappingURL=List.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js ***!
  \*****************************************************************************************************/
/*! exports provided: OCSPEvent, OCSPMemoryCacheHitEvent, OCSPCacheMissEvent, OCSPDiskCacheHitEvent, OCSPCacheUpdateNeededEvent, OCSPMemoryCacheStoreEvent, OCSPDiskCacheStoreEvent, OCSPCacheUpdateCompleteEvent, OCSPStapleReceivedEvent, OCSPWSUpgradeStartedEvent, OCSPCacheEntryExpiredEvent, OCSPCacheEntryNeedsRefreshEvent, OCSPCacheHitEvent, OCSPVerificationFailedEvent, OCSPCacheFetchErrorEvent, OCSPResponseRetrievedEvent, OCSPCacheUpdateErrorEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPEvent\", function() { return OCSPEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPMemoryCacheHitEvent\", function() { return OCSPMemoryCacheHitEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheMissEvent\", function() { return OCSPCacheMissEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPDiskCacheHitEvent\", function() { return OCSPDiskCacheHitEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateNeededEvent\", function() { return OCSPCacheUpdateNeededEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPMemoryCacheStoreEvent\", function() { return OCSPMemoryCacheStoreEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPDiskCacheStoreEvent\", function() { return OCSPDiskCacheStoreEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateCompleteEvent\", function() { return OCSPCacheUpdateCompleteEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPStapleReceivedEvent\", function() { return OCSPStapleReceivedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPWSUpgradeStartedEvent\", function() { return OCSPWSUpgradeStartedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheEntryExpiredEvent\", function() { return OCSPCacheEntryExpiredEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheEntryNeedsRefreshEvent\", function() { return OCSPCacheEntryNeedsRefreshEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheHitEvent\", function() { return OCSPCacheHitEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPVerificationFailedEvent\", function() { return OCSPVerificationFailedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheFetchErrorEvent\", function() { return OCSPCacheFetchErrorEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPResponseRetrievedEvent\", function() { return OCSPResponseRetrievedEvent; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OCSPCacheUpdateErrorEvent\", function() { return OCSPCacheUpdateErrorEvent; });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass OCSPEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"PlatformEvent\"] {\n    constructor(eventName, eventType, signature) {\n        super(eventName, eventType);\n        this.privSignature = signature;\n    }\n}\nclass OCSPMemoryCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPCacheMissEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheMissEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPDiskCacheHitEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPCacheUpdateNeededEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateNeededEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPMemoryCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPMemoryCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPDiskCacheStoreEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPDiskCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPCacheUpdateCompleteEvent extends OCSPEvent {\n    constructor(signature) {\n        super(\"OCSPCacheUpdateCompleteEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, signature);\n    }\n}\nclass OCSPStapleReceivedEvent extends OCSPEvent {\n    constructor() {\n        super(\"OCSPStapleReceivedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, \"\");\n    }\n}\nclass OCSPWSUpgradeStartedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPWSUpgradeStartedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n    }\n}\nclass OCSPCacheEntryExpiredEvent extends OCSPEvent {\n    constructor(serialNumber, expireTime) {\n        super(\"OCSPCacheEntryExpiredEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privExpireTime = expireTime;\n    }\n}\nclass OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheEntryNeedsRefreshEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privStartTime = startTime;\n    }\n}\nclass OCSPCacheHitEvent extends OCSPEvent {\n    constructor(serialNumber, startTime, expireTime) {\n        super(\"OCSPCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privExpireTime = expireTime;\n        this.privExpireTimeString = new Date(expireTime).toLocaleDateString();\n        this.privStartTime = startTime;\n        this.privStartTimeString = new Date(startTime).toLocaleTimeString();\n    }\n}\nclass OCSPVerificationFailedEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPVerificationFailedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privError = error;\n    }\n}\nclass OCSPCacheFetchErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheFetchErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privError = error;\n    }\n}\nclass OCSPResponseRetrievedEvent extends OCSPEvent {\n    constructor(serialNumber) {\n        super(\"OCSPResponseRetrievedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n    }\n}\nclass OCSPCacheUpdateErrorEvent extends OCSPEvent {\n    constructor(serialNumber, error) {\n        super(\"OCSPCacheUpdateErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"].Debug, serialNumber);\n        this.privError = error;\n    }\n}\n\n//# sourceMappingURL=OCSPEvents.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js ***!
  \********************************************************************************************************/
/*! exports provided: EventType, PlatformEvent */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"EventType\", function() { return EventType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PlatformEvent\", function() { return PlatformEvent; });\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar EventType;\n(function (EventType) {\n    EventType[EventType[\"Debug\"] = 0] = \"Debug\";\n    EventType[EventType[\"Info\"] = 1] = \"Info\";\n    EventType[EventType[\"Warning\"] = 2] = \"Warning\";\n    EventType[EventType[\"Error\"] = 3] = \"Error\";\n    EventType[EventType[\"None\"] = 4] = \"None\";\n})(EventType || (EventType = {}));\nclass PlatformEvent {\n    constructor(eventName, eventType) {\n        this.privName = eventName;\n        this.privEventId = Object(_Guid__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privEventTime = new Date().toISOString();\n        this.privEventType = eventType;\n        this.privMetadata = {};\n    }\n    get name() {\n        return this.privName;\n    }\n    get eventId() {\n        return this.privEventId;\n    }\n    get eventTime() {\n        return this.privEventTime;\n    }\n    get eventType() {\n        return this.privEventType;\n    }\n    get metadata() {\n        return this.privMetadata;\n    }\n}\n\n//# sourceMappingURL=PlatformEvent.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js ***!
  \**************************************************************************************************/
/*! exports provided: PromiseState, PromiseResult, PromiseResultEventSource, Deferred, Sink, marshalPromiseToCallbacks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PromiseState\", function() { return PromiseState; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PromiseResult\", function() { return PromiseResult; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PromiseResultEventSource\", function() { return PromiseResultEventSource; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Deferred\", function() { return Deferred; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Sink\", function() { return Sink; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"marshalPromiseToCallbacks\", function() { return marshalPromiseToCallbacks; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */\nvar PromiseState;\n(function (PromiseState) {\n    PromiseState[PromiseState[\"None\"] = 0] = \"None\";\n    PromiseState[PromiseState[\"Resolved\"] = 1] = \"Resolved\";\n    PromiseState[PromiseState[\"Rejected\"] = 2] = \"Rejected\";\n})(PromiseState || (PromiseState = {}));\nclass PromiseResult {\n    constructor(promiseResultEventSource) {\n        this.throwIfError = () => {\n            if (this.isError) {\n                throw this.error;\n            }\n        };\n        promiseResultEventSource.on((result) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = false;\n                this.privResult = result;\n            }\n        }, (error) => {\n            if (!this.privIsCompleted) {\n                this.privIsCompleted = true;\n                this.privIsError = true;\n                this.privError = error;\n            }\n        });\n    }\n    get isCompleted() {\n        return this.privIsCompleted;\n    }\n    get isError() {\n        return this.privIsError;\n    }\n    get error() {\n        return this.privError;\n    }\n    get result() {\n        return this.privResult;\n    }\n}\nclass PromiseResultEventSource {\n    constructor() {\n        this.setResult = (result) => {\n            this.privOnSetResult(result);\n        };\n        this.setError = (error) => {\n            this.privOnSetError(error);\n        };\n        this.on = (onSetResult, onSetError) => {\n            this.privOnSetResult = onSetResult;\n            this.privOnSetError = onSetError;\n        };\n    }\n}\nclass Deferred {\n    constructor() {\n        this.resolve = (result) => {\n            this.privResolve(result);\n            return this;\n        };\n        this.reject = (error) => {\n            this.privReject(error);\n            return this;\n        };\n        // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n        this.privPromise = new Promise((resolve, reject) => {\n            this.privResolve = resolve;\n            this.privReject = reject;\n        });\n    }\n    get promise() {\n        return this.privPromise;\n    }\n}\nclass Sink {\n    constructor() {\n        this.privState = PromiseState.None;\n        this.privPromiseResult = null;\n        this.privPromiseResultEvents = null;\n        this.privSuccessHandlers = [];\n        this.privErrorHandlers = [];\n        this.privPromiseResultEvents = new PromiseResultEventSource();\n        this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);\n    }\n    get state() {\n        return this.privState;\n    }\n    get result() {\n        return this.privPromiseResult;\n    }\n    resolve(result) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot resolve a completed promise'\");\n        }\n        this.privState = PromiseState.Resolved;\n        this.privPromiseResultEvents.setResult(result);\n        for (let i = 0; i < this.privSuccessHandlers.length; i++) {\n            this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);\n        }\n        this.detachHandlers();\n    }\n    reject(error) {\n        if (this.privState !== PromiseState.None) {\n            throw new Error(\"'Cannot reject a completed promise'\");\n        }\n        this.privState = PromiseState.Rejected;\n        this.privPromiseResultEvents.setError(error);\n        for (const errorHandler of this.privErrorHandlers) {\n            this.executeErrorCallback(error, errorHandler);\n        }\n        this.detachHandlers();\n    }\n    on(successCallback, errorCallback) {\n        if (successCallback == null) {\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            successCallback = () => { };\n        }\n        if (this.privState === PromiseState.None) {\n            this.privSuccessHandlers.push(successCallback);\n            this.privErrorHandlers.push(errorCallback);\n        }\n        else {\n            if (this.privState === PromiseState.Resolved) {\n                this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);\n            }\n            else if (this.privState === PromiseState.Rejected) {\n                this.executeErrorCallback(this.privPromiseResult.error, errorCallback);\n            }\n            this.detachHandlers();\n        }\n    }\n    executeSuccessCallback(result, successCallback, errorCallback) {\n        try {\n            successCallback(result);\n        }\n        catch (e) {\n            this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);\n        }\n    }\n    executeErrorCallback(error, errorCallback) {\n        if (errorCallback) {\n            try {\n                errorCallback(error);\n            }\n            catch (e) {\n                throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);\n            }\n        }\n        else {\n            throw new Error(`'Unhandled error: ${error}'`);\n        }\n    }\n    detachHandlers() {\n        this.privErrorHandlers = [];\n        this.privSuccessHandlers = [];\n    }\n}\n// eslint-disable-next-line prefer-arrow/prefer-arrow-functions\nfunction marshalPromiseToCallbacks(promise, cb, err) {\n    promise.then((val) => {\n        try {\n            if (!!cb) {\n                cb(val);\n            }\n        }\n        catch (error) {\n            if (!!err) {\n                try {\n                    if (error instanceof Error) {\n                        const typedError = error;\n                        err(typedError.name + \": \" + typedError.message);\n                    }\n                    else {\n                        err(error);\n                    }\n                    // eslint-disable-next-line no-empty\n                }\n                catch (error) { }\n            }\n        }\n    }, (error) => {\n        if (!!err) {\n            try {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n                // eslint-disable-next-line no-empty\n            }\n            catch (error) { }\n        }\n    });\n}\n\n//# sourceMappingURL=Promise.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js ***!
  \************************************************************************************************/
/*! exports provided: Queue */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Queue\", function() { return Queue; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./List */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js\");\n/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Promise */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nvar SubscriberType;\n(function (SubscriberType) {\n    SubscriberType[SubscriberType[\"Dequeue\"] = 0] = \"Dequeue\";\n    SubscriberType[SubscriberType[\"Peek\"] = 1] = \"Peek\";\n})(SubscriberType || (SubscriberType = {}));\nclass Queue {\n    constructor(list) {\n        this.privPromiseStore = new _List__WEBPACK_IMPORTED_MODULE_1__[\"List\"]();\n        this.privIsDrainInProgress = false;\n        this.privIsDisposing = false;\n        this.privDisposeReason = null;\n        this.privList = list ? list : new _List__WEBPACK_IMPORTED_MODULE_1__[\"List\"]();\n        this.privDetachables = [];\n        this.privSubscribers = new _List__WEBPACK_IMPORTED_MODULE_1__[\"List\"]();\n        this.privDetachables.push(this.privList.onAdded(() => this.drain()));\n    }\n    enqueue(item) {\n        this.throwIfDispose();\n        this.enqueueFromPromise(new Promise((resolve) => resolve(item)));\n    }\n    enqueueFromPromise(promise) {\n        this.throwIfDispose();\n        promise.then((val) => {\n            this.privList.add(val);\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n        }, () => { });\n    }\n    dequeue() {\n        this.throwIfDispose();\n        const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        if (this.privSubscribers) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Dequeue });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    peek() {\n        this.throwIfDispose();\n        const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n        const subs = this.privSubscribers;\n        if (subs) {\n            this.privSubscribers.add({ deferral: deferredSubscriber, type: SubscriberType.Peek });\n            this.drain();\n        }\n        return deferredSubscriber.promise;\n    }\n    length() {\n        this.throwIfDispose();\n        return this.privList.length();\n    }\n    isDisposed() {\n        return this.privSubscribers == null;\n    }\n    drainAndDispose(pendingItemProcessor, reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.isDisposed() && !this.privIsDisposing) {\n                this.privDisposeReason = reason;\n                this.privIsDisposing = true;\n                const subs = this.privSubscribers;\n                if (subs) {\n                    while (subs.length() > 0) {\n                        const subscriber = subs.removeFirst();\n                        // TODO: this needs work (Resolve(null) instead?).\n                        subscriber.deferral.resolve(undefined);\n                        // subscriber.deferral.reject(\"Disposed\");\n                    }\n                    // note: this block assumes cooperative multitasking, i.e.,\n                    // between the if-statement and the assignment there are no\n                    // thread switches.\n                    // Reason is that between the initial const = this.; and this\n                    // point there is the derral.resolve() operation that might have\n                    // caused recursive calls to the Queue, especially, calling\n                    // Dispose() on the queue alredy (which would reset the var\n                    // here to null!).\n                    // That should generally hold true for javascript...\n                    if (this.privSubscribers === subs) {\n                        this.privSubscribers = subs;\n                    }\n                }\n                for (const detachable of this.privDetachables) {\n                    yield detachable.detach();\n                }\n                if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {\n                    const promiseArray = [];\n                    this.privPromiseStore.toArray().forEach((wrapper) => {\n                        promiseArray.push(wrapper);\n                    });\n                    return Promise.all(promiseArray).finally(() => {\n                        this.privSubscribers = null;\n                        this.privList.forEach((item) => {\n                            pendingItemProcessor(item);\n                        });\n                        this.privList = null;\n                        return;\n                    }).then();\n                }\n                else {\n                    this.privSubscribers = null;\n                    this.privList = null;\n                }\n            }\n        });\n    }\n    dispose(reason) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.drainAndDispose(null, reason);\n        });\n    }\n    drain() {\n        if (!this.privIsDrainInProgress && !this.privIsDisposing) {\n            this.privIsDrainInProgress = true;\n            const subs = this.privSubscribers;\n            const lists = this.privList;\n            if (subs && lists) {\n                while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {\n                    const subscriber = subs.removeFirst();\n                    if (subscriber.type === SubscriberType.Peek) {\n                        subscriber.deferral.resolve(lists.first());\n                    }\n                    else {\n                        const dequeuedItem = lists.removeFirst();\n                        subscriber.deferral.resolve(dequeuedItem);\n                    }\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privSubscribers === subs) {\n                    this.privSubscribers = subs;\n                }\n                // note: this block assumes cooperative multitasking, i.e.,\n                // between the if-statement and the assignment there are no\n                // thread switches.\n                // Reason is that between the initial const = this.; and this\n                // point there is the derral.resolve() operation that might have\n                // caused recursive calls to the Queue, especially, calling\n                // Dispose() on the queue alredy (which would reset the var\n                // here to null!).\n                // That should generally hold true for javascript...\n                if (this.privList === lists) {\n                    this.privList = lists;\n                }\n            }\n            this.privIsDrainInProgress = false;\n        }\n    }\n    throwIfDispose() {\n        if (this.isDisposed()) {\n            if (this.privDisposeReason) {\n                throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](this.privDisposeReason);\n            }\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"ObjectDisposedError\"](\"Queue\");\n        }\n        else if (this.privIsDisposing) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Queue disposing\");\n        }\n    }\n}\n\n//# sourceMappingURL=Queue.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js ***!
  \**************************************************************************************************************/
/*! exports provided: RawWebsocketMessage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RawWebsocketMessage\", function() { return RawWebsocketMessage; });\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass RawWebsocketMessage {\n    constructor(messageType, payload, id) {\n        this.privPayload = null;\n        if (!payload) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_1__[\"ArgumentNullError\"](\"payload\");\n        }\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary && payload.__proto__.constructor.name !== \"ArrayBuffer\") {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_1__[\"InvalidOperationError\"](\"Payload must be ArrayBuffer\");\n        }\n        if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text && !(typeof (payload) === \"string\")) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_1__[\"InvalidOperationError\"](\"Payload must be a string\");\n        }\n        this.privMessageType = messageType;\n        this.privPayload = payload;\n        this.privId = id ? id : Object(_Guid__WEBPACK_IMPORTED_MODULE_2__[\"createNoDashGuid\"])();\n    }\n    get messageType() {\n        return this.privMessageType;\n    }\n    get payload() {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n        return this.privPayload;\n    }\n    get textContent() {\n        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Binary) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_1__[\"InvalidOperationError\"](\"Not supported for binary message\");\n        }\n        return this.privPayload;\n    }\n    get binaryContent() {\n        if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_0__[\"MessageType\"].Text) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_1__[\"InvalidOperationError\"](\"Not supported for text message\");\n        }\n        return this.privPayload;\n    }\n    get id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=RawWebsocketMessage.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js ***!
  \*********************************************************************************************************/
/*! exports provided: RiffPcmEncoder */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RiffPcmEncoder\", function() { return RiffPcmEncoder; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RiffPcmEncoder {\n    constructor(actualSampleRate, desiredSampleRate) {\n        this.privActualSampleRate = actualSampleRate;\n        this.privDesiredSampleRate = desiredSampleRate;\n    }\n    encode(actualAudioFrame) {\n        const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);\n        if (!audioFrame) {\n            return null;\n        }\n        const audioLength = audioFrame.length * 2;\n        const buffer = new ArrayBuffer(audioLength);\n        const view = new DataView(buffer);\n        this.floatTo16BitPCM(view, 0, audioFrame);\n        return buffer;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n    floatTo16BitPCM(view, offset, input) {\n        for (let i = 0; i < input.length; i++, offset += 2) {\n            const s = Math.max(-1, Math.min(1, input[i]));\n            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n        }\n    }\n    downSampleAudioFrame(srcFrame, srcRate, dstRate) {\n        if (!srcFrame) {\n            return null;\n        }\n        if (dstRate === srcRate || dstRate > srcRate) {\n            return srcFrame;\n        }\n        const ratio = srcRate / dstRate;\n        const dstLength = Math.round(srcFrame.length / ratio);\n        const dstFrame = new Float32Array(dstLength);\n        let srcOffset = 0;\n        let dstOffset = 0;\n        while (dstOffset < dstLength) {\n            const nextSrcOffset = Math.round((dstOffset + 1) * ratio);\n            let accum = 0;\n            let count = 0;\n            while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {\n                accum += srcFrame[srcOffset++];\n                count++;\n            }\n            dstFrame[dstOffset++] = accum / count;\n        }\n        return dstFrame;\n    }\n}\n\n//# sourceMappingURL=RiffPcmEncoder.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js ***!
  \*************************************************************************************************/
/*! exports provided: Stream */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Stream\", function() { return Stream; });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Queue */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nclass Stream {\n    constructor(streamId) {\n        this.privIsWriteEnded = false;\n        this.privIsReadEnded = false;\n        this.privId = streamId ? streamId : Object(_Guid__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_2__[\"Queue\"]();\n    }\n    get isClosed() {\n        return this.privIsWriteEnded;\n    }\n    get isReadEnded() {\n        return this.privIsReadEnded;\n    }\n    get id() {\n        return this.privId;\n    }\n    close() {\n        if (!this.privIsWriteEnded) {\n            this.writeStreamChunk({\n                buffer: null,\n                isEnd: true,\n                timeReceived: Date.now(),\n            });\n            this.privIsWriteEnded = true;\n        }\n    }\n    writeStreamChunk(streamChunk) {\n        this.throwIfClosed();\n        if (!this.privReaderQueue.isDisposed()) {\n            try {\n                this.privReaderQueue.enqueue(streamChunk);\n            }\n            catch (e) {\n                // Do nothing\n            }\n        }\n    }\n    read() {\n        if (this.privIsReadEnded) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Stream read has already finished\");\n        }\n        return this.privReaderQueue\n            .dequeue()\n            .then((streamChunk) => __awaiter(this, void 0, void 0, function* () {\n            if (streamChunk === undefined || streamChunk.isEnd) {\n                yield this.privReaderQueue.dispose(\"End of stream reached\");\n            }\n            return streamChunk;\n        }));\n    }\n    readEnded() {\n        if (!this.privIsReadEnded) {\n            this.privIsReadEnded = true;\n            this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_2__[\"Queue\"]();\n        }\n    }\n    throwIfClosed() {\n        if (this.privIsWriteEnded) {\n            throw new _Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Stream closed\");\n        }\n    }\n}\n\n//# sourceMappingURL=Stream.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js ***!
  \**************************************************************************************************/
/*! exports provided: Timeout */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Timeout\", function() { return Timeout; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass Timeout {\n    static load() {\n        // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.\n        const scheduledTimeoutFunctions = new Map([[0, () => { }]]); // eslint-disable-line @typescript-eslint/no-empty-function\n        const unhandledRequests = new Map();\n        // eslint-disable-next-line\n        const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,\"a\",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p=\"\",n(n.s=14)}([function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return i})),n.d(t,\"b\",(function(){return u})),n.d(t,\"c\",(function(){return a})),n.d(t,\"d\",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if(\"performance\"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o=\"performance\"in self?performance.now():Date.now();o>n?postMessage({id:null,method:\"call\",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){\"use strict\";n.r(t);var r=n(2);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)\"default\"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)\"default\"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)\"default\"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)\"default\"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)\"default\"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(11);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(0),o=n(1);for(var i in o)\"default\"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)\"default\"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener(\"message\",({data:e})=>{try{if(\"clear\"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if(\"set\"!==e.method)throw new Error('The given method \"'.concat(e.method,'\" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;\n        const workerUrl = \"data:text/javascript;base64,\" + btoa(workerScript);\n        const worker = new Worker(workerUrl);\n        worker.addEventListener(\"message\", ({ data }) => {\n            if (Timeout.isCallNotification(data)) {\n                const { params: { timerId } } = data;\n                const idOrFunc = scheduledTimeoutFunctions.get(timerId);\n                if (typeof idOrFunc === \"number\") {\n                    const unhandledTimerId = unhandledRequests.get(idOrFunc);\n                    if (unhandledTimerId === undefined ||\n                        unhandledTimerId !== timerId) {\n                        throw new Error(\"The timer is in an undefined state.\");\n                    }\n                }\n                else if (typeof idOrFunc !== \"undefined\") {\n                    idOrFunc();\n                    // A timeout can be safely deleted because it is only called once.\n                    scheduledTimeoutFunctions.delete(timerId);\n                }\n                else {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n            }\n            else if (Timeout.isClearResponse(data)) {\n                const { id } = data;\n                const unhandledTimerId = unhandledRequests.get(id);\n                if (unhandledTimerId === undefined) {\n                    throw new Error(\"The timer is in an undefined state.\");\n                }\n                unhandledRequests.delete(id);\n                scheduledTimeoutFunctions.delete(unhandledTimerId);\n            }\n            else {\n                const { error: { message } } = data;\n                throw new Error(message);\n            }\n        });\n        const clearTimeout = (timerId) => {\n            const id = Math.random();\n            unhandledRequests.set(id, timerId);\n            scheduledTimeoutFunctions.set(timerId, id);\n            worker.postMessage({\n                id,\n                method: \"clear\",\n                params: { timerId }\n            });\n        };\n        const setTimeout = (func, delay) => {\n            const timerId = Math.random();\n            scheduledTimeoutFunctions.set(timerId, func);\n            worker.postMessage({\n                id: null,\n                method: \"set\",\n                params: {\n                    delay,\n                    now: performance.now(),\n                    timerId\n                }\n            });\n            return timerId;\n        };\n        return {\n            clearTimeout,\n            setTimeout\n        };\n    }\n    static loadWorkerTimers() {\n        return () => {\n            if (Timeout.workerTimers !== null) {\n                return Timeout.workerTimers;\n            }\n            Timeout.workerTimers = Timeout.load();\n            return Timeout.workerTimers;\n        };\n    }\n    static isCallNotification(message) {\n        return message.method !== undefined && message.method === \"call\";\n    }\n    static isClearResponse(message) {\n        return message.error === null && typeof message.id === \"number\";\n    }\n}\nTimeout.workerTimers = null;\nTimeout.clearTimeout = (timerId) => Timeout.timers().clearTimeout(timerId);\nTimeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);\nTimeout.timers = Timeout.loadWorkerTimers();\n\n//# sourceMappingURL=Timeout.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js ***!
  \*****************************************************************************************************************/
/*! exports provided: ActivityReceivedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ActivityReceivedEventArgs\", function() { return ActivityReceivedEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of received message/events.\n * @class ActivityReceivedEventArgs\n */\nclass ActivityReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {any} activity - The activity..\n     */\n    constructor(activity, audioStream) {\n        this.privActivity = activity;\n        this.privAudioStream = audioStream;\n    }\n    /**\n     * Gets the received activity\n     * @member ActivityReceivedEventArgs.prototype.activity\n     * @function\n     * @public\n     * @returns {any} the received activity.\n     */\n    get activity() {\n        return this.privActivity;\n    }\n    get audioStream() {\n        return this.privAudioStream;\n    }\n}\n\n//# sourceMappingURL=ActivityReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js ***!
  \*********************************************************************************************************/
/*! exports provided: AudioConfig, AudioConfigImpl, AudioOutputConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioConfig\", function() { return AudioConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioConfigImpl\", function() { return AudioConfigImpl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioOutputConfigImpl\", function() { return AudioOutputConfigImpl; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _AudioFileWriter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioFileWriter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js\");\n/* harmony import */ var _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioInputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n/**\n * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).\n * @class AudioConfig\n * Updated in version 1.11.0\n */\nclass AudioConfig {\n    /**\n     * Creates an AudioConfig object representing the default microphone on the system.\n     * @member AudioConfig.fromDefaultMicrophoneInput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromDefaultMicrophoneInput() {\n        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PcmRecorder\"](true);\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MicAudioSource\"](pcmRecorder));\n    }\n    /**\n     * Creates an AudioConfig object representing a microphone with the specified device ID.\n     * @member AudioConfig.fromMicrophoneInput\n     * @function\n     * @public\n     * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.\n     * Default microphone is used the value is omitted.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromMicrophoneInput(deviceId) {\n        const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PcmRecorder\"](true);\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MicAudioSource\"](pcmRecorder, deviceId));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified file.\n     * @member AudioConfig.fromWavFileInput\n     * @function\n     * @public\n     * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromWavFileInput(file, name = \"unnamedBuffer.wav\") {\n        return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"FileAudioSource\"](file, name));\n    }\n    /**\n     * Creates an AudioConfig object representing the specified stream.\n     * @member AudioConfig.fromStreamInput\n     * @function\n     * @public\n     * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input\n     * stream. Currently, only WAV / PCM is supported.\n     * @returns {AudioConfig} The audio input configuration being created.\n     */\n    static fromStreamInput(audioStream) {\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioInputStreamCallback\"]) {\n            return new AudioConfigImpl(new _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__[\"PullAudioInputStreamImpl\"](audioStream));\n        }\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"AudioInputStream\"]) {\n            return new AudioConfigImpl(audioStream);\n        }\n        if (typeof MediaStream !== \"undefined\" && audioStream instanceof MediaStream) {\n            const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"PcmRecorder\"](false);\n            return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"MicAudioSource\"](pcmRecorder, null, null, audioStream));\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing the default speaker.\n     * @member AudioConfig.fromDefaultSpeakerOutput\n     * @function\n     * @public\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromDefaultSpeakerOutput() {\n        return new AudioOutputConfigImpl(new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerAudioDestination\"]());\n    }\n    /**\n     * Creates an AudioConfig object representing the custom IPlayer object.\n     * You can use the IPlayer object to control pause, resume, etc.\n     * @member AudioConfig.fromSpeakerOutput\n     * @function\n     * @public\n     * @param {IPlayer} player - the IPlayer object for playback.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.12.0\n     */\n    static fromSpeakerOutput(player) {\n        if (player === undefined) {\n            return AudioConfig.fromDefaultSpeakerOutput();\n        }\n        if (player instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerAudioDestination\"]) {\n            return new AudioOutputConfigImpl(player);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n    /**\n     * Creates an AudioConfig object representing a specified output audio file\n     * @member AudioConfig.fromAudioFileOutput\n     * @function\n     * @public\n     * @param {PathLike} filename - the filename of the output audio file\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromAudioFileOutput(filename) {\n        return new AudioOutputConfigImpl(new _AudioFileWriter__WEBPACK_IMPORTED_MODULE_3__[\"AudioFileWriter\"](filename));\n    }\n    /**\n     * Creates an AudioConfig object representing a specified audio output stream\n     * @member AudioConfig.fromStreamOutput\n     * @function\n     * @public\n     * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output\n     * stream.\n     * @returns {AudioConfig} The audio output configuration being created.\n     * Added in version 1.11.0\n     */\n    static fromStreamOutput(audioStream) {\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioOutputStreamCallback\"]) {\n            return new AudioOutputConfigImpl(new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__[\"PushAudioOutputStreamImpl\"](audioStream));\n        }\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioOutputStream\"]) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioOutputStream\"]) {\n            return new AudioOutputConfigImpl(audioStream);\n        }\n        throw new Error(\"Not Supported Type\");\n    }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class AudioConfigImpl\n */\nclass AudioConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioSource} source - An audio source.\n     */\n    constructor(source) {\n        super();\n        this.privSource = source;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privSource.format;\n    }\n    /**\n     * @member AudioConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        this.privSource.turnOff().then(() => {\n            if (!!cb) {\n                cb();\n            }\n        }, (error) => {\n            if (!!err) {\n                err(error);\n            }\n        });\n    }\n    /**\n     * @member AudioConfigImpl.prototype.id\n     * @function\n     * @public\n     */\n    id() {\n        return this.privSource.id();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.blob\n     * @function\n     * @public\n     */\n    get blob() {\n        return this.privSource.blob;\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOn\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOn() {\n        return this.privSource.turnOn();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.attach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     * @returns {Promise<IAudioStreamNode>} A promise.\n     */\n    attach(audioNodeId) {\n        return this.privSource.attach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.detach\n     * @function\n     * @public\n     * @param {string} audioNodeId - The audio node id.\n     */\n    detach(audioNodeId) {\n        return this.privSource.detach(audioNodeId);\n    }\n    /**\n     * @member AudioConfigImpl.prototype.turnOff\n     * @function\n     * @public\n     * @returns {Promise<void>} A promise.\n     */\n    turnOff() {\n        return this.privSource.turnOff();\n    }\n    /**\n     * @member AudioConfigImpl.prototype.events\n     * @function\n     * @public\n     * @returns {EventSource<AudioSourceEvent>} An event source for audio events.\n     */\n    get events() {\n        return this.privSource.events;\n    }\n    setProperty(name, value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(value, \"value\");\n        if (undefined !== this.privSource.setProperty) {\n            this.privSource.setProperty(name, value);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support setting properties.\");\n        }\n    }\n    getProperty(name, def) {\n        if (undefined !== this.privSource.getProperty) {\n            return this.privSource.getProperty(name, def);\n        }\n        else {\n            throw new Error(\"This AudioConfig instance does not support getting properties.\");\n        }\n        return def;\n    }\n    get deviceInfo() {\n        return this.privSource.deviceInfo;\n    }\n}\nclass AudioOutputConfigImpl extends AudioConfig {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {IAudioDestination} destination - An audio destination.\n     */\n    constructor(destination) {\n        super();\n        this.privDestination = destination;\n    }\n    set format(format) {\n        this.privDestination.format = format;\n    }\n    write(buffer) {\n        this.privDestination.write(buffer);\n    }\n    close() {\n        this.privDestination.close();\n    }\n    id() {\n        return this.privDestination.id();\n    }\n    setProperty() {\n        throw new Error(\"This AudioConfig instance does not support setting properties.\");\n    }\n    getProperty() {\n        throw new Error(\"This AudioConfig instance does not support getting properties.\");\n    }\n}\n\n//# sourceMappingURL=AudioConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js ***!
  \*************************************************************************************************************/
/*! exports provided: AudioFileWriter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioFileWriter\", function() { return AudioFileWriter; });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"fs\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass AudioFileWriter {\n    constructor(filename) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__[\"openSync\"], \"\\nFile System access not available, please use Push or PullAudioOutputStream\");\n        this.privFd = fs__WEBPACK_IMPORTED_MODULE_0__[\"openSync\"](filename, \"w\");\n    }\n    set format(format) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNotUndefined(this.privAudioFormat, \"format is already set\");\n        this.privAudioFormat = format;\n        let headerOffset = 0;\n        if (this.privAudioFormat.hasHeader) {\n            headerOffset = this.privAudioFormat.header.byteLength;\n        }\n        if (this.privFd !== undefined) {\n            this.privWriteStream = fs__WEBPACK_IMPORTED_MODULE_0__[\"createWriteStream\"](\"\", { fd: this.privFd, start: headerOffset, autoClose: false });\n        }\n    }\n    write(buffer) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(this.privAudioFormat, \"must set format before writing.\");\n        if (this.privWriteStream !== undefined) {\n            this.privWriteStream.write(new Uint8Array(buffer.slice(0)));\n        }\n    }\n    close() {\n        if (this.privFd !== undefined) {\n            this.privWriteStream.on(\"finish\", () => {\n                if (this.privAudioFormat.hasHeader) {\n                    this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);\n                    fs__WEBPACK_IMPORTED_MODULE_0__[\"writeSync\"](this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);\n                }\n                fs__WEBPACK_IMPORTED_MODULE_0__[\"closeSync\"](this.privFd);\n                this.privFd = undefined;\n            });\n            this.privWriteStream.end();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=AudioFileWriter.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js ***!
  \**************************************************************************************************************/
/*! exports provided: AudioInputStream, PushAudioInputStream, PushAudioInputStreamImpl, PullAudioInputStream, PullAudioInputStreamImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioInputStream\", function() { return AudioInputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PushAudioInputStream\", function() { return PushAudioInputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PushAudioInputStreamImpl\", function() { return PushAudioInputStreamImpl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStream\", function() { return PullAudioInputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStreamImpl\", function() { return PullAudioInputStreamImpl; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _common_Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @class AudioInputStream\n */\nclass AudioInputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member AudioInputStream.createPushStream\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The audio input stream being created.\n     */\n    static createPushStream(format) {\n        return PushAudioInputStream.create(format);\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for read()\n     * and close() methods.\n     * @member AudioInputStream.createPullStream\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from\n     * PullAudioInputStreamCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from\n     * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The audio input stream being created.\n     */\n    static createPullStream(callback, format) {\n        return PullAudioInputStream.create(callback, format);\n        // throw new Error(\"Oops\");\n    }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @class PushAudioInputStream\n */\nclass PushAudioInputStream extends AudioInputStream {\n    /**\n     * Creates a memory backed PushAudioInputStream with the specified audio format.\n     * @member PushAudioInputStream.create\n     * @function\n     * @public\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the\n     * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PushAudioInputStream} The push audio input stream being created.\n     */\n    static create(format) {\n        return new PushAudioInputStreamImpl(format);\n    }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @private\n * @class PushAudioInputStreamImpl\n */\nclass PushAudioInputStreamImpl extends PushAudioInputStream {\n    /**\n     * Creates and initalizes an instance with the given values.\n     * @constructor\n     * @param {AudioStreamFormat} format - The audio stream format.\n     */\n    constructor(format) {\n        super();\n        if (format === undefined) {\n            this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_4__[\"AudioStreamFormatImpl\"].getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privId = Object(_common_Guid__WEBPACK_IMPORTED_MODULE_2__[\"createNoDashGuid\"])();\n        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"ChunkedArrayBufferStream\"](this.privFormat.avgBytesPerSec / 10);\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PushAudioInputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PushAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n    id() {\n        return this.privId;\n    }\n    get blob() {\n        return this.attach(\"id\").then((audioNode) => {\n            const data = [];\n            let bufferData = Buffer.from(\"\");\n            const readCycle = () => audioNode.read().then((audioStreamChunk) => {\n                if (!audioStreamChunk || audioStreamChunk.isEnd) {\n                    if (typeof (XMLHttpRequest) !== \"undefined\" && typeof (Blob) !== \"undefined\") {\n                        return Promise.resolve(new Blob(data));\n                    }\n                    else {\n                        return Promise.resolve(Buffer.from(bufferData));\n                    }\n                }\n                else {\n                    if (typeof (Blob) !== \"undefined\") {\n                        data.push(audioStreamChunk.buffer);\n                    }\n                    else {\n                        bufferData = Buffer.concat([bufferData, this.toBuffer(audioStreamChunk.buffer)]);\n                    }\n                    return readCycle();\n                }\n            });\n            return readCycle();\n        });\n    }\n    turnOn() {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceInitializingEvent\"](this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceReadyEvent\"](this.privId));\n        return;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachingEvent\"](this.privId, audioNodeId));\n            yield this.turnOn();\n            const stream = this.privStream;\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachedEvent\"](this.privId, audioNodeId));\n            return {\n                detach: () => __awaiter(this, void 0, void 0, function* () {\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n                    return this.turnOff();\n                }),\n                id: () => audioNodeId,\n                read: () => stream.read(),\n            };\n        });\n    }\n    detach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"connectivity\"].Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PushStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"type\"].Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(event);\n    }\n    toBuffer(arrayBuffer) {\n        const buf = Buffer.alloc(arrayBuffer.byteLength);\n        const view = new Uint8Array(arrayBuffer);\n        for (let i = 0; i < buf.length; ++i) {\n            buf[i] = view[i];\n        }\n        return buf;\n    }\n}\n/*\n * Represents audio input stream used for custom audio input configurations.\n * @class PullAudioInputStream\n */\nclass PullAudioInputStream extends AudioInputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @member PullAudioInputStream.create\n     * @function\n     * @public\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     * @returns {PullAudioInputStream} The push audio input stream being created.\n     */\n    static create(callback, format) {\n        return new PullAudioInputStreamImpl(callback, format);\n    }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class PullAudioInputStreamImpl\n */\nclass PullAudioInputStreamImpl extends PullAudioInputStream {\n    /**\n     * Creates a PullAudioInputStream that delegates to the specified callback interface for\n     * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n     * @constructor\n     * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n     * derived from PullAudioInputStreamCustomCallback\n     * @param {AudioStreamFormat} format - The audio data format in which audio will be\n     * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n     */\n    constructor(callback, format) {\n        super();\n        if (undefined === format) {\n            this.privFormat = _Exports__WEBPACK_IMPORTED_MODULE_3__[\"AudioStreamFormat\"].getDefaultInputFormat();\n        }\n        else {\n            this.privFormat = format;\n        }\n        this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"EventSource\"]();\n        this.privId = Object(_common_Guid__WEBPACK_IMPORTED_MODULE_2__[\"createNoDashGuid\"])();\n        this.privCallback = callback;\n        this.privIsClosed = false;\n        this.privBufferSize = this.privFormat.avgBytesPerSec / 10;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return Promise.resolve(this.privFormat);\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioInputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privIsClosed = true;\n        this.privCallback.close();\n    }\n    id() {\n        return this.privId;\n    }\n    get blob() {\n        return Promise.reject(\"Not implemented\");\n    }\n    turnOn() {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceInitializingEvent\"](this.privId)); // no stream id\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioSourceReadyEvent\"](this.privId));\n        return;\n    }\n    attach(audioNodeId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachingEvent\"](this.privId, audioNodeId));\n            yield this.turnOn();\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeAttachedEvent\"](this.privId, audioNodeId));\n            return {\n                detach: () => {\n                    this.privCallback.close();\n                    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n                    return this.turnOff();\n                },\n                id: () => audioNodeId,\n                read: () => {\n                    let totalBytes = 0;\n                    let transmitBuff;\n                    // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n                    while (totalBytes < this.privBufferSize) {\n                        // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much\n                        // data back.\n                        const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);\n                        const pulledBytes = this.privCallback.read(readBuff);\n                        // If there is no return buffer yet defined, set the return buffer to the that was just populated.\n                        // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the\n                        // preferred size allocated.\n                        if (undefined === transmitBuff) {\n                            transmitBuff = readBuff;\n                        }\n                        else {\n                            // Not the first bite at the apple, so fill the return buffer with the data we got back.\n                            const intView = new Int8Array(transmitBuff);\n                            intView.set(new Int8Array(readBuff), totalBytes);\n                        }\n                        // If there are no bytes to read, just break out and be done.\n                        if (0 === pulledBytes) {\n                            break;\n                        }\n                        totalBytes += pulledBytes;\n                    }\n                    return Promise.resolve({\n                        buffer: transmitBuff.slice(0, totalBytes),\n                        isEnd: this.privIsClosed || totalBytes === 0,\n                        timeReceived: Date.now(),\n                    });\n                },\n            };\n        });\n    }\n    detach(audioNodeId) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamNodeDetachedEvent\"](this.privId, audioNodeId));\n    }\n    turnOff() {\n        return;\n    }\n    get events() {\n        return this.privEvents;\n    }\n    get deviceInfo() {\n        return Promise.resolve({\n            bitspersample: this.privFormat.bitsPerSample,\n            channelcount: this.privFormat.channels,\n            connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"connectivity\"].Unknown,\n            manufacturer: \"Speech SDK\",\n            model: \"PullStream\",\n            samplerate: this.privFormat.samplesPerSec,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"type\"].Stream,\n        });\n    }\n    onEvent(event) {\n        this.privEvents.onEvent(event);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(event);\n    }\n}\n\n//# sourceMappingURL=AudioInputStream.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioOutputFormatImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioOutputFormatImpl\", function() { return AudioOutputFormatImpl; });\n/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../SpeechSynthesisOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * @private\n * @class AudioOutputFormatImpl\n * Updated in version 1.17.0\n */\n// eslint-disable-next-line max-classes-per-file\nclass AudioOutputFormatImpl extends _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamFormatImpl\"] {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param formatTag\n     * @param {number} channels - Number of channels.\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} avgBytesPerSec - Average bytes per second.\n     * @param {number} blockAlign - Block alignment.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {string} audioFormatString - Audio format string\n     * @param {string} requestAudioFormatString - Audio format string sent to service.\n     * @param {boolean} hasHeader - If the format has header or not.\n     */\n    constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {\n        super(samplesPerSec, bitsPerSample, channels, formatTag);\n        this.formatTag = formatTag;\n        this.avgBytesPerSec = avgBytesPerSec;\n        this.blockAlign = blockAlign;\n        this.priAudioFormatString = audioFormatString;\n        this.priRequestAudioFormatString = requestAudioFormatString;\n        this.priHasHeader = hasHeader;\n    }\n    static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {\n        if (speechSynthesisOutputFormat === undefined) {\n            return AudioOutputFormatImpl.getDefaultOutputFormat();\n        }\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);\n    }\n    static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {\n        switch (speechSynthesisOutputFormatString) {\n            case \"raw-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, \"audio-16khz-16kbps-mono-siren\", true);\n            case \"audio-16khz-16kbps-mono-siren\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-32kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-128kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-64kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-48kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-160kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-16khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", true);\n            case \"riff-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", true);\n            case \"riff-8khz-8bit-mono-mulaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-mulaw\", true);\n            case \"raw-16khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, \"raw-16khz-16bit-mono-pcm\", false);\n            case \"raw-24khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", false);\n            case \"raw-8khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", false);\n            case \"ogg-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", false);\n            case \"riff-48khz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", true);\n            case \"audio-48khz-96kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-192kbitrate-mono-mp3\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"ogg-48khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-16khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"webm-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-16khz-16bit-32kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-48kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-24kbps-mono-opus\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-24khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"audio-48khz-16bit-mono-flac\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-24khz-16bit-mono-truesilk\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"raw-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-8khz-8bit-mono-alaw\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-alaw\", true);\n            case \"raw-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-22050hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, \"raw-22050hz-16bit-mono-pcm\", true);\n            case \"raw-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n            case \"riff-44100hz-16bit-mono-pcm\":\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, \"raw-44100hz-16bit-mono-pcm\", true);\n            case \"riff-16khz-16bit-mono-pcm\":\n            default:\n                return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"].PCM, 1, 16000, 32000, 2, 16, \"riff-16khz-16bit-mono-pcm\", \"raw-16khz-16bit-mono-pcm\", true);\n        }\n    }\n    static getDefaultOutputFormat() {\n        return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString((typeof window !== \"undefined\") ? \"audio-24khz-48kbitrate-mono-mp3\" : \"riff-16khz-16bit-mono-pcm\");\n    }\n    /**\n     * Specifies if this audio output format has a header\n     * @boolean AudioOutputFormatImpl.prototype.hasHeader\n     * @function\n     * @public\n     */\n    get hasHeader() {\n        return this.priHasHeader;\n    }\n    /**\n     * Specifies the header of this format\n     * @ArrayBuffer AudioOutputFormatImpl.prototype.header\n     * @function\n     * @public\n     */\n    get header() {\n        if (this.hasHeader) {\n            return this.privHeader;\n        }\n        return undefined;\n    }\n    /**\n     * Updates the header based on the audio length\n     * @member AudioOutputFormatImpl.updateHeader\n     * @function\n     * @public\n     * @param {number} audioLength - the audio length\n     */\n    updateHeader(audioLength) {\n        if (this.priHasHeader) {\n            const view = new DataView(this.privHeader);\n            view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);\n            view.setUint32(40, audioLength, true);\n        }\n    }\n    /**\n     * Specifies the audio format string to be sent to the service\n     * @string AudioOutputFormatImpl.prototype.requestAudioFormatString\n     * @function\n     * @public\n     */\n    get requestAudioFormatString() {\n        return this.priRequestAudioFormatString;\n    }\n}\nAudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw8Khz8BitMonoMULaw]: \"raw-8khz-8bit-mono-mulaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff16Khz16KbpsMonoSiren]: \"riff-16khz-16kbps-mono-siren\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio16Khz16KbpsMonoSiren]: \"audio-16khz-16kbps-mono-siren\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio16Khz32KBitRateMonoMp3]: \"audio-16khz-32kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio16Khz128KBitRateMonoMp3]: \"audio-16khz-128kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio16Khz64KBitRateMonoMp3]: \"audio-16khz-64kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio24Khz48KBitRateMonoMp3]: \"audio-24khz-48kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio24Khz96KBitRateMonoMp3]: \"audio-24khz-96kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio24Khz160KBitRateMonoMp3]: \"audio-24khz-160kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw16Khz16BitMonoTrueSilk]: \"raw-16khz-16bit-mono-truesilk\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff16Khz16BitMonoPcm]: \"riff-16khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff8Khz16BitMonoPcm]: \"riff-8khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff24Khz16BitMonoPcm]: \"riff-24khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff8Khz8BitMonoMULaw]: \"riff-8khz-8bit-mono-mulaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw16Khz16BitMonoPcm]: \"raw-16khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw24Khz16BitMonoPcm]: \"raw-24khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw8Khz16BitMonoPcm]: \"raw-8khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Ogg16Khz16BitMonoOpus]: \"ogg-16khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Ogg24Khz16BitMonoOpus]: \"ogg-24khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw48Khz16BitMonoPcm]: \"raw-48khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff48Khz16BitMonoPcm]: \"riff-48khz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio48Khz96KBitRateMonoMp3]: \"audio-48khz-96kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio48Khz192KBitRateMonoMp3]: \"audio-48khz-192kbitrate-mono-mp3\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Ogg48Khz16BitMonoOpus]: \"ogg-48khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Webm16Khz16BitMonoOpus]: \"webm-16khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Webm24Khz16BitMonoOpus]: \"webm-24khz-16bit-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Webm24Khz16Bit24KbpsMonoOpus]: \"webm-24khz-16bit-24kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw24Khz16BitMonoTrueSilk]: \"raw-24khz-16bit-mono-truesilk\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw8Khz8BitMonoALaw]: \"raw-8khz-8bit-mono-alaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff8Khz8BitMonoALaw]: \"riff-8khz-8bit-mono-alaw\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio16Khz16Bit32KbpsMonoOpus]: \"audio-16khz-16bit-32kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio24Khz16Bit48KbpsMonoOpus]: \"audio-24khz-16bit-48kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Audio24Khz16Bit24KbpsMonoOpus]: \"audio-24khz-16bit-24kbps-mono-opus\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw22050Hz16BitMonoPcm]: \"raw-22050hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff22050Hz16BitMonoPcm]: \"riff-22050hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Raw44100Hz16BitMonoPcm]: \"raw-44100hz-16bit-mono-pcm\",\n    [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisOutputFormat\"].Riff44100Hz16BitMonoPcm]: \"riff-44100hz-16bit-mono-pcm\",\n};\n\n//# sourceMappingURL=AudioOutputFormat.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioOutputStream, PullAudioOutputStream, PullAudioOutputStreamImpl, PushAudioOutputStream, PushAudioOutputStreamImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioOutputStream\", function() { return AudioOutputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PullAudioOutputStream\", function() { return PullAudioOutputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PullAudioOutputStreamImpl\", function() { return PullAudioOutputStreamImpl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStream\", function() { return PushAudioOutputStream; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStreamImpl\", function() { return PushAudioOutputStreamImpl; });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @class AudioOutputStream\n */\nclass AudioOutputStream {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member AudioOutputStream.createPullStream\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The audio output stream being created.\n     */\n    static createPullStream() {\n        return PullAudioOutputStream.create();\n    }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @class PullAudioOutputStream\n */\nclass PullAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates a memory backed PullAudioOutputStream with the specified audio format.\n     * @member PullAudioOutputStream.create\n     * @function\n     * @public\n     * @returns {PullAudioOutputStream} The push audio output stream being created.\n     */\n    static create() {\n        return new PullAudioOutputStreamImpl();\n    }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @private\n * @class PullAudioOutputStreamImpl\n */\nclass PullAudioOutputStreamImpl extends PullAudioOutputStream {\n    /**\n     * Creates and initializes an instance with the given values.\n     * @constructor\n     */\n    constructor() {\n        super();\n        this.privId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Stream\"]();\n    }\n    /**\n     * Sets the format information to the stream. For internal use only.\n     * @param {AudioStreamFormat} format - the format to be set.\n     */\n    set format(format) {\n        if (format === undefined || format === null) {\n            this.privFormat = _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__[\"AudioOutputFormatImpl\"].getDefaultOutputFormat();\n        }\n        this.privFormat = format;\n    }\n    /**\n     * Format information for the audio\n     */\n    get format() {\n        return this.privFormat;\n    }\n    /**\n     * Checks if the stream is closed\n     * @member PullAudioOutputStreamImpl.prototype.isClosed\n     * @property\n     * @public\n     */\n    get isClosed() {\n        return this.privStream.isClosed;\n    }\n    /**\n     * Gets the id of the stream\n     * @member PullAudioOutputStreamImpl.prototype.id\n     * @property\n     * @public\n     */\n    id() {\n        return this.privId;\n    }\n    /**\n     * Reads audio data from the internal buffer.\n     * @member PullAudioOutputStreamImpl.prototype.read\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.\n     * @returns {Promise<number>} - Audio buffer length has been read.\n     */\n    read(dataBuffer) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const intView = new Int8Array(dataBuffer);\n            let totalBytes = 0;\n            if (this.privLastChunkView !== undefined) {\n                if (this.privLastChunkView.length > dataBuffer.byteLength) {\n                    intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));\n                    this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);\n                    return Promise.resolve(dataBuffer.byteLength);\n                }\n                intView.set(this.privLastChunkView);\n                totalBytes = this.privLastChunkView.length;\n                this.privLastChunkView = undefined;\n            }\n            // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n            while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {\n                const chunk = yield this.privStream.read();\n                if (chunk !== undefined && !chunk.isEnd) {\n                    let tmpBuffer;\n                    if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {\n                        tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);\n                        this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));\n                    }\n                    else {\n                        tmpBuffer = chunk.buffer;\n                    }\n                    intView.set(new Int8Array(tmpBuffer), totalBytes);\n                    totalBytes += tmpBuffer.byteLength;\n                }\n                else {\n                    this.privStream.readEnded();\n                }\n            }\n            return totalBytes;\n        });\n    }\n    /**\n     * Writes the audio data specified by making an internal copy of the data.\n     * @member PullAudioOutputStreamImpl.prototype.write\n     * @function\n     * @public\n     * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n     */\n    write(dataBuffer) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(this.privStream, \"must set format before writing\");\n        this.privStream.writeStreamChunk({\n            buffer: dataBuffer,\n            isEnd: false,\n            timeReceived: Date.now()\n        });\n    }\n    /**\n     * Closes the stream.\n     * @member PullAudioOutputStreamImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        this.privStream.close();\n    }\n}\n/*\n * Represents audio output stream used for custom audio output configurations.\n * @class PushAudioOutputStream\n */\nclass PushAudioOutputStream extends AudioOutputStream {\n    /**\n     * Creates and initializes and instance.\n     * @constructor\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * write() and close() methods.\n     * @member PushAudioOutputStream.create\n     * @function\n     * @public\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     * @returns {PushAudioOutputStream} The push audio output stream being created.\n     */\n    static create(callback) {\n        return new PushAudioOutputStreamImpl(callback);\n    }\n}\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @private\n * @class PushAudioOutputStreamImpl\n */\nclass PushAudioOutputStreamImpl extends PushAudioOutputStream {\n    /**\n     * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n     * read() and close() methods.\n     * @constructor\n     * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n     * derived from PushAudioOutputStreamCallback\n     */\n    constructor(callback) {\n        super();\n        this.privId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"createNoDashGuid\"])();\n        this.privCallback = callback;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set format(format) { }\n    write(buffer) {\n        if (!!this.privCallback.write) {\n            this.privCallback.write(buffer);\n        }\n    }\n    close() {\n        if (!!this.privCallback.close) {\n            this.privCallback.close();\n        }\n    }\n    id() {\n        return this.privId;\n    }\n}\n\n//# sourceMappingURL=AudioOutputStream.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js ***!
  \***************************************************************************************************************/
/*! exports provided: AudioFormatTag, AudioStreamFormat, AudioStreamFormatImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioFormatTag\", function() { return AudioFormatTag; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamFormat\", function() { return AudioStreamFormat; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamFormatImpl\", function() { return AudioStreamFormatImpl; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// eslint-disable-next-line max-classes-per-file\nvar AudioFormatTag;\n(function (AudioFormatTag) {\n    AudioFormatTag[AudioFormatTag[\"PCM\"] = 1] = \"PCM\";\n    AudioFormatTag[AudioFormatTag[\"MuLaw\"] = 2] = \"MuLaw\";\n    AudioFormatTag[AudioFormatTag[\"Siren\"] = 3] = \"Siren\";\n    AudioFormatTag[AudioFormatTag[\"MP3\"] = 4] = \"MP3\";\n    AudioFormatTag[AudioFormatTag[\"SILKSkype\"] = 5] = \"SILKSkype\";\n    AudioFormatTag[AudioFormatTag[\"OGG_OPUS\"] = 6] = \"OGG_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"WEBM_OPUS\"] = 7] = \"WEBM_OPUS\";\n    AudioFormatTag[AudioFormatTag[\"ALaw\"] = 8] = \"ALaw\";\n    AudioFormatTag[AudioFormatTag[\"FLAC\"] = 9] = \"FLAC\";\n    AudioFormatTag[AudioFormatTag[\"OPUS\"] = 10] = \"OPUS\";\n})(AudioFormatTag || (AudioFormatTag = {}));\n/**\n * Represents audio stream format used for custom audio input configurations.\n * @class AudioStreamFormat\n */\nclass AudioStreamFormat {\n    /**\n     * Creates an audio stream format object representing the default audio stream\n     * format (16KHz 16bit mono PCM).\n     * @member AudioStreamFormat.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getDefaultInputFormat() {\n        return AudioStreamFormatImpl.getDefaultInputFormat();\n    }\n    /**\n     * Creates an audio stream format object with the specified format characteristics.\n     * @member AudioStreamFormat.getWaveFormat\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);\n    }\n    /**\n     * Creates an audio stream format object with the specified pcm waveformat characteristics.\n     * @member AudioStreamFormat.getWaveFormatPCM\n     * @function\n     * @public\n     * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n     * @param {number} bitsPerSample - Bits per sample, typically 16.\n     * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n     * uses one channel and stereo data uses two channels.\n     * @returns {AudioStreamFormat} The audio stream format being created.\n     */\n    static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {\n        return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);\n    }\n}\n/**\n * @private\n * @class AudioStreamFormatImpl\n */\nclass AudioStreamFormatImpl extends AudioStreamFormat {\n    /**\n     * Creates an instance with the given values.\n     * @constructor\n     * @param {number} samplesPerSec - Samples per second.\n     * @param {number} bitsPerSample - Bits per sample.\n     * @param {number} channels - Number of channels.\n     * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n     */\n    constructor(samplesPerSec = 16000, bitsPerSample = 16, channels = 1, format = AudioFormatTag.PCM) {\n        super();\n        let isWavFormat = true;\n        /* 1 for PCM; 6 for alaw; 7 for mulaw */\n        switch (format) {\n            case AudioFormatTag.PCM:\n                this.formatTag = 1;\n                break;\n            case AudioFormatTag.ALaw:\n                this.formatTag = 6;\n                break;\n            case AudioFormatTag.MuLaw:\n                this.formatTag = 7;\n                break;\n            default:\n                isWavFormat = false;\n        }\n        this.bitsPerSample = bitsPerSample;\n        this.samplesPerSec = samplesPerSec;\n        this.channels = channels;\n        this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);\n        this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);\n        if (isWavFormat) {\n            this.privHeader = new ArrayBuffer(44);\n            // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\n            const view = new DataView(this.privHeader);\n            /* RIFF identifier */\n            this.setString(view, 0, \"RIFF\");\n            /* file length */\n            view.setUint32(4, 0, true);\n            /* RIFF type & Format */\n            this.setString(view, 8, \"WAVEfmt \");\n            /* format chunk length */\n            view.setUint32(16, 16, true);\n            /* audio format */\n            view.setUint16(20, this.formatTag, true);\n            /* channel count */\n            view.setUint16(22, this.channels, true);\n            /* sample rate */\n            view.setUint32(24, this.samplesPerSec, true);\n            /* byte rate (sample rate * block align) */\n            view.setUint32(28, this.avgBytesPerSec, true);\n            /* block align (channel count * bytes per sample) */\n            view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);\n            /* bits per sample */\n            view.setUint16(34, this.bitsPerSample, true);\n            /* data chunk identifier */\n            this.setString(view, 36, \"data\");\n            /* data chunk length */\n            view.setUint32(40, 0, true);\n        }\n    }\n    /**\n     * Retrieves the default input format.\n     * @member AudioStreamFormatImpl.getDefaultInputFormat\n     * @function\n     * @public\n     * @returns {AudioStreamFormatImpl} The default input format.\n     */\n    static getDefaultInputFormat() {\n        return new AudioStreamFormatImpl();\n    }\n    /**\n     * Creates an audio context appropriate to current browser\n     * @member AudioStreamFormatImpl.getAudioContext\n     * @function\n     * @public\n     * @returns {AudioContext} An audio context instance\n     */\n    /* eslint-disable */\n    static getAudioContext(sampleRate) {\n        // Workaround for Speech SDK bug in Safari.\n        const AudioContext = window.AudioContext // our preferred impl\n            || window.webkitAudioContext // fallback, mostly when on Safari\n            || false; // could not find.\n        // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\n        if (!!AudioContext) {\n            if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n                return new AudioContext({ sampleRate });\n            }\n            else {\n                return new AudioContext();\n            }\n        }\n        else {\n            throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\n        }\n    }\n    /* eslint-enable */\n    /**\n     * Closes the configuration object.\n     * @member AudioStreamFormatImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    get header() {\n        return this.privHeader;\n    }\n    setString(view, offset, str) {\n        for (let i = 0; i < str.length; i++) {\n            view.setUint8(offset + i, str.charCodeAt(i));\n        }\n    }\n}\n\n//# sourceMappingURL=AudioStreamFormat.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js ***!
  \*************************************************************************************************************/
/*! exports provided: BaseAudioPlayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BaseAudioPlayer\", function() { return BaseAudioPlayer; });\n/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Base audio player class\n * TODO: Plays only PCM for now.\n * @class\n */\nclass BaseAudioPlayer {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.\n     */\n    constructor(audioFormat) {\n        this.audioContext = null;\n        this.gainNode = null;\n        this.autoUpdateBufferTimer = 0;\n        if (audioFormat === undefined) {\n            audioFormat = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamFormat\"].getDefaultInputFormat();\n        }\n        this.init(audioFormat);\n    }\n    /**\n     * play Audio sample\n     * @param newAudioData audio data to be played.\n     */\n    playAudioSample(newAudioData, cb, err) {\n        try {\n            this.ensureInitializedContext();\n            const audioData = this.formatAudioData(newAudioData);\n            const newSamplesData = new Float32Array(this.samples.length + audioData.length);\n            newSamplesData.set(this.samples, 0);\n            newSamplesData.set(audioData, this.samples.length);\n            this.samples = newSamplesData;\n            if (!!cb) {\n                cb();\n            }\n        }\n        catch (e) {\n            if (!!err) {\n                err(e);\n            }\n        }\n    }\n    /**\n     * stops audio and clears the buffers\n     */\n    stopAudio(cb, err) {\n        if (this.audioContext !== null) {\n            this.samples = new Float32Array();\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n            clearInterval(this.autoUpdateBufferTimer);\n            this.audioContext.close().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n            this.audioContext = null;\n        }\n    }\n    init(audioFormat) {\n        this.audioFormat = audioFormat;\n        this.samples = new Float32Array();\n    }\n    ensureInitializedContext() {\n        if (this.audioContext === null) {\n            this.createAudioContext();\n            const timerPeriod = 200;\n            this.autoUpdateBufferTimer = setInterval(() => {\n                this.updateAudioBuffer();\n            }, timerPeriod);\n        }\n    }\n    createAudioContext() {\n        // new ((window as any).AudioContext || (window as any).webkitAudioContext)();\n        this.audioContext = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_2__[\"AudioStreamFormatImpl\"].getAudioContext();\n        // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan\n        // to control the volume, not likely\n        this.gainNode = this.audioContext.createGain();\n        this.gainNode.gain.value = 1;\n        this.gainNode.connect(this.audioContext.destination);\n        this.startTime = this.audioContext.currentTime;\n    }\n    formatAudioData(audioData) {\n        switch (this.audioFormat.bitsPerSample) {\n            case 8:\n                return this.formatArrayBuffer(new Int8Array(audioData), 128);\n            case 16:\n                return this.formatArrayBuffer(new Int16Array(audioData), 32768);\n            case 32:\n                return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);\n            default:\n                throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__[\"InvalidOperationError\"](\"Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time\");\n        }\n    }\n    formatArrayBuffer(audioData, maxValue) {\n        const float32Data = new Float32Array(audioData.length);\n        for (let i = 0; i < audioData.length; i++) {\n            float32Data[i] = audioData[i] / maxValue;\n        }\n        return float32Data;\n    }\n    updateAudioBuffer() {\n        if (this.samples.length === 0) {\n            return;\n        }\n        const channelCount = this.audioFormat.channels;\n        const bufferSource = this.audioContext.createBufferSource();\n        const frameCount = this.samples.length / channelCount;\n        const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);\n        // TODO: Should we do the conversion in the pushAudioSample instead?\n        for (let channel = 0; channel < channelCount; channel++) {\n            // Fill in individual channel data\n            let channelOffset = channel;\n            const audioData = audioBuffer.getChannelData(channel);\n            for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {\n                audioData[i] = this.samples[channelOffset];\n            }\n        }\n        if (this.startTime < this.audioContext.currentTime) {\n            this.startTime = this.audioContext.currentTime;\n        }\n        bufferSource.buffer = audioBuffer;\n        bufferSource.connect(this.gainNode);\n        bufferSource.start(this.startTime);\n        // Make sure we play the next sample after the current one.\n        this.startTime += audioBuffer.duration;\n        // Clear the samples for the next pushed data.\n        this.samples = new Float32Array();\n    }\n    playAudio(audioData) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.audioContext === null) {\n                this.createAudioContext();\n            }\n            const source = this.audioContext.createBufferSource();\n            const destination = this.audioContext.destination;\n            yield this.audioContext.decodeAudioData(audioData, (newBuffer) => {\n                source.buffer = newBuffer;\n                source.connect(destination);\n                source.start(0);\n            });\n        });\n    }\n}\n\n//# sourceMappingURL=BaseAudioPlayer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \**************************************************************************************************************************/
/*! exports provided: PullAudioInputStreamCallback */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStreamCallback\", function() { return PullAudioInputStreamCallback; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (read() and close()) for\n * custom audio input streams).\n * @class PullAudioInputStreamCallback\n */\nclass PullAudioInputStreamCallback {\n}\n\n//# sourceMappingURL=PullAudioInputStreamCallback.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \***************************************************************************************************************************/
/*! exports provided: PushAudioOutputStreamCallback */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStreamCallback\", function() { return PushAudioOutputStreamCallback; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (write() and close()) for\n * custom audio output streams).\n * @class PushAudioOutputStreamCallback\n */\nclass PushAudioOutputStreamCallback {\n}\n\n//# sourceMappingURL=PushAudioOutputStreamCallback.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \*********************************************************************************************************************/
/*! exports provided: SpeakerAudioDestination */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerAudioDestination\", function() { return SpeakerAudioDestination; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nconst MediaDurationPlaceholderSeconds = 60 * 30;\nconst AudioFormatToMimeType = {\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].PCM]: \"audio/wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].MuLaw]: \"audio/x-wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].MP3]: \"audio/mpeg\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].OGG_OPUS]: \"audio/ogg\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].WEBM_OPUS]: \"audio/webm; codecs=opus\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].ALaw]: \"audio/x-wav\",\n    [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].FLAC]: \"audio/flac\",\n};\n/**\n * Represents the speaker playback audio destination, which only works in browser.\n * Note: the SDK will try to use <a href=\"https://www.w3.org/TR/media-source/\">Media Source Extensions</a> to play audio.\n * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.\n * @class SpeakerAudioDestination\n * Updated in version 1.17.0\n */\nclass SpeakerAudioDestination {\n    constructor(audioDestinationId) {\n        this.privPlaybackStarted = false;\n        this.privAppendingToBuffer = false;\n        this.privMediaSourceOpened = false;\n        this.privBytesReceived = 0;\n        this.privId = audioDestinationId ? audioDestinationId : Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n        this.privIsPaused = false;\n        this.privIsClosed = false;\n    }\n    id() {\n        return this.privId;\n    }\n    write(buffer, cb, err) {\n        if (this.privAudioBuffer !== undefined) {\n            this.privAudioBuffer.push(buffer);\n            this.updateSourceBuffer().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined) {\n            this.privAudioOutputStream.write(buffer);\n            this.privBytesReceived += buffer.byteLength;\n        }\n    }\n    close(cb, err) {\n        this.privIsClosed = true;\n        if (this.privSourceBuffer !== undefined) {\n            this.handleSourceBufferUpdateEnd().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        else if (this.privAudioOutputStream !== undefined && typeof window !== \"undefined\") {\n            if ((this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].PCM || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].MuLaw\n                || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"].ALaw) && this.privFormat.hasHeader === false) {\n                // eslint-disable-next-line no-console\n                console.warn(\"Play back is not supported for raw PCM, mulaw or alaw format without header.\");\n                if (!!this.onAudioEnd) {\n                    this.onAudioEnd(this);\n                }\n            }\n            else {\n                let receivedAudio = new ArrayBuffer(this.privBytesReceived);\n                this.privAudioOutputStream.read(receivedAudio).then(() => {\n                    receivedAudio = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisAdapterBase\"].addHeader(receivedAudio, this.privFormat);\n                    const audioBlob = new Blob([receivedAudio], { type: AudioFormatToMimeType[this.privFormat.formatTag] });\n                    this.privAudio.src = window.URL.createObjectURL(audioBlob);\n                    this.notifyPlayback().then(() => {\n                        if (!!cb) {\n                            cb();\n                        }\n                    }, (error) => {\n                        if (!!err) {\n                            err(error);\n                        }\n                    });\n                }, (error) => {\n                    if (!!err) {\n                        err(error);\n                    }\n                });\n            }\n        }\n        else {\n            // unsupported format, call onAudioEnd directly.\n            if (!!this.onAudioEnd) {\n                this.onAudioEnd(this);\n            }\n        }\n    }\n    set format(format) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        if (typeof (AudioContext) !== \"undefined\" || (typeof (window) !== \"undefined\" && typeof (window.webkitAudioContext) !== \"undefined\")) {\n            this.privFormat = format;\n            const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];\n            if (mimeType === undefined) {\n                // eslint-disable-next-line no-console\n                console.warn(`Unknown mimeType for format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"][this.privFormat.formatTag]}; playback is not supported.`);\n            }\n            else if (typeof (MediaSource) !== \"undefined\" && MediaSource.isTypeSupported(mimeType)) {\n                this.privAudio = new Audio();\n                this.privAudioBuffer = [];\n                this.privMediaSource = new MediaSource();\n                this.privAudio.src = URL.createObjectURL(this.privMediaSource);\n                this.privAudio.load();\n                this.privMediaSource.onsourceopen = () => {\n                    this.privMediaSourceOpened = true;\n                    this.privMediaSource.duration = MediaDurationPlaceholderSeconds;\n                    this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);\n                    this.privSourceBuffer.onupdate = () => {\n                        this.updateSourceBuffer().catch((reason) => {\n                            _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"BackgroundEvent\"](reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdateend = () => {\n                        this.handleSourceBufferUpdateEnd().catch((reason) => {\n                            _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"BackgroundEvent\"](reason));\n                        });\n                    };\n                    this.privSourceBuffer.onupdatestart = () => {\n                        this.privAppendingToBuffer = false;\n                    };\n                };\n                this.updateSourceBuffer().catch((reason) => {\n                    _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"BackgroundEvent\"](reason));\n                });\n            }\n            else {\n                // eslint-disable-next-line no-console\n                console.warn(`Format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioFormatTag\"][this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);\n                this.privAudioOutputStream = new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioOutputStreamImpl\"]();\n                this.privAudioOutputStream.format = this.privFormat;\n                this.privAudio = new Audio();\n            }\n        }\n    }\n    get volume() {\n        var _a, _b;\n        return (_b = (_a = this.privAudio) === null || _a === void 0 ? void 0 : _a.volume) !== null && _b !== void 0 ? _b : -1;\n    }\n    set volume(volume) {\n        if (!!this.privAudio) {\n            this.privAudio.volume = volume;\n        }\n    }\n    mute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = true;\n        }\n    }\n    unmute() {\n        if (!!this.privAudio) {\n            this.privAudio.muted = false;\n        }\n    }\n    get isClosed() {\n        return this.privIsClosed;\n    }\n    get currentTime() {\n        if (this.privAudio !== undefined) {\n            return this.privAudio.currentTime;\n        }\n        return -1;\n    }\n    pause() {\n        if (!this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.pause();\n            this.privIsPaused = true;\n        }\n    }\n    resume(cb, err) {\n        if (this.privIsPaused && this.privAudio !== undefined) {\n            this.privAudio.play().then(() => {\n                if (!!cb) {\n                    cb();\n                }\n            }, (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n            this.privIsPaused = false;\n        }\n    }\n    get internalAudio() {\n        return this.privAudio;\n    }\n    updateSourceBuffer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privAudioBuffer !== undefined && (this.privAudioBuffer.length > 0) && this.sourceBufferAvailable()) {\n                this.privAppendingToBuffer = true;\n                const binary = this.privAudioBuffer.shift();\n                try {\n                    this.privSourceBuffer.appendBuffer(binary);\n                }\n                catch (error) {\n                    this.privAudioBuffer.unshift(binary);\n                    // eslint-disable-next-line no-console\n                    console.log(\"buffer filled, pausing addition of binaries until space is made\");\n                    return;\n                }\n                yield this.notifyPlayback();\n            }\n            else if (this.canEndStream()) {\n                yield this.handleSourceBufferUpdateEnd();\n            }\n        });\n    }\n    handleSourceBufferUpdateEnd() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.canEndStream() && this.sourceBufferAvailable()) {\n                this.privMediaSource.endOfStream();\n                yield this.notifyPlayback();\n            }\n        });\n    }\n    notifyPlayback() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privPlaybackStarted && this.privAudio !== undefined) {\n                this.privPlaybackStarted = true;\n                if (!!this.onAudioStart) {\n                    this.onAudioStart(this);\n                }\n                this.privAudio.onended = () => {\n                    if (!!this.onAudioEnd) {\n                        this.onAudioEnd(this);\n                    }\n                };\n                if (!this.privIsPaused) {\n                    yield this.privAudio.play();\n                }\n            }\n        });\n    }\n    canEndStream() {\n        return (this.isClosed && this.privSourceBuffer !== undefined && (this.privAudioBuffer.length === 0)\n            && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === \"open\");\n    }\n    sourceBufferAvailable() {\n        return (this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating);\n    }\n}\n\n//# sourceMappingURL=SpeakerAudioDestination.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AutoDetectSourceLanguageConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageConfig\", function() { return AutoDetectSourceLanguageConfig; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./LanguageIdMode */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js\");\n/* harmony import */ var _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./LanguageIdPriority */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n/**\n * Language auto detect configuration.\n * @class AutoDetectSourceLanguageConfig\n * Added in version 1.13.0.\n */\nclass AutoDetectSourceLanguageConfig {\n    constructor() {\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AtStartLanguageIdPriority, \"Latency\");\n        this.privLanguageIdMode = _LanguageIdMode__WEBPACK_IMPORTED_MODULE_3__[\"LanguageIdMode\"].AtStart;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromOpenRange\n     * @function\n     * @public\n     * Only [[SpeechSynthesizer]] supports source language auto detection from open range,\n     * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.\n     */\n    static fromOpenRange() {\n        const config = new AutoDetectSourceLanguageConfig();\n        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AutoDetectSourceLanguagesOpenRangeOptionName\"]);\n        return config;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromLanguages\n     * @function\n     * @public\n     * @param {string[]} languages Comma-separated string of languages (eg. \"en-US,fr-FR\") to populate properties of config.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.\n     */\n    static fromLanguages(languages) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfArrayEmptyOrWhitespace(languages, \"languages\");\n        const config = new AutoDetectSourceLanguageConfig();\n        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());\n        return config;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs\n     * @function\n     * @public\n     * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.\n     * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n     * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.\n     */\n    static fromSourceLanguageConfigs(configs) {\n        if (configs.length < 1) {\n            throw new Error(\"Expected non-empty SourceLanguageConfig array.\");\n        }\n        const autoConfig = new AutoDetectSourceLanguageConfig();\n        const langs = [];\n        configs.forEach((config) => {\n            langs.push(config.language);\n            if (config.endpointId !== undefined && config.endpointId !== \"\") {\n                const customProperty = config.language + _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId.toString();\n                autoConfig.properties.setProperty(customProperty, config.endpointId);\n            }\n        });\n        autoConfig.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());\n        return autoConfig;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.prototype.properties\n     * @function\n     * @public\n     * @return {PropertyCollection} Properties of the config.\n     * @summary Gets an auto detected language config properties\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.prototype.mode\n     * @function\n     * @public\n     * @param {LanguageIdMode} mode LID mode desired.\n     * @summary Sets LID operation to desired mode\n     */\n    set mode(mode) {\n        if (mode === _LanguageIdMode__WEBPACK_IMPORTED_MODULE_3__[\"LanguageIdMode\"].Continuous) {\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecognitionEndpointVersion, \"2\");\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ContinuousLanguageIdPriority, \"Latency\");\n        }\n        else {\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecognitionEndpointVersion, \"1\");\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ContinuousLanguageIdPriority, undefined);\n        }\n        this.privLanguageIdMode = mode;\n    }\n    /**\n     * @member AutoDetectSourceLanguageConfig.prototype.priority\n     * @function\n     * @public\n     * @param {LanguageIdPriority} priority LID priority desired.\n     * @summary Sets LID operation to desired priority\n     */\n    set priority(priority) {\n        if (priority === _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_4__[\"LanguageIdPriority\"].Accuracy) {\n            if (this.privLanguageIdMode !== _LanguageIdMode__WEBPACK_IMPORTED_MODULE_3__[\"LanguageIdMode\"].Continuous) {\n                // Accuracy not allowed for continuous mode\n                this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AtStartLanguageIdPriority, \"Accuracy\");\n            }\n        }\n        else {\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ContinuousLanguageIdPriority, \"Latency\");\n            this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AtStartLanguageIdPriority, \"Latency\");\n        }\n    }\n}\n\n//# sourceMappingURL=AutoDetectSourceLanguageConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \**********************************************************************************************************************/
/*! exports provided: AutoDetectSourceLanguageResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageResult\", function() { return AutoDetectSourceLanguageResult; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Output format\n * @class AutoDetectSourceLanguageResult\n */\nclass AutoDetectSourceLanguageResult {\n    constructor(language, languageDetectionConfidence) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(language, \"language\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(languageDetectionConfidence, \"languageDetectionConfidence\");\n        this.privLanguage = language;\n        this.privLanguageDetectionConfidence = languageDetectionConfidence;\n    }\n    /**\n     * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.\n     * @member AutoDetectSourceLanguageResult.fromResult\n     * @function\n     * @public\n     * @param {SpeechRecognitionResult} result - The recognition result.\n     * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.\n     */\n    static fromResult(result) {\n        return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);\n    }\n    get language() {\n        return this.privLanguage;\n    }\n    get languageDetectionConfidence() {\n        return this.privLanguageDetectionConfidence;\n    }\n}\n\n//# sourceMappingURL=AutoDetectSourceLanguageResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js ***!
  \**********************************************************************************************************/
/*! exports provided: BotFrameworkConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BotFrameworkConfig\", function() { return BotFrameworkConfig; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.\n * @class BotFrameworkConfig\n */\nclass BotFrameworkConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"] {\n    /**\n     * Creates an instance of BotFrameworkConfig.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates a bot framework configuration instance with the provided subscription information.\n     * @member BotFrameworkConfig.fromSubscription\n     * @function\n     * @public\n     * @param subscription Subscription key associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromSubscription(subscription, region, botId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(subscription, \"subscription\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscription);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        if (botId) {\n            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, botId);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates a bot framework configuration instance for the specified authorization token and region.\n     * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the\n     * caller must refresh it by setting the authorizationToken property on the corresponding\n     * DialogServiceConnector instance created with this config. The contents of configuration objects are copied\n     * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the\n     * original configuration's authorization token. Create a new configuration instance or set the\n     * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create\n     * further DialogServiceConnectors.\n     * @member BotFrameworkConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param authorizationToken The authorization token associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromAuthorizationToken(authorizationToken, region, botId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, authorizationToken);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        if (botId) {\n            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, botId);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates an instance of a BotFrameworkConfig.\n     * This method is intended only for users who use a non-default service host. The standard resource path will be\n     * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken\n     * property on the created BotFrameworkConfig instance.\n     * Note: Added in version 1.15.0.\n     * @member BotFrameworkConfig.fromHost\n     * @function\n     * @public\n     * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.\n     * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in\n     * wss://{host}.convai.speech.azure.us.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n     * token must be set.\n     * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n     * resource name.\n     * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n     */\n    static fromHost(host, subscriptionKey, botId) {\n        void botId;\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(host, \"host\");\n        const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(resolvedHost, \"resolvedHost\");\n        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Host, resolvedHost.toString());\n        if (undefined !== subscriptionKey) {\n            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return botFrameworkConfig;\n    }\n    /**\n     * Creates an instance of a BotFrameworkConfig.\n     * This method is intended only for users who use a non-standard service endpoint or parameters.\n     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created BotFrameworkConfig instance to\n     * use the authorization token.\n     * Note: Added in version 1.15.0.\n     * @member BotFrameworkConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n     * token must be set.\n     * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNull(endpoint, \"endpoint\");\n        const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.BotFramework);\n        botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint, endpoint.toString());\n        if (undefined !== subscriptionKey) {\n            botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return botFrameworkConfig;\n    }\n}\n\n//# sourceMappingURL=BotFrameworkConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js ***!
  \***********************************************************************************************************/
/*! exports provided: CancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetails\", function() { return CancellationDetails; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CancellationDetailsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetails\n */\nclass CancellationDetails extends _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_1__[\"CancellationDetailsBase\"] {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of CancellationDetails object for the canceled RecognitionResult.\n     * @member CancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.\n     * @returns {CancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        let reason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error;\n        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError;\n        if (result instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"RecognitionResult\"] && !!result.json) {\n            const simpleSpeech = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SimpleSpeechPhrase\"].fromJSON(result.json);\n            reason = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EnumTranslation\"].implTranslateCancelResult(simpleSpeech.RecognitionStatus);\n        }\n        if (!!result.properties) {\n            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError])];\n        }\n        return new CancellationDetails(reason, result.errorDetails || _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EnumTranslation\"].implTranslateErrorDetails(errorCode), errorCode);\n    }\n}\n\n//# sourceMappingURL=CancellationDetails.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js ***!
  \***************************************************************************************************************/
/*! exports provided: CancellationDetailsBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetailsBase\", function() { return CancellationDetailsBase; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetailsBase\n */\nclass CancellationDetailsBase {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - The error details, if provided.\n     */\n    constructor(reason, errorDetails, errorCode) {\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationDetailsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member CancellationDetailsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get ErrorCode() {\n        return this.privErrorCode;\n    }\n}\n\n//# sourceMappingURL=CancellationDetailsBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js ***!
  \**************************************************************************************************************/
/*! exports provided: CancellationErrorCode */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationErrorCode\", function() { return CancellationErrorCode; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines error code in case that CancellationReason is Error.\n * Added in version 1.1.0.\n */\nvar CancellationErrorCode;\n(function (CancellationErrorCode) {\n    /**\n     * Indicates that no error occurred during speech recognition.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"NoError\"] = 0] = \"NoError\";\n    /**\n     * Indicates an authentication error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"AuthenticationFailure\"] = 1] = \"AuthenticationFailure\";\n    /**\n     * Indicates that one or more recognition parameters are invalid.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"BadRequestParameters\"] = 2] = \"BadRequestParameters\";\n    /**\n     * Indicates that the number of parallel requests exceeded the number of allowed\n     * concurrent transcriptions for the subscription.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"TooManyRequests\"] = 3] = \"TooManyRequests\";\n    /**\n     * Indicates a connection error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ConnectionFailure\"] = 4] = \"ConnectionFailure\";\n    /**\n     * Indicates a time-out error when waiting for response from service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceTimeout\"] = 5] = \"ServiceTimeout\";\n    /**\n     * Indicates that an error is returned by the service.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"ServiceError\"] = 6] = \"ServiceError\";\n    /**\n     * Indicates an unexpected runtime error.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"RuntimeError\"] = 7] = \"RuntimeError\";\n    /**\n     * Indicates an quota overrun on existing key.\n     */\n    CancellationErrorCode[CancellationErrorCode[\"Forbidden\"] = 8] = \"Forbidden\";\n})(CancellationErrorCode || (CancellationErrorCode = {}));\n\n//# sourceMappingURL=CancellationErrorCodes.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js ***!
  \*****************************************************************************************************************/
/*! exports provided: CancellationEventArgsBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationEventArgsBase\", function() { return CancellationEventArgsBase; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a CancellationEvent.\n * @class CancellationEventArgsBase\n */\nclass CancellationEventArgsBase extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} reason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, offset, sessionId) {\n        super(offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member CancellationEventArgsBase.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful operation.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful operation, provides details of the occurred error.\n     * @member CancellationEventArgsBase.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=CancellationEventArgsBase.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js ***!
  \**********************************************************************************************************/
/*! exports provided: CancellationReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CancellationReason\", function() { return CancellationReason; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be canceled.\n * @class CancellationReason\n */\nvar CancellationReason;\n(function (CancellationReason) {\n    /**\n     * Indicates that an error occurred during speech recognition.\n     * @member CancellationReason.Error\n     */\n    CancellationReason[CancellationReason[\"Error\"] = 0] = \"Error\";\n    /**\n     * Indicates that the end of the audio stream was reached.\n     * @member CancellationReason.EndOfStream\n     */\n    CancellationReason[CancellationReason[\"EndOfStream\"] = 1] = \"EndOfStream\";\n})(CancellationReason || (CancellationReason = {}));\n\n//# sourceMappingURL=CancellationReason.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js ***!
  \**************************************************************************************************/
/*! exports provided: Connection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Connection\", function() { return Connection; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n\n\n\n\n/**\n * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.\n * By default, a Recognizer autonomously manages connection to service when needed.\n * The Connection class provides additional methods for users to explicitly open or close a connection and\n * to subscribe to connection status changes.\n * The use of Connection is optional, and mainly for scenarios where fine tuning of application\n * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection\n * in advance before starting recognition on the Recognizer associated with this Connection.\n * If the Recognizer needs to connect or disconnect to service, it will\n * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection\n * status via Connected/Disconnected events.\n * Added in version 1.2.1.\n */\nclass Connection {\n    /**\n     * Gets the Connection instance from the specified recognizer.\n     * @param recognizer The recognizer associated with the connection.\n     * @return The Connection instance of the recognizer.\n     */\n    static fromRecognizer(recognizer) {\n        const recoBase = recognizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = recoBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Gets the Connection instance from the specified synthesizer.\n     * @param synthesizer The synthesizer associated with the connection.\n     * @return The Connection instance of the synthesizer.\n     */\n    static fromSynthesizer(synthesizer) {\n        const synthBase = synthesizer.internalData;\n        const ret = new Connection();\n        ret.privInternalData = synthBase;\n        ret.setupEvents();\n        return ret;\n    }\n    /**\n     * Starts to set up connection to the service.\n     * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the\n     * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect\n     *\n     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n     * be notified when the connection is established.\n     */\n    openConnection(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.privInternalData.connect(), cb, err);\n    }\n    /**\n     * Closes the connection the service.\n     * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.\n     *\n     * If closeConnection() is called during recognition, recognition will fail and cancel with an error.\n     */\n    closeConnection(cb, err) {\n        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisAdapterBase\"]) {\n            throw new Error(\"Disconnecting a synthesizer's connection is currently not supported\");\n        }\n        else {\n            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.privInternalData.disconnect(), cb, err);\n        }\n    }\n    /**\n     * Appends a parameter in a message to service.\n     * Added in version 1.12.1.\n     * @param path The path of the network message.\n     * @param propertyName Name of the property\n     * @param propertyValue Value of the property. This is a json string.\n     */\n    setMessageProperty(path, propertyName, propertyValue) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrWhitespace(propertyName, \"propertyName\");\n        if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServiceRecognizerBase\"]) {\n            if (path.toLowerCase() !== \"speech.context\") {\n                throw new Error(\"Only speech.context message property sets are currently supported for recognizer\");\n            }\n            else {\n                this.privInternalData.speechContext.setSection(propertyName, propertyValue);\n            }\n        }\n        else if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisAdapterBase\"]) {\n            if (path.toLowerCase() !== \"synthesis.context\") {\n                throw new Error(\"Only synthesis.context message property sets are currently supported for synthesizer\");\n            }\n            else {\n                this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);\n            }\n        }\n    }\n    /**\n     * Sends a message to the speech service.\n     * Added in version 1.13.0.\n     * @param path The WebSocket path of the message\n     * @param payload The payload of the message. This is a json string or a ArrayBuffer.\n     * @param success A callback to indicate success.\n     * @param error A callback to indicate an error.\n     */\n    sendMessageAsync(path, payload, success, error) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.privInternalData.sendNetworkMessage(path, payload), success, error);\n    }\n    /**\n     * Dispose of associated resources.\n     */\n    close() {\n        /* eslint-disable no-empty */\n    }\n    setupEvents() {\n        this.privEventListener = this.privInternalData.connectionEvents.attach((connectionEvent) => {\n            if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n                if (!!this.connected) {\n                    this.connected(new _Exports__WEBPACK_IMPORTED_MODULE_4__[\"ConnectionEventArgs\"](connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n                if (!!this.disconnected) {\n                    this.disconnected(new _Exports__WEBPACK_IMPORTED_MODULE_4__[\"ConnectionEventArgs\"](connectionEvent.connectionId));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageSentEvent\") {\n                if (!!this.messageSent) {\n                    this.messageSent(new _Exports__WEBPACK_IMPORTED_MODULE_4__[\"ConnectionMessageEventArgs\"](new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageImpl\"](connectionEvent.message)));\n                }\n            }\n            else if (connectionEvent.name === \"ConnectionMessageReceivedEvent\") {\n                if (!!this.messageReceived) {\n                    this.messageReceived(new _Exports__WEBPACK_IMPORTED_MODULE_4__[\"ConnectionMessageEventArgs\"](new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_2__[\"ConnectionMessageImpl\"](connectionEvent.message)));\n                }\n            }\n        });\n        this.privServiceEventListener = this.privInternalData.serviceEvents.attach((e) => {\n            if (!!this.receivedServiceMessage) {\n                this.receivedServiceMessage(new _Exports__WEBPACK_IMPORTED_MODULE_4__[\"ServiceEventArgs\"](e.jsonString, e.name));\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=Connection.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js ***!
  \***********************************************************************************************************/
/*! exports provided: ConnectionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEventArgs\", function() { return ConnectionEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for connection events like Connected/Disconnected.\n * Added in version 1.2.0\n */\nclass ConnectionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n}\n\n//# sourceMappingURL=ConnectionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js ***!
  \*********************************************************************************************************/
/*! exports provided: ConnectionMessage, ConnectionMessageImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessage\", function() { return ConnectionMessage; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageImpl\", function() { return ConnectionMessageImpl; });\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./PropertyCollection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n/**\n * ConnectionMessage represents implementation specific messages sent to and received from\n * the speech service. These messages are provided for debugging purposes and should not\n * be used for production use cases with the Azure Cognitive Services Speech Service.\n * Messages sent to and received from the Speech Service are subject to change without\n * notice. This includes message contents, headers, payloads, ordering, etc.\n * Added in version 1.11.0.\n */\nclass ConnectionMessage {\n}\nclass ConnectionMessageImpl {\n    constructor(message) {\n        this.privConnectionMessage = message;\n        this.privProperties = new _PropertyCollection__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        if (!!this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__[\"HeaderNames\"].ConnectionId]) {\n            this.privProperties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].Speech_SessionId, this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_0__[\"HeaderNames\"].ConnectionId]);\n        }\n        Object.keys(this.privConnectionMessage.headers).forEach((header) => {\n            this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);\n        });\n    }\n    /**\n     * The message path.\n     */\n    get path() {\n        return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find((key) => key.toLowerCase() === \"path\".toLowerCase())];\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a text message.\n     * See also IsBinaryMessage().\n     */\n    get isTextMessage() {\n        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Text;\n    }\n    /**\n     * Checks to see if the ConnectionMessage is a binary message.\n     * See also GetBinaryMessage().\n     */\n    get isBinaryMessage() {\n        return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"MessageType\"].Binary;\n    }\n    /**\n     * Gets the text message payload. Typically the text message content-type is\n     * application/json. To determine other content-types use\n     * Properties.GetProperty(\"Content-Type\").\n     */\n    get TextMessage() {\n        return this.privConnectionMessage.textBody;\n    }\n    /**\n     * Gets the binary message payload.\n     */\n    get binaryMessage() {\n        return this.privConnectionMessage.binaryBody;\n    }\n    /**\n     * A collection of properties and their values defined for this <see cref=\"ConnectionMessage\"/>.\n     * Message headers can be accessed via this collection (e.g. \"Content-Type\").\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Returns a string that represents the connection message.\n     */\n    toString() {\n        return \"\";\n    }\n}\n\n//# sourceMappingURL=ConnectionMessage.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: ConnectionMessageEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageEventArgs\", function() { return ConnectionMessageEventArgs; });\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nclass ConnectionMessageEventArgs {\n    constructor(message) {\n        this.privConnectionMessage = message;\n    }\n    /**\n     * Gets the <see cref=\"ConnectionMessage\"/> associated with this <see cref=\"ConnectionMessageEventArgs\"/>.\n     */\n    get message() {\n        return this.privConnectionMessage;\n    }\n    /**\n     * Returns a string that represents the connection message event.\n     */\n    toString() {\n        return \"Message: \" + this.privConnectionMessage.toString();\n    }\n}\n\n//# sourceMappingURL=ConnectionMessageEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js ***!
  \*************************************************************************************************/
/*! exports provided: Contracts */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Contracts\", function() { return Contracts; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class Contracts\n * @private\n */\nclass Contracts {\n    static throwIfNullOrUndefined(param, name) {\n        if (param === undefined || param === null) {\n            throw new Error(\"throwIfNullOrUndefined:\" + name);\n        }\n    }\n    static throwIfNull(param, name) {\n        if (param === null) {\n            throw new Error(\"throwIfNull:\" + name);\n        }\n    }\n    static throwIfNullOrWhitespace(param, name) {\n        Contracts.throwIfNullOrUndefined(param, name);\n        if ((\"\" + param).trim().length < 1) {\n            throw new Error(\"throwIfNullOrWhitespace:\" + name);\n        }\n    }\n    static throwIfDisposed(isDisposed) {\n        if (isDisposed) {\n            throw new Error(\"the object is already disposed\");\n        }\n    }\n    static throwIfArrayEmptyOrWhitespace(array, name) {\n        Contracts.throwIfNullOrUndefined(array, name);\n        if (array.length === 0) {\n            throw new Error(\"throwIfArrayEmptyOrWhitespace:\" + name);\n        }\n        for (const item of array) {\n            Contracts.throwIfNullOrWhitespace(item, name);\n        }\n    }\n    static throwIfFileDoesNotExist(param, name) {\n        Contracts.throwIfNullOrWhitespace(param, name);\n        // TODO check for file existence.\n    }\n    static throwIfNotUndefined(param, name) {\n        if (param !== undefined) {\n            throw new Error(\"throwIfNotUndefined:\" + name);\n        }\n    }\n}\n\n//# sourceMappingURL=Contracts.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \**********************************************************************************************************************************/
/*! exports provided: ConversationTranscriptionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionCanceledEventArgs\", function() { return ConversationTranscriptionCanceledEventArgs; });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a RecognitionErrorEvent.\n * @class ConversationTranscriptionCanceledEventArgs\n */\nclass ConversationTranscriptionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__[\"CancellationEventArgsBase\"] {\n}\n\n//# sourceMappingURL=ConversationTranscriptionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js ***!
  \************************************************************************************************************/
/*! exports provided: CustomCommandsConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CustomCommandsConfig\", function() { return CustomCommandsConfig; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.\n * @class CustomCommandsConfig\n */\nclass CustomCommandsConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"] {\n    /**\n     * Creates an instance of CustomCommandsConfig.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Creates an instance of the bot framework config with the specified subscription and region.\n     * @member CustomCommandsConfig.fromSubscription\n     * @function\n     * @public\n     * @param applicationId Speech Commands application id.\n     * @param subscription Subscription key associated with the bot\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {CustomCommandsConfig} A new bot framework config.\n     */\n    static fromSubscription(applicationId, subscription, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(applicationId, \"applicationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(subscription, \"subscription\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.CustomCommands);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, applicationId);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscription);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        return customCommandsConfig;\n    }\n    /**\n     * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by calling this setter with a new valid token.\n     * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.\n     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member CustomCommandsConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param applicationId Speech Commands application id.\n     * @param authorizationToken The authorization token associated with the application.\n     * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {CustomCommandsConfig} A new speech commands config.\n     */\n    static fromAuthorizationToken(applicationId, authorizationToken, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(applicationId, \"applicationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfigImpl\"]();\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceConfig\"].DialogTypes.CustomCommands);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, applicationId);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, authorizationToken);\n        customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        return customCommandsConfig;\n    }\n    /**\n     * Sets the corresponding backend application identifier.\n     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to set.\n     */\n    set applicationId(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId, value);\n    }\n    /**\n     * Gets the corresponding backend application identifier.\n     * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to get.\n     */\n    get applicationId() {\n        return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].Conversation_ApplicationId);\n    }\n}\n\n//# sourceMappingURL=CustomCommandsConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js ***!
  \***************************************************************************************************/
/*! exports provided: Diagnostics */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Diagnostics\", function() { return Diagnostics; });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n\n/**\n * Defines diagnostics API for managing console output\n * Added in version 1.21.0\n */\nclass Diagnostics {\n    static SetLoggingLevel(logLevel) {\n        this.privListener = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConsoleLoggingListener\"](logLevel);\n        _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Events\"].instance.attachConsoleListener(this.privListener);\n    }\n    static SetLogOutputPath(path) {\n        if (typeof window === \"undefined\") {\n            if (!!this.privListener) {\n                this.privListener.logPath = path;\n            }\n        }\n        else {\n            throw new Error(\"File system logging not available in browser.\");\n        }\n    }\n}\nDiagnostics.privListener = undefined;\n\n//# sourceMappingURL=Diagnostics.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js ***!
  \***********************************************************************************************************/
/*! exports provided: DialogServiceConfig, DialogServiceConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConfig\", function() { return DialogServiceConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConfigImpl\", function() { return DialogServiceConfigImpl; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n/**\n * Class that defines base configurations for dialog service connector\n * @class DialogServiceConfig\n */\nclass DialogServiceConfig {\n    /**\n     * Creates an instance of DialogService config.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Sets the corresponding backend application identifier.\n     * @member DialogServiceConfig.prototype.Conversation_ApplicationId\n     * @function\n     * @public\n     * @param {string} value - The application identifier to set.\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    set applicationId(value) { }\n    static get DialogTypes() {\n        return {\n            BotFramework: \"bot_framework\",\n            CustomCommands: \"custom_commands\"\n        };\n    }\n}\n/**\n * Dialog Service configuration.\n * @class DialogServiceConfigImpl\n */\nclass DialogServiceConfigImpl extends DialogServiceConfig {\n    /**\n     * Creates an instance of dialogService config.\n     */\n    constructor() {\n        super();\n        this.privSpeechConfig = new _Exports__WEBPACK_IMPORTED_MODULE_1__[\"SpeechConfigImpl\"]();\n    }\n    /**\n     * Provides access to custom properties.\n     * @member DialogServiceConfigImpl.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The properties.\n     */\n    get properties() {\n        return this.privSpeechConfig.properties;\n    }\n    /**\n     * Gets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechConfig.speechRecognitionLanguage;\n    }\n    /**\n     * Sets the speech recognition language.\n     * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @param {string} value - The language to set.\n     */\n    set speechRecognitionLanguage(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechConfig.speechRecognitionLanguage = value;\n    }\n    get outputFormat() {\n        return this.privSpeechConfig.outputFormat;\n    }\n    set outputFormat(value) {\n        this.privSpeechConfig.outputFormat = value;\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.setProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to set.\n     * @param {string} value - The value.\n     */\n    setProperty(name, value) {\n        this.privSpeechConfig.setProperty(name, value);\n    }\n    /**\n     * Sets a named property as value\n     * @member DialogServiceConfigImpl.prototype.getProperty\n     * @function\n     * @public\n     * @param {PropertyId | string} name - The property to get.\n     * @param {string} def - The default value to return in case the property is not known.\n     * @returns {string} The current value, or provided default, of the given property.\n     */\n    getProperty(name, def) {\n        void def;\n        return this.privSpeechConfig.getProperty(name);\n    }\n    /**\n     * Sets the proxy configuration.\n     * Only relevant in Node.js environments.\n     * Added in version 1.4.0.\n     * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)\n     * @param proxyPort The port number of the proxy server.\n     * @param proxyUserName The user name of the proxy server.\n     * @param proxyPassword The password of the proxy server.\n     */\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_ProxyHostName, proxyHostName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_ProxyPort, `${proxyPort}`);\n        if (proxyUserName) {\n            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_ProxyUserName, proxyUserName);\n        }\n        if (proxyPassword) {\n            this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceConnection_ProxyPassword, proxyPassword);\n        }\n    }\n    setServiceProperty(name, value, channel) {\n        void channel;\n        this.privSpeechConfig.setServiceProperty(name, value);\n    }\n    /**\n     * Dispose of associated resources.\n     * @member DialogServiceConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n}\n\n//# sourceMappingURL=DialogServiceConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js ***!
  \**************************************************************************************************************/
/*! exports provided: DialogServiceConnector */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConnector\", function() { return DialogServiceConnector; });\n/* harmony import */ var _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/DialogConnectorFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n/**\n * Dialog Service Connector\n * @class DialogServiceConnector\n */\nclass DialogServiceConnector extends _Exports__WEBPACK_IMPORTED_MODULE_4__[\"Recognizer\"] {\n    /**\n     * Initializes an instance of the DialogServiceConnector.\n     * @constructor\n     * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.\n     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n     */\n    constructor(dialogConfig, audioConfig) {\n        const dialogServiceConfigImpl = dialogConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNull(dialogConfig, \"dialogConfig\");\n        super(audioConfig, dialogServiceConfigImpl.properties, new _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_0__[\"DialogConnectionFactory\"]());\n        this.isTurnComplete = true;\n        this.privIsDisposed = false;\n        this.privProperties = dialogServiceConfigImpl.properties.clone();\n        const agentConfig = this.buildAgentConfig();\n        this.privReco.agentConfig.set(agentConfig);\n    }\n    /**\n     * Starts a connection to the service.\n     * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.\n     *\n     * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n     * be notified when the connection is established.\n     * @member DialogServiceConnector.prototype.connect\n     * @function\n     * @public\n     */\n    connect(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"marshalPromiseToCallbacks\"])(this.privReco.connect(), cb, err);\n    }\n    /**\n     * Closes the connection the service.\n     * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.\n     *\n     * If disconnect() is called during a recognition, recognition will fail and cancel with an error.\n     */\n    disconnect(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"marshalPromiseToCallbacks\"])(this.privReco.disconnect(), cb, err);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member DialogServiceConnector.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Sets the authorization token used to communicate with the service.\n     * @member DialogServiceConnector.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this DialogServiceConnector.\n     * @member DialogServiceConnector.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /** Gets the template for the activity generated by service from speech.\n     * Properties from the template will be stamped on the generated activity.\n     * It can be empty\n     */\n    get speechActivityTemplate() {\n        return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].Conversation_Speech_Activity_Template);\n    }\n    /** Sets the template for the activity generated by service from speech.\n     * Properties from the template will be stamped on the generated activity.\n     * It can be null or empty.\n     * Note: it has to be a valid Json object.\n     */\n    set speechActivityTemplate(speechActivityTemplate) {\n        this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].Conversation_Speech_Activity_Template, speechActivityTemplate);\n    }\n    /**\n     * Starts recognition and stops after the first utterance is recognized.\n     * @member DialogServiceConnector.prototype.listenOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the result when the reco has completed.\n     * @param err - Callback invoked in case of an error.\n     */\n    listenOnceAsync(cb, err) {\n        if (this.isTurnComplete) {\n            _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            const callbackHolder = () => __awaiter(this, void 0, void 0, function* () {\n                yield this.privReco.connect();\n                yield this.implRecognizerStop();\n                this.isTurnComplete = false;\n                const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"Deferred\"]();\n                yield this.privReco.recognize(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognitionMode\"].Conversation, ret.resolve, ret.reject);\n                const e = yield ret.promise;\n                yield this.implRecognizerStop();\n                return e;\n            });\n            const retPromise = callbackHolder();\n            retPromise.catch(() => {\n                // Destroy the recognizer.\n                // We've done all we can here.\n                // eslint-disable-next-line @typescript-eslint/no-empty-function\n                this.dispose(true).catch(() => { });\n            });\n            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"marshalPromiseToCallbacks\"])(retPromise.finally(() => {\n                this.isTurnComplete = true;\n            }), cb, err);\n        }\n    }\n    sendActivityAsync(activity, cb, errCb) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"marshalPromiseToCallbacks\"])(this.privReco.sendMessage(activity), cb, errCb);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member DialogServiceConnector.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_2__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, err);\n    }\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privIsDisposed) {\n                return;\n            }\n            if (disposing) {\n                this.privIsDisposed = true;\n                yield this.implRecognizerStop();\n                yield _super.dispose.call(this, disposing);\n            }\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"RecognizerConfig\"](speechConfig, this.privProperties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioSource = audioConfig;\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__[\"DialogServiceAdapter\"](authentication, connectionFactory, audioSource, recognizerConfig, this);\n    }\n    buildAgentConfig() {\n        const communicationType = this.properties.getProperty(\"Conversation_Communication_Type\", \"Default\");\n        return {\n            botInfo: {\n                commType: communicationType,\n                commandsCulture: undefined,\n                connectionId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].Conversation_Agent_Connection_Id),\n                conversationId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].Conversation_Conversation_Id, undefined),\n                fromId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].Conversation_From_Id, undefined),\n                ttsAudioFormat: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_5__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, undefined)\n            },\n            version: 0.2\n        };\n    }\n}\n\n//# sourceMappingURL=DialogServiceConnector.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js ***!
  \***********************************************************************************************/
/*! exports provided: AudioConfig, AudioStreamFormat, AudioFormatTag, AudioInputStream, PullAudioInputStream, PushAudioInputStream, AudioOutputStream, PullAudioOutputStream, PushAudioOutputStream, CancellationReason, PullAudioInputStreamCallback, PushAudioOutputStreamCallback, KeywordRecognitionModel, SessionEventArgs, RecognitionEventArgs, OutputFormat, IntentRecognitionEventArgs, RecognitionResult, SpeechRecognitionResult, IntentRecognitionResult, LanguageUnderstandingModel, SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs, SpeechRecognitionCanceledEventArgs, TranslationRecognitionEventArgs, TranslationSynthesisEventArgs, TranslationRecognitionResult, TranslationSynthesisResult, ResultReason, SpeechConfig, SpeechConfigImpl, SpeechTranslationConfig, SpeechTranslationConfigImpl, PropertyCollection, PropertyId, Recognizer, SpeechRecognizer, IntentRecognizer, VoiceProfileType, TranslationRecognizer, Translations, NoMatchReason, NoMatchDetails, TranslationRecognitionCanceledEventArgs, IntentRecognitionCanceledEventArgs, CancellationDetailsBase, CancellationDetails, CancellationErrorCode, ConnectionEventArgs, ServiceEventArgs, Connection, PhraseListGrammar, DialogServiceConfig, BotFrameworkConfig, CustomCommandsConfig, DialogServiceConnector, ActivityReceivedEventArgs, TurnStatusReceivedEventArgs, ServicePropertyChannel, ProfanityOption, BaseAudioPlayer, ConnectionMessageEventArgs, ConnectionMessage, VoiceProfile, VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails, VoiceProfileResult, VoiceProfileCancellationDetails, VoiceProfilePhraseResult, VoiceProfileClient, SpeakerRecognizer, SpeakerIdentificationModel, SpeakerVerificationModel, AutoDetectSourceLanguageConfig, AutoDetectSourceLanguageResult, SourceLanguageConfig, SpeakerRecognitionResult, SpeakerRecognitionResultType, SpeakerRecognitionCancellationDetails, Conversation, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, ParticipantChangedReason, User, SpeechSynthesisOutputFormat, SpeechSynthesizer, SynthesisResult, SpeechSynthesisResult, SpeechSynthesisEventArgs, SpeechSynthesisWordBoundaryEventArgs, SpeechSynthesisBookmarkEventArgs, SpeechSynthesisVisemeEventArgs, SpeechSynthesisBoundaryType, SynthesisVoicesResult, VoiceInfo, SpeakerAudioDestination, ConversationTranscriptionCanceledEventArgs, PronunciationAssessmentGradingSystem, PronunciationAssessmentGranularity, PronunciationAssessmentConfig, PronunciationAssessmentResult, LanguageIdMode, LanguageIdPriority, Diagnostics, LogLevel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Audio/AudioConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioConfig\", function() { return _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__[\"AudioConfig\"]; });\n\n/* harmony import */ var _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioStreamFormat\", function() { return _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioStreamFormat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioFormatTag\", function() { return _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__[\"AudioFormatTag\"]; });\n\n/* harmony import */ var _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioInputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioInputStream\", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__[\"AudioInputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStream\", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__[\"PullAudioInputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioInputStream\", function() { return _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__[\"PushAudioInputStream\"]; });\n\n/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AudioOutputStream\", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__[\"AudioOutputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioOutputStream\", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__[\"PullAudioOutputStream\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStream\", function() { return _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__[\"PushAudioOutputStream\"]; });\n\n/* harmony import */ var _CancellationReason__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./CancellationReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationReason\", function() { return _CancellationReason__WEBPACK_IMPORTED_MODULE_4__[\"CancellationReason\"]; });\n\n/* harmony import */ var _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PullAudioInputStreamCallback\", function() { return _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__[\"PullAudioInputStreamCallback\"]; });\n\n/* harmony import */ var _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PushAudioOutputStreamCallback\", function() { return _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__[\"PushAudioOutputStreamCallback\"]; });\n\n/* harmony import */ var _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./KeywordRecognitionModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"KeywordRecognitionModel\", function() { return _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__[\"KeywordRecognitionModel\"]; });\n\n/* harmony import */ var _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SessionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SessionEventArgs\", function() { return _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__[\"SessionEventArgs\"]; });\n\n/* harmony import */ var _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionEventArgs\", function() { return _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__[\"RecognitionEventArgs\"]; });\n\n/* harmony import */ var _OutputFormat__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./OutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"OutputFormat\", function() { return _OutputFormat__WEBPACK_IMPORTED_MODULE_10__[\"OutputFormat\"]; });\n\n/* harmony import */ var _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IntentRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionEventArgs\", function() { return _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__[\"IntentRecognitionEventArgs\"]; });\n\n/* harmony import */ var _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./RecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RecognitionResult\", function() { return _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__[\"RecognitionResult\"]; });\n\n/* harmony import */ var _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionResult\", function() { return _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__[\"SpeechRecognitionResult\"]; });\n\n/* harmony import */ var _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IntentRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionResult\", function() { return _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__[\"IntentRecognitionResult\"]; });\n\n/* harmony import */ var _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./LanguageUnderstandingModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageUnderstandingModel\", function() { return _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__[\"LanguageUnderstandingModel\"]; });\n\n/* harmony import */ var _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./SpeechRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionEventArgs\", function() { return _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__[\"SpeechRecognitionEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionEventArgs\", function() { return _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__[\"ConversationTranscriptionEventArgs\"]; });\n\n/* harmony import */ var _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionCanceledEventArgs\", function() { return _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__[\"SpeechRecognitionCanceledEventArgs\"]; });\n\n/* harmony import */ var _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./TranslationRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionEventArgs\", function() { return _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__[\"TranslationRecognitionEventArgs\"]; });\n\n/* harmony import */ var _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./TranslationSynthesisEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisEventArgs\", function() { return _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__[\"TranslationSynthesisEventArgs\"]; });\n\n/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionResult\", function() { return _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__[\"TranslationRecognitionResult\"]; });\n\n/* harmony import */ var _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./TranslationSynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisResult\", function() { return _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__[\"TranslationSynthesisResult\"]; });\n\n/* harmony import */ var _ResultReason__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ResultReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ResultReason\", function() { return _ResultReason__WEBPACK_IMPORTED_MODULE_22__[\"ResultReason\"]; });\n\n/* harmony import */ var _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./SpeechConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfig\", function() { return _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__[\"SpeechConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfigImpl\", function() { return _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__[\"SpeechConfigImpl\"]; });\n\n/* harmony import */ var _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechTranslationConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfig\", function() { return _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__[\"SpeechTranslationConfig\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfigImpl\", function() { return _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__[\"SpeechTranslationConfigImpl\"]; });\n\n/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./PropertyCollection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PropertyCollection\", function() { return _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__[\"PropertyCollection\"]; });\n\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PropertyId\", function() { return _PropertyId__WEBPACK_IMPORTED_MODULE_26__[\"PropertyId\"]; });\n\n/* harmony import */ var _Recognizer__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./Recognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Recognizer\", function() { return _Recognizer__WEBPACK_IMPORTED_MODULE_27__[\"Recognizer\"]; });\n\n/* harmony import */ var _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./SpeechRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognizer\", function() { return _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__[\"SpeechRecognizer\"]; });\n\n/* harmony import */ var _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognizer\", function() { return _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__[\"IntentRecognizer\"]; });\n\n/* harmony import */ var _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./VoiceProfileType */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileType\", function() { return _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__[\"VoiceProfileType\"]; });\n\n/* harmony import */ var _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./TranslationRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognizer\", function() { return _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__[\"TranslationRecognizer\"]; });\n\n/* harmony import */ var _Translations__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./Translations */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Translations\", function() { return _Translations__WEBPACK_IMPORTED_MODULE_32__[\"Translations\"]; });\n\n/* harmony import */ var _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./NoMatchReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NoMatchReason\", function() { return _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__[\"NoMatchReason\"]; });\n\n/* harmony import */ var _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./NoMatchDetails */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NoMatchDetails\", function() { return _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__[\"NoMatchDetails\"]; });\n\n/* harmony import */ var _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionCanceledEventArgs\", function() { return _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__[\"TranslationRecognitionCanceledEventArgs\"]; });\n\n/* harmony import */ var _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./IntentRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionCanceledEventArgs\", function() { return _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__[\"IntentRecognitionCanceledEventArgs\"]; });\n\n/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./CancellationDetailsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetailsBase\", function() { return _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__[\"CancellationDetailsBase\"]; });\n\n/* harmony import */ var _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./CancellationDetails */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationDetails\", function() { return _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__[\"CancellationDetails\"]; });\n\n/* harmony import */ var _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./CancellationErrorCodes */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CancellationErrorCode\", function() { return _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__[\"CancellationErrorCode\"]; });\n\n/* harmony import */ var _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./ConnectionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionEventArgs\", function() { return _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__[\"ConnectionEventArgs\"]; });\n\n/* harmony import */ var _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./ServiceEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServiceEventArgs\", function() { return _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__[\"ServiceEventArgs\"]; });\n\n/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./Connection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Connection\", function() { return _Connection__WEBPACK_IMPORTED_MODULE_42__[\"Connection\"]; });\n\n/* harmony import */ var _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./PhraseListGrammar */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PhraseListGrammar\", function() { return _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__[\"PhraseListGrammar\"]; });\n\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConfig\", function() { return _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__[\"DialogServiceConfig\"]; });\n\n/* harmony import */ var _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./BotFrameworkConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BotFrameworkConfig\", function() { return _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__[\"BotFrameworkConfig\"]; });\n\n/* harmony import */ var _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./CustomCommandsConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CustomCommandsConfig\", function() { return _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__[\"CustomCommandsConfig\"]; });\n\n/* harmony import */ var _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./DialogServiceConnector */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DialogServiceConnector\", function() { return _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__[\"DialogServiceConnector\"]; });\n\n/* harmony import */ var _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./ActivityReceivedEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ActivityReceivedEventArgs\", function() { return _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__[\"ActivityReceivedEventArgs\"]; });\n\n/* harmony import */ var _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./TurnStatusReceivedEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TurnStatusReceivedEventArgs\", function() { return _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__[\"TurnStatusReceivedEventArgs\"]; });\n\n/* harmony import */ var _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./ServicePropertyChannel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ServicePropertyChannel\", function() { return _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__[\"ServicePropertyChannel\"]; });\n\n/* harmony import */ var _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./ProfanityOption */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ProfanityOption\", function() { return _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__[\"ProfanityOption\"]; });\n\n/* harmony import */ var _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./Audio/BaseAudioPlayer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BaseAudioPlayer\", function() { return _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__[\"BaseAudioPlayer\"]; });\n\n/* harmony import */ var _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./ConnectionMessageEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessageEventArgs\", function() { return _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__[\"ConnectionMessageEventArgs\"]; });\n\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConnectionMessage\", function() { return _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__[\"ConnectionMessage\"]; });\n\n/* harmony import */ var _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./VoiceProfile */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfile\", function() { return _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__[\"VoiceProfile\"]; });\n\n/* harmony import */ var _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./VoiceProfileEnrollmentResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentResult\", function() { return _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__[\"VoiceProfileEnrollmentResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentCancellationDetails\", function() { return _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__[\"VoiceProfileEnrollmentCancellationDetails\"]; });\n\n/* harmony import */ var _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./VoiceProfileResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileResult\", function() { return _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__[\"VoiceProfileResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileCancellationDetails\", function() { return _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__[\"VoiceProfileCancellationDetails\"]; });\n\n/* harmony import */ var _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./VoiceProfilePhraseResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfilePhraseResult\", function() { return _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__[\"VoiceProfilePhraseResult\"]; });\n\n/* harmony import */ var _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./VoiceProfileClient */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileClient\", function() { return _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__[\"VoiceProfileClient\"]; });\n\n/* harmony import */ var _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./SpeakerRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognizer\", function() { return _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__[\"SpeakerRecognizer\"]; });\n\n/* harmony import */ var _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./SpeakerIdentificationModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerIdentificationModel\", function() { return _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__[\"SpeakerIdentificationModel\"]; });\n\n/* harmony import */ var _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./SpeakerVerificationModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerVerificationModel\", function() { return _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__[\"SpeakerVerificationModel\"]; });\n\n/* harmony import */ var _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageConfig\", function() { return _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__[\"AutoDetectSourceLanguageConfig\"]; });\n\n/* harmony import */ var _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./AutoDetectSourceLanguageResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AutoDetectSourceLanguageResult\", function() { return _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__[\"AutoDetectSourceLanguageResult\"]; });\n\n/* harmony import */ var _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./SourceLanguageConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SourceLanguageConfig\", function() { return _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__[\"SourceLanguageConfig\"]; });\n\n/* harmony import */ var _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./SpeakerRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResult\", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__[\"SpeakerRecognitionResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResultType\", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__[\"SpeakerRecognitionResultType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionCancellationDetails\", function() { return _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__[\"SpeakerRecognitionCancellationDetails\"]; });\n\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Conversation\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"Conversation\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationExpirationEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationExpirationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationParticipantsChangedEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationParticipantsChangedEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationCanceledEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationTranslationCanceledEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationEventArgs\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationTranslationEventArgs\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationResult\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationTranslationResult\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslator\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationTranslator\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriber\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ConversationTranscriber\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Participant\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"Participant\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantChangedReason\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"ParticipantChangedReason\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"User\", function() { return _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__[\"User\"]; });\n\n/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./SpeechSynthesisOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisOutputFormat\", function() { return _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_68__[\"SpeechSynthesisOutputFormat\"]; });\n\n/* harmony import */ var _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./SpeechSynthesizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesizer\", function() { return _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_69__[\"SpeechSynthesizer\"]; });\n\n/* harmony import */ var _SynthesisResult__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./SynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisResult\", function() { return _SynthesisResult__WEBPACK_IMPORTED_MODULE_70__[\"SynthesisResult\"]; });\n\n/* harmony import */ var _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./SpeechSynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisResult\", function() { return _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_71__[\"SpeechSynthesisResult\"]; });\n\n/* harmony import */ var _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./SpeechSynthesisEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisEventArgs\", function() { return _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_72__[\"SpeechSynthesisEventArgs\"]; });\n\n/* harmony import */ var _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisWordBoundaryEventArgs\", function() { return _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_73__[\"SpeechSynthesisWordBoundaryEventArgs\"]; });\n\n/* harmony import */ var _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBookmarkEventArgs\", function() { return _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_74__[\"SpeechSynthesisBookmarkEventArgs\"]; });\n\n/* harmony import */ var _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisVisemeEventArgs\", function() { return _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_75__[\"SpeechSynthesisVisemeEventArgs\"]; });\n\n/* harmony import */ var _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./SpeechSynthesisBoundaryType */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBoundaryType\", function() { return _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_76__[\"SpeechSynthesisBoundaryType\"]; });\n\n/* harmony import */ var _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./SynthesisVoicesResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SynthesisVoicesResult\", function() { return _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_77__[\"SynthesisVoicesResult\"]; });\n\n/* harmony import */ var _VoiceInfo__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./VoiceInfo */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"VoiceInfo\", function() { return _VoiceInfo__WEBPACK_IMPORTED_MODULE_78__[\"VoiceInfo\"]; });\n\n/* harmony import */ var _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./Audio/SpeakerAudioDestination */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SpeakerAudioDestination\", function() { return _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_79__[\"SpeakerAudioDestination\"]; });\n\n/* harmony import */ var _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionCanceledEventArgs\", function() { return _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_80__[\"ConversationTranscriptionCanceledEventArgs\"]; });\n\n/* harmony import */ var _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGradingSystem\", function() { return _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_81__[\"PronunciationAssessmentGradingSystem\"]; });\n\n/* harmony import */ var _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./PronunciationAssessmentGranularity */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGranularity\", function() { return _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_82__[\"PronunciationAssessmentGranularity\"]; });\n\n/* harmony import */ var _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./PronunciationAssessmentConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentConfig\", function() { return _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_83__[\"PronunciationAssessmentConfig\"]; });\n\n/* harmony import */ var _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./PronunciationAssessmentResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentResult\", function() { return _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_84__[\"PronunciationAssessmentResult\"]; });\n\n/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./LanguageIdMode */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdMode\", function() { return _LanguageIdMode__WEBPACK_IMPORTED_MODULE_85__[\"LanguageIdMode\"]; });\n\n/* harmony import */ var _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./LanguageIdPriority */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdPriority\", function() { return _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_86__[\"LanguageIdPriority\"]; });\n\n/* harmony import */ var _Diagnostics__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./Diagnostics */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Diagnostics\", function() { return _Diagnostics__WEBPACK_IMPORTED_MODULE_87__[\"Diagnostics\"]; });\n\n/* harmony import */ var _LogLevel__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./LogLevel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LogLevel.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LogLevel\", function() { return _LogLevel__WEBPACK_IMPORTED_MODULE_88__[\"LogLevel\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/*! exports provided: IntentRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionCanceledEventArgs\", function() { return IntentRecognitionCanceledEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Define payload of intent recognition canceled result events.\n * @class IntentRecognitionCanceledEventArgs\n */\nclass IntentRecognitionCanceledEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"IntentRecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {CancellationReason} result - The result of the intent recognition.\n     * @param {string} offset - The offset.\n     * @param {IntentRecognitionResult} sessionId - The session id.\n     */\n    constructor(reason, errorDetails, errorCode, result, offset, sessionId) {\n        super(result, offset, sessionId);\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member IntentRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: IntentRecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionEventArgs\", function() { return IntentRecognitionEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result event arguments.\n * @class\n */\nclass IntentRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param result - The result of the intent recognition.\n     * @param offset - The offset.\n     * @param sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Represents the intent recognition result.\n     * @member IntentRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {IntentRecognitionResult} Represents the intent recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js ***!
  \***************************************************************************************************************/
/*! exports provided: IntentRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognitionResult\", function() { return IntentRecognitionResult; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result.\n * @class\n */\nclass IntentRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param intentId - The intent id.\n     * @param resultId - The result id.\n     * @param reason - The reason.\n     * @param text - The recognized text.\n     * @param duration - The duration.\n     * @param offset - The offset into the stream.\n     * @param language - Primary Language detected, if provided.\n     * @param languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param errorDetails - Error details, if provided.\n     * @param json - Additional Json, if provided.\n     * @param properties - Additional properties, if provided.\n     */\n    constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);\n        this.privIntentId = intentId;\n    }\n    /**\n     * A String that represents the intent identifier being recognized.\n     * @member IntentRecognitionResult.prototype.intentId\n     * @function\n     * @public\n     * @returns {string} A String that represents the intent identifier being recognized.\n     */\n    get intentId() {\n        return this.privIntentId;\n    }\n}\n\n//# sourceMappingURL=IntentRecognitionResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js ***!
  \********************************************************************************************************/
/*! exports provided: IntentRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IntentRecognizer\", function() { return IntentRecognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n/**\n * Intent recognizer.\n * @class\n */\nclass IntentRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__[\"Recognizer\"] {\n    /**\n     * Initializes an instance of the IntentRecognizer.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - The set of configuration properties.\n     * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(speechConfig, \"speechConfig\");\n        const configImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(configImpl, \"speechConfig\");\n        super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"IntentConnectionFactory\"]());\n        this.privAddedIntents = [];\n        this.privAddedLmIntents = {};\n        this.privDisposedIntentRecognizer = false;\n        this.privProperties = configImpl.properties;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member IntentRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} the spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedIntentRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member IntentRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.\n     * @member IntentRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - Authorization token.\n     */\n    set authorizationToken(value) {\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * The collection of properties and their values defined for this IntentRecognizer.\n     * @member IntentRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their\n     * values defined for this IntentRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts intent recognition, and stops after the first utterance is recognized.\n     * The task returns the recognition text and intent as result.\n     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n     * so it is suitable only for single shot recognition like command or query.\n     * For long-running recognition, use StartContinuousRecognitionAsync() instead.\n     * @member IntentRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedIntentRecognizer);\n        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n            const context = this.buildSpeechContext();\n            this.privReco.speechContext.setSection(\"intent\", context.Intent);\n            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n            const intentReco = this.privReco;\n            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n        }\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Interactive), cb, err);\n    }\n    /**\n     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * @member IntentRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n            const context = this.buildSpeechContext();\n            this.privReco.speechContext.setSection(\"intent\", context.Intent);\n            this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n            const intentReco = this.privReco;\n            intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n        }\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Conversation), cb, err);\n    }\n    /**\n     * Stops continuous intent recognition.\n     * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n     * This functionality is currently not included in the SDK itself.\n     * @member IntentRecognizer.prototype.startKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startKeywordRecognitionAsync(model, cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(model, \"model\");\n        if (!!err) {\n            err(\"Not yet implemented.\");\n        }\n    }\n    /**\n     * Stops continuous speech recognition.\n     * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n     * This functionality is currently not included in the SDK itself.\n     * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopKeywordRecognitionAsync(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n        }\n    }\n    /**\n     * Adds a phrase that should be recognized as intent.\n     * @member IntentRecognizer.prototype.addIntent\n     * @function\n     * @public\n     * @param {string} intentId - A String that represents the identifier of the intent to be recognized.\n     * @param {string} phrase - A String that specifies the phrase representing the intent.\n     */\n    addIntent(simplePhrase, intentId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedIntentRecognizer);\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(intentId, \"intentId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(simplePhrase, \"simplePhrase\");\n        this.privAddedIntents.push([intentId, simplePhrase]);\n    }\n    /**\n     * Adds an intent from Language Understanding service for recognition.\n     * @member IntentRecognizer.prototype.addIntentWithLanguageModel\n     * @function\n     * @public\n     * @param {string} intentId - A String that represents the identifier of the intent\n     * to be recognized. Ignored if intentName is empty.\n     * @param {string} model - The intent model from Language Understanding service.\n     * @param {string} intentName - The intent name defined in the intent model. If it\n     * is empty, all intent names defined in the model will be added.\n     */\n    addIntentWithLanguageModel(intentId, model, intentName) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedIntentRecognizer);\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(intentId, \"intentId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(model, \"model\");\n        const modelImpl = model;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n        this.privAddedLmIntents[intentId] = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AddedLmIntent\"](modelImpl, intentName);\n    }\n    /**\n     * @summary Adds all intents from the specified Language Understanding Model.\n     * @member IntentRecognizer.prototype.addAllIntents\n     * @function\n     * @public\n     * @function\n     * @public\n     * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.\n     * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.\n     */\n    addAllIntents(model, intentId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(model, \"model\");\n        const modelImpl = model;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n        this.privUmbrellaIntent = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AddedLmIntent\"](modelImpl, intentId);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member IntentRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedIntentRecognizer);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, errorCb);\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognizerConfig\"](speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const audioImpl = audioConfig;\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"IntentServiceRecognizer\"](authentication, connectionFactory, audioImpl, recognizerConfig, this);\n    }\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedIntentRecognizer) {\n                return;\n            }\n            if (disposing) {\n                this.privDisposedIntentRecognizer = true;\n                yield _super.dispose.call(this, disposing);\n            }\n        });\n    }\n    buildSpeechContext() {\n        let appId;\n        let region;\n        let subscriptionKey;\n        const refGrammers = [];\n        if (undefined !== this.privUmbrellaIntent) {\n            appId = this.privUmbrellaIntent.modelImpl.appId;\n            region = this.privUmbrellaIntent.modelImpl.region;\n            subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;\n        }\n        // Build the reference grammer array.\n        for (const intentId of Object.keys(this.privAddedLmIntents)) {\n            const addedLmIntent = this.privAddedLmIntents[intentId];\n            // validate all the same model, region, and key...\n            if (appId === undefined) {\n                appId = addedLmIntent.modelImpl.appId;\n            }\n            else {\n                if (appId !== addedLmIntent.modelImpl.appId) {\n                    throw new Error(\"Intents must all be from the same LUIS model\");\n                }\n            }\n            if (region === undefined) {\n                region = addedLmIntent.modelImpl.region;\n            }\n            else {\n                if (region !== addedLmIntent.modelImpl.region) {\n                    throw new Error(\"Intents must all be from the same LUIS model in a single region\");\n                }\n            }\n            if (subscriptionKey === undefined) {\n                subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;\n            }\n            else {\n                if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {\n                    throw new Error(\"Intents must all use the same subscription key\");\n                }\n            }\n            const grammer = \"luis/\" + appId + \"-PRODUCTION#\" + intentId;\n            refGrammers.push(grammer);\n        }\n        return {\n            Intent: {\n                id: appId,\n                key: (subscriptionKey === undefined) ? this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Key]) : subscriptionKey,\n                provider: \"LUIS\",\n            },\n            ReferenceGrammars: (undefined === this.privUmbrellaIntent) ? refGrammers : [\"luis/\" + appId + \"-PRODUCTION\"],\n        };\n    }\n}\n\n//# sourceMappingURL=IntentRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js ***!
  \***************************************************************************************************************/
/*! exports provided: KeywordRecognitionModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"KeywordRecognitionModel\", function() { return KeywordRecognitionModel; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents a keyword recognition model for recognizing when\n * the user says a keyword to initiate further speech recognition.\n * @class KeywordRecognitionModel\n */\nclass KeywordRecognitionModel {\n    /**\n     * Create and initializes a new instance.\n     * @constructor\n     */\n    constructor() {\n        this.privDisposed = false;\n        return;\n    }\n    /**\n     * Creates a keyword recognition model using the specified filename.\n     * @member KeywordRecognitionModel.fromFile\n     * @function\n     * @public\n     * @param {string} fileName - A string that represents file name for the keyword recognition model.\n     * Note, the file can point to a zip file in which case the model\n     * will be extracted from the zip.\n     * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n     */\n    static fromFile(fileName) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfFileDoesNotExist(fileName, \"fileName\");\n        throw new Error(\"Not yet implemented.\");\n    }\n    /**\n     * Creates a keyword recognition model using the specified filename.\n     * @member KeywordRecognitionModel.fromStream\n     * @function\n     * @public\n     * @param {string} file - A File that represents file for the keyword recognition model.\n     * Note, the file can point to a zip file in which case the model will be extracted from the zip.\n     * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n     */\n    static fromStream(file) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNull(file, \"file\");\n        throw new Error(\"Not yet implemented.\");\n    }\n    /**\n     * Dispose of associated resources.\n     * @member KeywordRecognitionModel.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        if (this.privDisposed) {\n            return;\n        }\n        this.privDisposed = true;\n    }\n}\n\n//# sourceMappingURL=KeywordRecognitionModel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js ***!
  \******************************************************************************************************/
/*! exports provided: LanguageIdMode */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdMode\", function() { return LanguageIdMode; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Language Identification mode\n * @class LanguageIdMode\n */\nvar LanguageIdMode;\n(function (LanguageIdMode) {\n    /**\n     * Detect language at audio start\n     * @member LanguageIdMode.AtStart\n     */\n    LanguageIdMode[LanguageIdMode[\"AtStart\"] = 0] = \"AtStart\";\n    /**\n     * Continuously detect language\n     * @member LanguageIdMode.Continuous\n     */\n    LanguageIdMode[LanguageIdMode[\"Continuous\"] = 1] = \"Continuous\";\n})(LanguageIdMode || (LanguageIdMode = {}));\n\n//# sourceMappingURL=LanguageIdMode.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js ***!
  \**********************************************************************************************************/
/*! exports provided: LanguageIdPriority */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LanguageIdPriority\", function() { return LanguageIdPriority; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Language Identification priority\n * @class LanguageIdPriority\n */\nvar LanguageIdPriority;\n(function (LanguageIdPriority) {\n    /**\n     * Prioritize Accuracy for Language Id (does not work for continuous mode LID)\n     * @member LanguageIdPriority.Accuracy\n     */\n    LanguageIdPriority[LanguageIdPriority[\"Accuracy\"] = 0] = \"Accuracy\";\n    /**\n     * Prioritize latency for Language Id\n     * @member LanguageIdPriority.Latency\n     */\n    LanguageIdPriority[LanguageIdPriority[\"Latency\"] = 1] = \"Latency\";\n})(LanguageIdPriority || (LanguageIdPriority = {}));\n\n//# sourceMappingURL=LanguageIdPriority.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js ***!
  \******************************************************************************************************************/
/*! exports provided: LanguageUnderstandingModel, LanguageUnderstandingModelImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LanguageUnderstandingModel\", function() { return LanguageUnderstandingModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LanguageUnderstandingModelImpl\", function() { return LanguageUnderstandingModelImpl; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// eslint-disable-next-line max-classes-per-file\n\n/**\n * Language understanding model\n * @class LanguageUnderstandingModel\n */\nclass LanguageUnderstandingModel {\n    /**\n     * Creates and initializes a new instance\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Creates an language understanding model using the specified endpoint.\n     * @member LanguageUnderstandingModel.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} uri - A String that represents the endpoint of the language understanding model.\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromEndpoint(uri) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNull(uri, \"uri\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(uri.hostname, \"uri\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        // Need to extract the app ID from the URL.\n        // URL is in the format: https://<region>.api.cognitive.microsoft.com/luis/v2.0/apps/<Guid>?subscription-key=<key>&timezoneOffset=-360\n        // Start tearing the string apart.\n        // region can be extracted from the host name.\n        const firstDot = uri.host.indexOf(\".\");\n        if (-1 === firstDot) {\n            throw new Error(\"Could not determine region from endpoint\");\n        }\n        langModelImp.region = uri.host.substr(0, firstDot);\n        // Now the app ID.\n        const lastSegment = uri.pathname.lastIndexOf(\"/\") + 1;\n        if (-1 === lastSegment) {\n            throw new Error(\"Could not determine appId from endpoint\");\n        }\n        langModelImp.appId = uri.pathname.substr(lastSegment);\n        // And finally the key.\n        langModelImp.subscriptionKey = uri.searchParams.get(\"subscription-key\");\n        if (undefined === langModelImp.subscriptionKey) {\n            throw new Error(\"Could not determine subscription key from endpoint\");\n        }\n        return langModelImp;\n    }\n    /**\n     * Creates an language understanding model using the application id of Language Understanding service.\n     * @member LanguageUnderstandingModel.fromAppId\n     * @function\n     * @public\n     * @param {string} appId - A String that represents the application id of Language Understanding service.\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromAppId(appId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(appId, \"appId\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        langModelImp.appId = appId;\n        return langModelImp;\n    }\n    /**\n     * Creates a language understanding model using hostname, subscription key and application\n     * id of Language Understanding service.\n     * @member LanguageUnderstandingModel.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - A String that represents the subscription key of\n     * Language Understanding service.\n     * @param {string} appId - A String that represents the application id of Language\n     * Understanding service.\n     * @param {LanguageUnderstandingModel} region - A String that represents the region\n     * of the Language Understanding service (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {LanguageUnderstandingModel} The language understanding model being created.\n     */\n    static fromSubscription(subscriptionKey, appId, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(appId, \"appId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const langModelImp = new LanguageUnderstandingModelImpl();\n        langModelImp.appId = appId;\n        langModelImp.region = region;\n        langModelImp.subscriptionKey = subscriptionKey;\n        return langModelImp;\n    }\n}\n/**\n * @private\n * @class LanguageUnderstandingModelImpl\n */\nclass LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {\n}\n\n//# sourceMappingURL=LanguageUnderstandingModel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LogLevel.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LogLevel.js ***!
  \************************************************************************************************/
/*! exports provided: LogLevel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LogLevel\", function() { return _common_Exports__WEBPACK_IMPORTED_MODULE_0__[\"EventType\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Define event severity types for setting logging output.\n * @class LogLevel\n */\n\n\n//# sourceMappingURL=LogLevel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LogLevel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js ***!
  \******************************************************************************************************/
/*! exports provided: NoMatchDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NoMatchDetails\", function() { return NoMatchDetails; });\n/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../src/common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Contains detailed information for NoMatch recognition results.\n * @class NoMatchDetails\n */\nclass NoMatchDetails {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {NoMatchReason} reason - The no-match reason.\n     */\n    constructor(reason) {\n        this.privReason = reason;\n    }\n    /**\n     * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.\n     * @member NoMatchDetails.fromResult\n     * @function\n     * @public\n     * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}\n     * result - The recognition result that was not recognized.\n     * @returns {NoMatchDetails} The no match details object being created.\n     */\n    static fromResult(result) {\n        const simpleSpeech = _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SimpleSpeechPhrase\"].fromJSON(result.json);\n        let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"NoMatchReason\"].NotRecognized;\n        switch (simpleSpeech.RecognitionStatus) {\n            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionStatus\"].BabbleTimeout:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"NoMatchReason\"].InitialBabbleTimeout;\n                break;\n            case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionStatus\"].InitialSilenceTimeout:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"NoMatchReason\"].InitialSilenceTimeout;\n                break;\n            default:\n                reason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"NoMatchReason\"].NotRecognized;\n                break;\n        }\n        return new NoMatchDetails(reason);\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member NoMatchDetails.prototype.reason\n     * @function\n     * @public\n     * @returns {NoMatchReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=NoMatchDetails.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js ***!
  \*****************************************************************************************************/
/*! exports provided: NoMatchReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NoMatchReason\", function() { return NoMatchReason; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might not be recognized.\n * @class NoMatchReason\n */\nvar NoMatchReason;\n(function (NoMatchReason) {\n    /**\n     * Indicates that speech was detected, but not recognized.\n     * @member NoMatchReason.NotRecognized\n     */\n    NoMatchReason[NoMatchReason[\"NotRecognized\"] = 0] = \"NotRecognized\";\n    /**\n     * Indicates that the start of the audio stream contained only silence,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialSilenceTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialSilenceTimeout\"] = 1] = \"InitialSilenceTimeout\";\n    /**\n     * Indicates that the start of the audio stream contained only noise,\n     * and the service timed out waiting for speech.\n     * @member NoMatchReason.InitialBabbleTimeout\n     */\n    NoMatchReason[NoMatchReason[\"InitialBabbleTimeout\"] = 2] = \"InitialBabbleTimeout\";\n})(NoMatchReason || (NoMatchReason = {}));\n\n//# sourceMappingURL=NoMatchReason.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js ***!
  \****************************************************************************************************/
/*! exports provided: OutputFormat */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OutputFormat\", function() { return OutputFormat; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define Speech Recognizer output formats.\n * @class OutputFormat\n */\nvar OutputFormat;\n(function (OutputFormat) {\n    /**\n     * @member OutputFormat.Simple\n     */\n    OutputFormat[OutputFormat[\"Simple\"] = 0] = \"Simple\";\n    /**\n     * @member OutputFormat.Detailed\n     */\n    OutputFormat[OutputFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(OutputFormat || (OutputFormat = {}));\n\n//# sourceMappingURL=OutputFormat.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js ***!
  \*********************************************************************************************************/
/*! exports provided: PhraseListGrammar */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PhraseListGrammar\", function() { return PhraseListGrammar; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Allows additions of new phrases to improve speech recognition.\n *\n * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect\n * to the speech service.\n */\nclass PhraseListGrammar {\n    constructor(recogBase) {\n        this.privGrammerBuilder = recogBase.dynamicGrammar;\n    }\n    /**\n     * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.\n     * @param recognizer The recognizer to add phrase lists to.\n     */\n    static fromRecognizer(recognizer) {\n        const recoBase = recognizer.internalData;\n        return new PhraseListGrammar(recoBase);\n    }\n    /**\n     * Adds a single phrase to the current recognizer.\n     * @param phrase Phrase to add.\n     */\n    addPhrase(phrase) {\n        this.privGrammerBuilder.addPhrase(phrase);\n    }\n    /**\n     * Adds multiple phrases to the current recognizer.\n     * @param phrases Array of phrases to add.\n     */\n    addPhrases(phrases) {\n        this.privGrammerBuilder.addPhrase(phrases);\n    }\n    /**\n     * Clears all phrases added to the current recognizer.\n     */\n    clear() {\n        this.privGrammerBuilder.clearPhrases();\n    }\n}\n\n//# sourceMappingURL=PhraseListGrammar.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js ***!
  \*******************************************************************************************************/
/*! exports provided: ProfanityOption */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ProfanityOption\", function() { return ProfanityOption; });\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n/**\n * Profanity option.\n * Added in version 1.7.0.\n */\nvar ProfanityOption;\n(function (ProfanityOption) {\n    ProfanityOption[ProfanityOption[\"Masked\"] = 0] = \"Masked\";\n    ProfanityOption[ProfanityOption[\"Removed\"] = 1] = \"Removed\";\n    ProfanityOption[ProfanityOption[\"Raw\"] = 2] = \"Raw\";\n})(ProfanityOption || (ProfanityOption = {}));\n\n//# sourceMappingURL=ProfanityOption.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js ***!
  \*********************************************************************************************************************/
/*! exports provided: PronunciationAssessmentConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentConfig\", function() { return PronunciationAssessmentConfig; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Pronunciation assessment configuration.\n * @class PronunciationAssessmentConfig\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentConfig {\n    /**\n     * PronunciationAssessmentConfig constructor.\n     * @constructor\n     * @param {string} referenceText\n     * @param gradingSystem\n     * @param granularity\n     * @param enableMiscue\n     */\n    constructor(referenceText, gradingSystem = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PronunciationAssessmentGradingSystem\"].FivePoint, granularity = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PronunciationAssessmentGranularity\"].Phoneme, enableMiscue = false) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(referenceText, \"referenceText\");\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_ReferenceText, referenceText);\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_GradingSystem, _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PronunciationAssessmentGradingSystem\"][gradingSystem]);\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Granularity, _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PronunciationAssessmentGranularity\"][granularity]);\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_EnableMiscue, String(enableMiscue));\n    }\n    /**\n     * @member PronunciationAssessmentConfig.fromJSON\n     * @function\n     * @public\n     * @param {string} json The json string containing the pronunciation assessment parameters.\n     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n     * @summary Creates an instance of the PronunciationAssessmentConfig from json.\n     */\n    static fromJSON(json) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(json, \"json\");\n        const config = new PronunciationAssessmentConfig(\"\");\n        config.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Json, json);\n        return config;\n    }\n    toJSON() {\n        this.updateJson();\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Params);\n    }\n    applyTo(recognizer) {\n        this.updateJson();\n        const recoBase = recognizer.internalData;\n        recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Params));\n    }\n    /**\n     * Gets the reference text.\n     * @member PronunciationAssessmentConfig.prototype.referenceText\n     * @function\n     * @public\n     * @returns {string} Reference text.\n     */\n    get referenceText() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_ReferenceText);\n    }\n    /**\n     * Gets/Sets the reference text.\n     * @member PronunciationAssessmentConfig.prototype.referenceText\n     * @function\n     * @public\n     * @param {string} referenceText - Reference text.\n     */\n    set referenceText(referenceText) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(referenceText, \"referenceText\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_ReferenceText, referenceText);\n    }\n    /**\n     * Sets the phoneme alphabet.\n     * The valid values are \"SAPI\" (default) and \"IPA\".\n     * Added in version 1.20.0\n     * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet\n     * @function\n     * @public\n     * @param {string} phonemeAlphabet - Phoneme alphabet.\n     */\n    set phonemeAlphabet(phonemeAlphabet) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrWhitespace(phonemeAlphabet, \"phonemeAlphabet\");\n        this.privPhonemeAlphabet = phonemeAlphabet;\n    }\n    /**\n     * Sets the nbest phoneme count\n     * Added in version 1.20.0\n     * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount\n     * @function\n     * @public\n     * @param {number} nbestPhonemeCount - NBest phoneme count.\n     */\n    set nbestPhonemeCount(nbestPhonemeCount) {\n        this.privNBestPhonemeCount = nbestPhonemeCount;\n    }\n    /**\n     * @member PronunciationAssessmentConfig.prototype.properties\n     * @function\n     * @public\n     * @return {PropertyCollection} Properties of the config.\n     * @summary Gets a pronunciation assessment config properties\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    updateJson() {\n        const jsonString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Json, \"{}\");\n        const paramsJson = JSON.parse(jsonString);\n        const referenceText = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_ReferenceText);\n        if (referenceText) {\n            paramsJson.referenceText = referenceText;\n        }\n        const gradingSystem = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_GradingSystem);\n        if (gradingSystem) {\n            paramsJson.gradingSystem = gradingSystem;\n        }\n        const granularity = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Granularity);\n        if (granularity) {\n            paramsJson.granularity = granularity;\n        }\n        if (this.privPhonemeAlphabet) {\n            paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;\n        }\n        if (this.privNBestPhonemeCount) {\n            paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;\n        }\n        // always set dimension to Comprehensive\n        paramsJson.dimension = \"Comprehensive\";\n        const enableMiscueString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_EnableMiscue);\n        if (enableMiscueString === \"true\") {\n            paramsJson.enableMiscue = true;\n        }\n        else if (enableMiscueString === \"false\") {\n            paramsJson.enableMiscue = false;\n        }\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].PronunciationAssessment_Params, JSON.stringify(paramsJson));\n    }\n}\n\n//# sourceMappingURL=PronunciationAssessmentConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \****************************************************************************************************************************/
/*! exports provided: PronunciationAssessmentGradingSystem */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGradingSystem\", function() { return PronunciationAssessmentGradingSystem; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the point system for pronunciation score calibration; default value is FivePoint.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGradingSystem\n */\nvar PronunciationAssessmentGradingSystem;\n(function (PronunciationAssessmentGradingSystem) {\n    /**\n     * Five point calibration\n     * @member PronunciationAssessmentGradingSystem.FivePoint\n     */\n    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"FivePoint\"] = 1] = \"FivePoint\";\n    /**\n     * Hundred mark\n     * @member PronunciationAssessmentGradingSystem.HundredMark\n     */\n    PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"HundredMark\"] = 2] = \"HundredMark\";\n})(PronunciationAssessmentGradingSystem || (PronunciationAssessmentGradingSystem = {}));\n\n//# sourceMappingURL=PronunciationAssessmentGradingSystem.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js ***!
  \**************************************************************************************************************************/
/*! exports provided: PronunciationAssessmentGranularity */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentGranularity\", function() { return PronunciationAssessmentGranularity; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the pronunciation evaluation granularity; default value is Phoneme.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGranularity\n */\nvar PronunciationAssessmentGranularity;\n(function (PronunciationAssessmentGranularity) {\n    /**\n     * Shows the score on the full text, word and phoneme level\n     * @member PronunciationAssessmentGranularity.Phoneme\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Phoneme\"] = 1] = \"Phoneme\";\n    /**\n     * Shows the score on the full text and word level\n     * @member PronunciationAssessmentGranularity.Word\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Word\"] = 2] = \"Word\";\n    /**\n     * Shows the score on the full text level only\n     * @member PronunciationAssessmentGranularity.FullText\n     */\n    PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"FullText\"] = 3] = \"FullText\";\n})(PronunciationAssessmentGranularity || (PronunciationAssessmentGranularity = {}));\n\n//# sourceMappingURL=PronunciationAssessmentGranularity.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js ***!
  \*********************************************************************************************************************/
/*! exports provided: PronunciationAssessmentResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PronunciationAssessmentResult\", function() { return PronunciationAssessmentResult; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Pronunciation assessment results.\n * @class PronunciationAssessmentResult\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentResult {\n    constructor(jsonString) {\n        const j = JSON.parse(jsonString);\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(j.NBest[0], \"NBest\");\n        this.privPronJson = j.NBest[0];\n    }\n    /**\n     * @member PronunciationAssessmentResult.fromResult\n     * @function\n     * @public\n     * @param {RecognitionResult} result The recognition result.\n     * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n     * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.\n     */\n    static fromResult(result) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(result, \"result\");\n        const json = result.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyId\"].SpeechServiceResponse_JsonResult);\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(json, \"json\");\n        return new PronunciationAssessmentResult(json);\n    }\n    /**\n     * Gets the detail result of pronunciation assessment.\n     * @member PronunciationAssessmentConfig.prototype.detailResult\n     * @function\n     * @public\n     * @returns {DetailResult} detail result.\n     */\n    get detailResult() {\n        return this.privPronJson;\n    }\n    /**\n     * The score indicating the pronunciation accuracy of the given speech, which indicates\n     * how closely the phonemes match a native speaker's pronunciation.\n     * @member PronunciationAssessmentResult.prototype.accuracyScore\n     * @function\n     * @public\n     * @returns {number} Accuracy score.\n     */\n    get accuracyScore() {\n        return this.detailResult.PronunciationAssessment.AccuracyScore;\n    }\n    /**\n     * The overall score indicating the pronunciation quality of the given speech.\n     * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.\n     * @member PronunciationAssessmentResult.prototype.pronunciationScore\n     * @function\n     * @public\n     * @returns {number} Pronunciation score.\n     */\n    get pronunciationScore() {\n        return this.detailResult.PronunciationAssessment.PronScore;\n    }\n    /**\n     * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.\n     * @member PronunciationAssessmentResult.prototype.completenessScore\n     * @function\n     * @public\n     * @returns {number} Completeness score.\n     */\n    get completenessScore() {\n        return this.detailResult.PronunciationAssessment.CompletenessScore;\n    }\n    /**\n     * The score indicating the fluency of the given speech.\n     * @member PronunciationAssessmentResult.prototype.fluencyScore\n     * @function\n     * @public\n     * @returns {number} Fluency score.\n     */\n    get fluencyScore() {\n        return this.detailResult.PronunciationAssessment.FluencyScore;\n    }\n}\n\n//# sourceMappingURL=PronunciationAssessmentResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js ***!
  \**********************************************************************************************************/
/*! exports provided: PropertyCollection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PropertyCollection\", function() { return PropertyCollection; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of properties and their values.\n * @class PropertyCollection\n */\nclass PropertyCollection {\n    constructor() {\n        this.privKeys = [];\n        this.privValues = [];\n    }\n    /**\n     * Returns the property value in type String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member PropertyCollection.prototype.getProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string | number | boolean} def - The default value which is returned if the parameter\n     * is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    getProperty(key, def) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"][key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                return this.privValues[n];\n            }\n        }\n        if (def === undefined) {\n            return undefined;\n        }\n        return String(def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member PropertyCollection.prototype.setProperty\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    setProperty(key, value) {\n        let keyToUse;\n        if (typeof key === \"string\") {\n            keyToUse = key;\n        }\n        else {\n            keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyId\"][key];\n        }\n        for (let n = 0; n < this.privKeys.length; n++) {\n            if (this.privKeys[n] === keyToUse) {\n                this.privValues[n] = value;\n                return;\n            }\n        }\n        this.privKeys.push(keyToUse);\n        this.privValues.push(value);\n    }\n    /**\n     * Clones the collection.\n     * @member PropertyCollection.prototype.clone\n     * @function\n     * @public\n     * @returns {PropertyCollection} A copy of the collection.\n     */\n    clone() {\n        const clonedMap = new PropertyCollection();\n        for (let n = 0; n < this.privKeys.length; n++) {\n            clonedMap.privKeys.push(this.privKeys[n]);\n            clonedMap.privValues.push(this.privValues[n]);\n        }\n        return clonedMap;\n    }\n    /**\n     * Merges this set of properties into another, no overwrites.\n     * @member PropertyCollection.prototype.mergeTo\n     * @function\n     * @public\n     * @param {PropertyCollection}  destinationCollection - The collection to merge into.\n     */\n    mergeTo(destinationCollection) {\n        this.privKeys.forEach((key) => {\n            if (destinationCollection.getProperty(key, undefined) === undefined) {\n                const value = this.getProperty(key);\n                destinationCollection.setProperty(key, value);\n            }\n        });\n    }\n    /**\n     * Get the keys in Property Collection.\n     * @member PropertyCollection.prototype.keys\n     * @function\n     * @public\n     * @returns {string []} Keys in the collection.\n     */\n    get keys() {\n        return this.privKeys;\n    }\n}\n\n//# sourceMappingURL=PropertyCollection.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js ***!
  \**************************************************************************************************/
/*! exports provided: PropertyId */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PropertyId\", function() { return PropertyId; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nvar PropertyId;\n(function (PropertyId) {\n    /**\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]].\n     * @member PropertyId.SpeechServiceConnection_Key\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n    /**\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.fromEndpoint]].\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n     * @member PropertyId.SpeechServiceConnection_Endpoint\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n    /**\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n     * use this property directly.\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n     * @member PropertyId.SpeechServiceConnection_Region\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n    /**\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n     * @member PropertyId.SpeechServiceAuthorization_Token\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n    /**\n     * The Cognitive Services Speech Service authorization type. Currently unused.\n     * @member PropertyId.SpeechServiceAuthorization_Type\n     */\n    PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n    /**\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n     * have to use this property directly.\n     * Instead, use [[SpeechConfig.endpointId]].\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n     * @member PropertyId.SpeechServiceConnection_EndpointId\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n    /**\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n     * you shouldn't have to use this property directly.\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n    /**\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n    /**\n     * Translation features.\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n    /**\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[LanguageUnderstandingModel]].\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n    /**\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n    /**\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n    /**\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n    /**\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n     * You shouldn't have to use this property directly.\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n     * Added in version 1.4.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n    /**\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n     * This property is intended to be read-only. The SDK is using it internally.\n     * @member PropertyId.SpeechServiceConnection_RecoMode\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n    /**\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n     * directly.\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n    /**\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n     * property directly.\n     * Instead use [[SessionEventArgs.sessionId]].\n     * @member PropertyId.Speech_SessionId\n     */\n    PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n    /**\n     * The spoken language to be synthesized (e.g. en-US)\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n    /**\n     * The name of the TTS voice to be used for speech synthesis\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n    /**\n     * The string to specify TTS output audio format\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n    /**\n     * The list of comma separated languages used as possible source languages\n     * Added in version 1.13.0\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n    /**\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n     * to use this property directly.\n     * Instead use [[SpeechConfig.outputFormat]].\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n    /**\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n     * @member PropertyId.SpeechServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n    /**\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n    /**\n     * The cancellation reason. Currently unused.\n     * @member PropertyId.CancellationDetails_Reason\n     */\n    PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n    /**\n     * The cancellation text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n    /**\n     * The Cancellation detailed text. Currently unused.\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\n     */\n    PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n    /**\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n     */\n    PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n    /**\n     * The URL string built from speech configuration.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * NOTE: Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n    /**\n     * The initial silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n    /**\n     * The end silence timeout value (in milliseconds) used by the service.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n    /**\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n     * behavior should be thoroughly validated as intended.\n     *\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\n     * https://aka.ms/csspeech/timeouts.\n     *\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n    /**\n     * A boolean value specifying whether audio logging is enabled in the service or not.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 33] = \"SpeechServiceConnection_EnableAudioLogging\";\n    /**\n     * A string value representing the priority for single language detection.\n     * Allowed values include \"Latency\" and \"Accuracy\"\n     * Added in version 1.21.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_AtStartLanguageIdPriority\"] = 34] = \"SpeechServiceConnection_AtStartLanguageIdPriority\";\n    /**\n     * A string value representing the priority for continuous language detection.\n     * \"Latency\" is default, \"Accuracy\" is currently not allowed for continuous LID\n     * Added in version 1.21.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_ContinuousLanguageIdPriority\"] = 35] = \"SpeechServiceConnection_ContinuousLanguageIdPriority\";\n    /**\n     * A string value representing the desired endpoint version to target for Speech Recognition.\n     * Added in version 1.21.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 36] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n    /**\n     * The requested Cognitive Services Speech Service response output profanity setting.\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 37] = \"SpeechServiceResponse_ProfanityOption\";\n    /**\n     * A string value specifying which post processing option should be used by service.\n     * Allowed values are \"TrueText\".\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 38] = \"SpeechServiceResponse_PostProcessingOption\";\n    /**\n     * A boolean value specifying whether to include word-level timestamps in the response result.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 39] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n    /**\n     * The number of times a word has to be in partial results to be returned.\n     * Added in version 1.7.0\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 40] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n    /**\n     * A string value specifying the output format option in the response result. Internal use only.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 41] = \"SpeechServiceResponse_OutputFormatOption\";\n    /**\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n     * Added in version 1.7.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 42] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n    /**\n     * A boolean value specifying whether to request WordBoundary events.\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 43] = \"SpeechServiceResponse_RequestWordBoundary\";\n    /**\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 44] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n    /**\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n     * Added in version 1.21.0.\n     */\n    PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 45] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n    /**\n     * Identifier used to connect to the backend service.\n     * @member PropertyId.Conversation_ApplicationId\n     */\n    PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 46] = \"Conversation_ApplicationId\";\n    /**\n     * Type of dialog backend to connect to.\n     * @member PropertyId.Conversation_DialogType\n     */\n    PropertyId[PropertyId[\"Conversation_DialogType\"] = 47] = \"Conversation_DialogType\";\n    /**\n     * Silence timeout for listening\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\n     */\n    PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 48] = \"Conversation_Initial_Silence_Timeout\";\n    /**\n     * From Id to add to speech recognition activities.\n     * @member PropertyId.Conversation_From_Id\n     */\n    PropertyId[PropertyId[\"Conversation_From_Id\"] = 49] = \"Conversation_From_Id\";\n    /**\n     * ConversationId for the session.\n     * @member PropertyId.Conversation_Conversation_Id\n     */\n    PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 50] = \"Conversation_Conversation_Id\";\n    /**\n     * Comma separated list of custom voice deployment ids.\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n     */\n    PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 51] = \"Conversation_Custom_Voice_Deployment_Ids\";\n    /**\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n     * @member PropertyId.Conversation_Speech_Activity_Template\n     * Added in version 1.10.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 52] = \"Conversation_Speech_Activity_Template\";\n    /**\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\n     * Added in version 1.15.0.\n     */\n    PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 53] = \"Conversation_Request_Bot_Status_Messages\";\n    /**\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n     * channel authentication.\n     * Added in version 1.15.1.\n     */\n    PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 54] = \"Conversation_Agent_Connection_Id\";\n    /**\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n     * Instead, use [[SpeechConfig.fromHost]].\n     */\n    PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 55] = \"SpeechServiceConnection_Host\";\n    /**\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 56] = \"ConversationTranslator_Host\";\n    /**\n     * Optionally set the the host's display name.\n     * Used when joining a conversation.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 57] = \"ConversationTranslator_Name\";\n    /**\n     * Optionally set a value for the X-CorrelationId request header.\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 58] = \"ConversationTranslator_CorrelationId\";\n    /**\n     * Set the conversation token to be sent to the speech service. This enables the\n     * service to service call from the speech service to the Conversation Translator service for relaying\n     * recognitions. For internal use.\n     */\n    PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 59] = \"ConversationTranslator_Token\";\n    /**\n     * The reference text of the audio for pronunciation evaluation.\n     * For this and the following pronunciation assessment parameters, see\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 60] = \"PronunciationAssessment_ReferenceText\";\n    /**\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 61] = \"PronunciationAssessment_GradingSystem\";\n    /**\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 62] = \"PronunciationAssessment_Granularity\";\n    /**\n     * Defines if enable miscue calculation.\n     * With this enabled, the pronounced words will be compared to the reference text,\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 63] = \"PronunciationAssessment_EnableMiscue\";\n    /**\n     * The json string of pronunciation assessment parameters\n     * Under normal circumstances, you shouldn't have to use this property directly.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 64] = \"PronunciationAssessment_Json\";\n    /**\n     * Pronunciation assessment parameters.\n     * This property is intended to be read-only. The SDK is using it internally.\n     * Added in version 1.15.0\n     */\n    PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 65] = \"PronunciationAssessment_Params\";\n    /**\n     * Version of Speaker Recognition API to use.\n     * Added in version 1.18.0\n     */\n    PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 66] = \"SpeakerRecognition_Api_Version\";\n})(PropertyId || (PropertyId = {}));\n\n//# sourceMappingURL=PropertyId.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js ***!
  \************************************************************************************************************/
/*! exports provided: RecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionEventArgs\", function() { return RecognitionEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines payload for session events like Speech Start/End Detected\n * @class\n */\nclass RecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(offset, sessionId) {\n        super(sessionId);\n        this.privOffset = offset;\n    }\n    /**\n     * Represents the message offset\n     * @member RecognitionEventArgs.prototype.offset\n     * @function\n     * @public\n     */\n    get offset() {\n        return this.privOffset;\n    }\n}\n\n//# sourceMappingURL=RecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js ***!
  \*********************************************************************************************************/
/*! exports provided: RecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RecognitionResult\", function() { return RecognitionResult; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines result of speech recognition.\n * @class RecognitionResult\n */\nclass RecognitionResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privText = text;\n        this.privDuration = duration;\n        this.privOffset = offset;\n        this.privLanguage = language;\n        this.privLanguageDetectionConfidence = languageDetectionConfidence;\n        this.privErrorDetails = errorDetails;\n        this.privJson = json;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member RecognitionResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member RecognitionResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * Presents the recognized text in the result.\n     * @member RecognitionResult.prototype.text\n     * @function\n     * @public\n     * @returns {string} Presents the recognized text in the result.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Duration of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration of recognized speech in 100 nano second increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Offset of recognized speech in 100 nano second increments.\n     * @member RecognitionResult.prototype.offset\n     * @function\n     * @public\n     * @returns {number} Offset of recognized speech in 100 nano second increments.\n     */\n    get offset() {\n        return this.privOffset;\n    }\n    /**\n     * Primary Language detected.\n     * @member RecognitionResult.prototype.language\n     * @function\n     * @public\n     * @returns {string} language detected.\n     */\n    get language() {\n        return this.privLanguage;\n    }\n    /**\n     * Primary Language detection confidence (Unknown, Low, Medium, High).\n     * @member RecognitionResult.prototype.languageDetectionConfidence\n     * @function\n     * @public\n     * @returns {string} detection confidence strength.\n     */\n    get languageDetectionConfidence() {\n        return this.privLanguageDetectionConfidence;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member RecognitionResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * A string containing Json serialized recognition result as it was received from the service.\n     * @member RecognitionResult.prototype.json\n     * @function\n     * @private\n     * @returns {string} Json serialized representation of the result.\n     */\n    get json() {\n        return this.privJson;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member RecognitionResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\n\n//# sourceMappingURL=RecognitionResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js ***!
  \**************************************************************************************************/
/*! exports provided: Recognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Recognizer\", function() { return Recognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n/**\n * Defines the base class Recognizer which mainly contains common event handlers.\n * @class Recognizer\n */\nclass Recognizer {\n    /**\n     * Creates and initializes an instance of a Recognizer\n     * @constructor\n     * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer\n     */\n    constructor(audioConfig, properties, connectionFactory) {\n        this.audioConfig = (audioConfig !== undefined) ? audioConfig : _Exports__WEBPACK_IMPORTED_MODULE_3__[\"AudioConfig\"].fromDefaultMicrophoneInput();\n        this.privDisposed = false;\n        this.privProperties = properties.clone();\n        this.privConnectionFactory = connectionFactory;\n        this.implCommonRecognizerSetup();\n    }\n    /**\n     * Dispose of associated resources.\n     * @member Recognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * @Internal\n     * Internal data member to support fromRecognizer* pattern methods on other classes.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privReco;\n    }\n    /**\n     * This method performs cleanup of resources.\n     * The Boolean parameter disposing indicates whether the method is called\n     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n     * Derived classes should override this method to dispose resource if needed.\n     * @member Recognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - Flag to request disposal.\n     */\n    dispose(disposing) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposed) {\n                return;\n            }\n            this.privDisposed = true;\n            if (disposing) {\n                if (this.privReco) {\n                    yield this.privReco.audioSource.turnOff();\n                    yield this.privReco.dispose();\n                }\n            }\n        });\n    }\n    /**\n     * This method returns the current state of the telemetry setting.\n     * @member Recognizer.prototype.telemetryEnabled\n     * @function\n     * @public\n     * @returns true if the telemetry is enabled, false otherwise.\n     */\n    static get telemetryEnabled() {\n        return _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServiceRecognizerBase\"].telemetryDataEnabled;\n    }\n    /**\n     * This method globally enables or disables telemetry.\n     * @member Recognizer.prototype.enableTelemetry\n     * @function\n     * @public\n     * @param enabled - Global setting for telemetry collection.\n     * If set to true, telemetry information like microphone errors,\n     * recognition errors are collected and sent to Microsoft.\n     * If set to false, no telemetry is sent to Microsoft.\n     */\n    static enableTelemetry(enabled) {\n        _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServiceRecognizerBase\"].telemetryDataEnabled = enabled;\n    }\n    // Does the generic recognizer setup that is common across all recognizer types.\n    implCommonRecognizerSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const recognizerConfig = this.createRecognizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechServiceConfig\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OS\"](osPlatform, osName, osVersion))));\n        this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);\n    }\n    recognizeOnceAsyncImpl(recognitionMode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n            const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Deferred\"]();\n            yield this.implRecognizerStop();\n            yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);\n            const result = yield ret.promise;\n            yield this.implRecognizerStop();\n            return result;\n        });\n    }\n    startContinuousRecognitionAsyncImpl(recognitionMode) {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n            yield this.implRecognizerStop();\n            yield this.privReco.recognize(recognitionMode, undefined, undefined);\n        });\n    }\n    stopContinuousRecognitionAsyncImpl() {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n            yield this.implRecognizerStop();\n        });\n    }\n    implRecognizerStop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privReco) {\n                yield this.privReco.stopRecognizing();\n            }\n            return;\n        });\n    }\n    static getAuthFromProperties(properties) {\n        const subscriptionKey = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Key, undefined);\n        const authentication = (subscriptionKey && subscriptionKey !== \"\") ?\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CognitiveSubscriptionKeyAuthentication\"](subscriptionKey) :\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CognitiveTokenAuthentication\"](() => {\n                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            }, () => {\n                const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            });\n        return authentication;\n    }\n}\n\n//# sourceMappingURL=Recognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js ***!
  \****************************************************************************************************/
/*! exports provided: ResultReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ResultReason\", function() { return ResultReason; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be generated.\n * @class ResultReason\n */\nvar ResultReason;\n(function (ResultReason) {\n    /**\n     * Indicates speech could not be recognized. More details\n     * can be found in the NoMatchDetails object.\n     * @member ResultReason.NoMatch\n     */\n    ResultReason[ResultReason[\"NoMatch\"] = 0] = \"NoMatch\";\n    /**\n     * Indicates that the recognition was canceled. More details\n     * can be found using the CancellationDetails object.\n     * @member ResultReason.Canceled\n     */\n    ResultReason[ResultReason[\"Canceled\"] = 1] = \"Canceled\";\n    /**\n     * Indicates the speech result contains hypothesis text.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizingSpeech\"] = 2] = \"RecognizingSpeech\";\n    /**\n     * Indicates the speech result contains final text that has been recognized.\n     * Speech Recognition is now complete for this phrase.\n     * @member ResultReason.RecognizedSpeech\n     */\n    ResultReason[ResultReason[\"RecognizedSpeech\"] = 3] = \"RecognizedSpeech\";\n    /**\n     * Indicates the speech result contains a finalized acceptance of a provided keyword.\n     * Speech recognition will continue unless otherwise configured.\n     * @member ResultReason.RecognizedKeyword\n     */\n    ResultReason[ResultReason[\"RecognizedKeyword\"] = 4] = \"RecognizedKeyword\";\n    /**\n     * Indicates the intent result contains hypothesis text and intent.\n     * @member ResultReason.RecognizingIntent\n     */\n    ResultReason[ResultReason[\"RecognizingIntent\"] = 5] = \"RecognizingIntent\";\n    /**\n     * Indicates the intent result contains final text and intent.\n     * Speech Recognition and Intent determination are now complete for this phrase.\n     * @member ResultReason.RecognizedIntent\n     */\n    ResultReason[ResultReason[\"RecognizedIntent\"] = 6] = \"RecognizedIntent\";\n    /**\n     * Indicates the translation result contains hypothesis text and its translation(s).\n     * @member ResultReason.TranslatingSpeech\n     */\n    ResultReason[ResultReason[\"TranslatingSpeech\"] = 7] = \"TranslatingSpeech\";\n    /**\n     * Indicates the translation result contains final text and corresponding translation(s).\n     * Speech Recognition and Translation are now complete for this phrase.\n     * @member ResultReason.TranslatedSpeech\n     */\n    ResultReason[ResultReason[\"TranslatedSpeech\"] = 8] = \"TranslatedSpeech\";\n    /**\n     * Indicates the synthesized audio result contains a non-zero amount of audio data\n     * @member ResultReason.SynthesizingAudio\n     */\n    ResultReason[ResultReason[\"SynthesizingAudio\"] = 9] = \"SynthesizingAudio\";\n    /**\n     * Indicates the synthesized audio is now complete for this phrase.\n     * @member ResultReason.SynthesizingAudioCompleted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioCompleted\"] = 10] = \"SynthesizingAudioCompleted\";\n    /**\n     * Indicates the speech synthesis is now started\n     * @member ResultReason.SynthesizingAudioStarted\n     */\n    ResultReason[ResultReason[\"SynthesizingAudioStarted\"] = 11] = \"SynthesizingAudioStarted\";\n    /**\n     * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.\n     * @member ResultReason.EnrollingVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrollingVoiceProfile\"] = 12] = \"EnrollingVoiceProfile\";\n    /**\n     * Indicates the voice profile has been enrolled.\n     * @member ResultReason.EnrolledVoiceProfile\n     */\n    ResultReason[ResultReason[\"EnrolledVoiceProfile\"] = 13] = \"EnrolledVoiceProfile\";\n    /**\n     * Indicates successful identification of some speakers.\n     * @member ResultReason.RecognizedSpeakers\n     */\n    ResultReason[ResultReason[\"RecognizedSpeakers\"] = 14] = \"RecognizedSpeakers\";\n    /**\n     * Indicates successfully verified one speaker.\n     * @member ResultReason.RecognizedSpeaker\n     */\n    ResultReason[ResultReason[\"RecognizedSpeaker\"] = 15] = \"RecognizedSpeaker\";\n    /**\n     * Indicates a voice profile has been reset successfully.\n     * @member ResultReason.ResetVoiceProfile\n     */\n    ResultReason[ResultReason[\"ResetVoiceProfile\"] = 16] = \"ResetVoiceProfile\";\n    /**\n     * Indicates a voice profile has been deleted successfully.\n     * @member ResultReason.DeletedVoiceProfile\n     */\n    ResultReason[ResultReason[\"DeletedVoiceProfile\"] = 17] = \"DeletedVoiceProfile\";\n    /**\n     * Indicates synthesis voices list has been successfully retrieved.\n     * @member ResultReason.VoicesListRetrieved\n     */\n    ResultReason[ResultReason[\"VoicesListRetrieved\"] = 18] = \"VoicesListRetrieved\";\n})(ResultReason || (ResultReason = {}));\n\n//# sourceMappingURL=ResultReason.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js ***!
  \********************************************************************************************************/
/*! exports provided: ServiceEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServiceEventArgs\", function() { return ServiceEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for any Service message event\n * Added in version 1.9.0\n */\nclass ServiceEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} json - json payload of the USP message.\n     */\n    constructor(json, name, sessionId) {\n        super(sessionId);\n        this.privJsonResult = json;\n        this.privEventName = name;\n    }\n    get jsonString() {\n        return this.privJsonResult;\n    }\n    get eventName() {\n        return this.privEventName;\n    }\n}\n\n//# sourceMappingURL=ServiceEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js ***!
  \**************************************************************************************************************/
/*! exports provided: ServicePropertyChannel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ServicePropertyChannel\", function() { return ServicePropertyChannel; });\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n/**\n * Defines channels used to pass property settings to service.\n * Added in version 1.7.0.\n */\nvar ServicePropertyChannel;\n(function (ServicePropertyChannel) {\n    /**\n     * Uses URI query parameter to pass property settings to service.\n     */\n    ServicePropertyChannel[ServicePropertyChannel[\"UriQueryParameter\"] = 0] = \"UriQueryParameter\";\n})(ServicePropertyChannel || (ServicePropertyChannel = {}));\n\n//# sourceMappingURL=ServicePropertyChannel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js ***!
  \********************************************************************************************************/
/*! exports provided: SessionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SessionEventArgs\", function() { return SessionEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.\n * @class SessionEventArgs\n */\nclass SessionEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionId - The session id.\n     */\n    constructor(sessionId) {\n        this.privSessionId = sessionId;\n    }\n    /**\n     * Represents the session identifier.\n     * @member SessionEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} Represents the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n}\n\n//# sourceMappingURL=SessionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js ***!
  \************************************************************************************************************/
/*! exports provided: SourceLanguageConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SourceLanguageConfig\", function() { return SourceLanguageConfig; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Source Language configuration.\n * @class SourceLanguageConfig\n */\nclass SourceLanguageConfig {\n    constructor(language, endpointId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(language, \"language\");\n        this.privLanguage = language;\n        this.privEndpointId = endpointId;\n    }\n    /**\n     * @member SourceLanguageConfig.fromLanguage\n     * @function\n     * @public\n     * @param {string} language language (eg. \"en-US\") value of config.\n     * @param {string?} endpointId endpointId of model bound to given language of config.\n     * @return {SourceLanguageConfig} Instance of SourceLanguageConfig\n     * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.\n     * Added in version 1.13.0.\n     */\n    static fromLanguage(language, endpointId) {\n        return new SourceLanguageConfig(language, endpointId);\n    }\n    get language() {\n        return this.privLanguage;\n    }\n    get endpointId() {\n        return this.privEndpointId;\n    }\n}\n\n//# sourceMappingURL=SourceLanguageConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js ***!
  \******************************************************************************************************************/
/*! exports provided: SpeakerIdentificationModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerIdentificationModel\", function() { return SpeakerIdentificationModel; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Defines SpeakerIdentificationModel class for Speaker Recognition\n * Model contains a set of profiles against which to identify speaker(s)\n * @class SpeakerIdentificationModel\n */\nclass SpeakerIdentificationModel {\n    constructor(profiles) {\n        this.privVoiceProfiles = [];\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(profiles, \"VoiceProfiles\");\n        if (profiles.length === 0) {\n            throw new Error(\"Empty Voice Profiles array\");\n        }\n        profiles.forEach((profile) => {\n            if (profile.profileType !== _Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileType\"].TextIndependentIdentification) {\n                throw new Error(\"Identification model can only be created from Identification profile: \" + profile.profileId);\n            }\n            this.privVoiceProfiles.push(profile);\n        });\n    }\n    static fromProfiles(profiles) {\n        return new SpeakerIdentificationModel(profiles);\n    }\n    get voiceProfileIds() {\n        return this.privVoiceProfiles.map((profile) => profile.profileId).join(\",\");\n    }\n}\n\n//# sourceMappingURL=SpeakerIdentificationModel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeakerRecognitionResultType, SpeakerRecognitionResult, SpeakerRecognitionCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResultType\", function() { return SpeakerRecognitionResultType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionResult\", function() { return SpeakerRecognitionResult; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognitionCancellationDetails\", function() { return SpeakerRecognitionCancellationDetails; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\nvar SpeakerRecognitionResultType;\n(function (SpeakerRecognitionResultType) {\n    SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Verify\"] = 0] = \"Verify\";\n    SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Identify\"] = 1] = \"Identify\";\n})(SpeakerRecognitionResultType || (SpeakerRecognitionResultType = {}));\n/**\n * Output format\n * @class SpeakerRecognitionResult\n */\nclass SpeakerRecognitionResult {\n    constructor(resultType, data, profileId, resultReason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].RecognizedSpeaker) {\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        this.privReason = resultReason;\n        if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled) {\n            if (resultType === SpeakerRecognitionResultType.Identify) {\n                const json = JSON.parse(data);\n                _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(json, \"JSON\");\n                this.privProfileId = json.identifiedProfile.profileId;\n                this.privScore = json.identifiedProfile.score;\n            }\n            else {\n                const json = JSON.parse(data);\n                _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(json, \"JSON\");\n                this.privScore = json.score;\n                if (json.recognitionResult.toLowerCase() !== \"accept\") {\n                    this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].NoMatch;\n                }\n                if (profileId !== undefined && profileId !== \"\") {\n                    this.privProfileId = profileId;\n                }\n            }\n        }\n        else {\n            const json = JSON.parse(data);\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(json, \"JSON\");\n            this.privErrorDetails = json.statusText;\n            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].ServiceError]);\n        }\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceResponse_JsonResult, data);\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get profileId() {\n        return this.privProfileId;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    get score() {\n        return this.privScore;\n    }\n}\n/**\n * @class SpeakerRecognitionCancellationDetails\n */\nclass SpeakerRecognitionCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationDetailsBase\"] {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult\n     * @member SpeakerRecognitionCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {SpeakerRecognitionResult} result - The result that was canceled.\n     * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error;\n        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError;\n        if (!!result.properties) {\n            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError])];\n        }\n        return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\n\n//# sourceMappingURL=SpeakerRecognitionResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js ***!
  \*********************************************************************************************************/
/*! exports provided: SpeakerRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerRecognizer\", function() { return SpeakerRecognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Defines SpeakerRecognizer class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class SpeakerRecognizer\n */\nclass SpeakerRecognizer {\n    /**\n     * SpeakerRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - An set of initial properties for this recognizer (authentication key, region, &c)\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(speechConfigImpl, \"speechConfig\");\n        this.privAudioConfigImpl = audioConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(this.privAudioConfigImpl, \"audioConfig\");\n        this.privProperties = speechConfigImpl.properties.clone();\n        this.implSRSetup();\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeakerRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeakerRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this SpeakerRecognizer.\n     * @member SpeakerRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Get recognition result for model using given audio\n     * @member SpeakerRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @async\n     * @param {SpeakerIdentificationModel} model Model containing Voice Profiles to be identified\n     * @param cb - Callback invoked once result is returned.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(model) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerIdentificationModel\"]) {\n                const responsePromise = this.privAdapter.identifySpeaker(model, this.privAudioConfigImpl);\n                return this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionResultType\"].Identify, undefined);\n            }\n            else if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerVerificationModel\"]) {\n                const responsePromise = this.privAdapter.verifySpeaker(model, this.privAudioConfigImpl);\n                return this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionResultType\"].Verify, model.voiceProfile.profileId);\n            }\n            else {\n                throw new Error(\"SpeakerRecognizer.recognizeOnce: Unexpected model type\");\n            }\n        });\n    }\n    /**\n     * Included for compatibility\n     * @member SpeakerRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    // Does class setup, swiped from Recognizer.\n    implSRSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeakerRecognitionConfig\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OS\"](osPlatform, osName, osVersion)), this.privProperties);\n        this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeakerIdMessageAdapter\"](recognizerConfig);\n    }\n    getResult(responsePromise, resultType, profileId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const response = yield responsePromise;\n            return new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeakerRecognitionResult\"](resultType, response.data, profileId, response.ok ? _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].RecognizedSpeaker : _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled);\n        });\n    }\n}\n\n//# sourceMappingURL=SpeakerRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeakerVerificationModel */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeakerVerificationModel\", function() { return SpeakerVerificationModel; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Defines SpeakerVerificationModel class for Speaker Recognition\n * Model contains a profile against which to verify a speaker\n * @class SpeakerVerificationModel\n */\nclass SpeakerVerificationModel {\n    constructor(profile) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(profile, \"VoiceProfile\");\n        if (profile.profileType === _Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileType\"].TextIndependentIdentification) {\n            throw new Error(\"Verification model cannot be created from Identification profile\");\n        }\n        this.privVoiceProfile = profile;\n    }\n    static fromProfile(profile) {\n        return new SpeakerVerificationModel(profile);\n    }\n    get voiceProfile() {\n        return this.privVoiceProfile;\n    }\n}\n\n//# sourceMappingURL=SpeakerVerificationModel.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js ***!
  \****************************************************************************************************/
/*! exports provided: SpeechConfig, SpeechConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfig\", function() { return SpeechConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechConfigImpl\", function() { return SpeechConfigImpl; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Speech configuration.\n * @class SpeechConfig\n */\nclass SpeechConfig {\n    /**\n     * Creates and initializes an instance.\n     * @constructor\n     */\n    constructor() {\n        return;\n    }\n    /**\n     * Static instance of SpeechConfig returned by passing subscriptionKey and service region.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * @member SpeechConfig.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - The subscription key.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} The speech factory\n     */\n    static fromSubscription(subscriptionKey, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_IntentRegion, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified endpoint and subscription key.\n     * This method is intended only for users who use a non-standard service endpoint or parameters.\n     * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n     * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n     * For example, if language is defined in the uri as query parameter \"language=de-DE\", and also set by\n     * SpeechConfig.speechRecognitionLanguage = \"en-US\", the language setting in uri takes precedence,\n     * and the effective language is \"de-DE\". Only the parameters that are not specified in the\n     * endpoint URL can be set by other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n     * use the authorization token.\n     * @member SpeechConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(endpoint, \"endpoint\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint, endpoint.href);\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech config with specified host and subscription key.\n     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL),\n     * and then set the AuthorizationToken property on the created SpeechConfig instance.\n     * Note: Added in version 1.9.0.\n     * @member SpeechConfig.fromHost\n     * @function\n     * @public\n     * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromHost(hostName, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(hostName, \"hostName\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech factory with specified initial authorization token and region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by calling this setter with a new valid token.\n     * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want\n     * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,\n     * the new token value will not apply to recognizers that have already been created. For recognizers\n     * that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member SpeechConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param {string} authorizationToken - The initial authorization token.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromAuthorizationToken(authorizationToken, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(authorizationToken, \"authorizationToken\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const speechImpl = new SpeechConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_IntentRegion, region);\n        speechImpl.authorizationToken = authorizationToken;\n        return speechImpl;\n    }\n    /**\n     * Closes the configuration.\n     * @member SpeechConfig.prototype.close\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    close() { }\n}\n/**\n * @public\n * @class SpeechConfigImpl\n */\nclass SpeechConfigImpl extends SpeechConfig {\n    constructor() {\n        super();\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        this.speechRecognitionLanguage = \"en-US\"; // Should we have a default?\n        this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"].Simple;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get endPoint() {\n        return new URL(this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint));\n    }\n    get subscriptionKey() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key);\n    }\n    get region() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region);\n    }\n    get authorizationToken() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    set authorizationToken(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, value);\n    }\n    get speechRecognitionLanguage() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    set speechRecognitionLanguage(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, value);\n    }\n    get autoDetectSourceLanguages() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages);\n    }\n    set autoDetectSourceLanguages(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages, value);\n    }\n    get outputFormat() {\n        return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormatPropertyName\"], undefined)];\n    }\n    set outputFormat(value) {\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormatPropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][value]);\n    }\n    get endpointId() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId);\n    }\n    set endpointId(value) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId, value);\n    }\n    setProperty(name, value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(value, \"value\");\n        this.privProperties.setProperty(name, value);\n    }\n    getProperty(name, def) {\n        return this.privProperties.getProperty(name, def);\n    }\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyHostName], proxyHostName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyPort], proxyPort);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyUserName], proxyUserName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyPassword], proxyPassword);\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServicePropertiesPropertyName\"], \"{}\"));\n        currentProperties[name] = value;\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServicePropertiesPropertyName\"], JSON.stringify(currentProperties));\n    }\n    setProfanity(profanity) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ProfanityOption\"][profanity]);\n    }\n    enableAudioLogging() {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EnableAudioLogging, \"true\");\n    }\n    requestWordLevelTimestamps() {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n    }\n    enableDictation() {\n        this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ForceDictationPropertyName\"], \"true\");\n    }\n    clone() {\n        const ret = new SpeechConfigImpl();\n        ret.privProperties = this.privProperties.clone();\n        return ret;\n    }\n    get speechSynthesisLanguage() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthLanguage);\n    }\n    set speechSynthesisLanguage(language) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthLanguage, language);\n    }\n    get speechSynthesisVoiceName() {\n        return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthVoice);\n    }\n    set speechSynthesisVoiceName(voice) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthVoice, voice);\n    }\n    get speechSynthesisOutputFormat() {\n        return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisOutputFormat\"][this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, undefined)];\n    }\n    set speechSynthesisOutputFormat(format) {\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisOutputFormat\"][format]);\n    }\n}\n\n//# sourceMappingURL=SpeechConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/*! exports provided: SpeechRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionCanceledEventArgs\", function() { return SpeechRecognitionCanceledEventArgs; });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeechRecognitionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__[\"CancellationEventArgsBase\"] {\n}\n\n//# sourceMappingURL=SpeechRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/*! exports provided: SpeechRecognitionEventArgs, ConversationTranscriptionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionEventArgs\", function() { return SpeechRecognitionEventArgs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriptionEventArgs\", function() { return ConversationTranscriptionEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n/**\n * Defines contents of speech recognizing/recognized event.\n * @class SpeechRecognitionEventArgs\n */\nclass SpeechRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechRecognitionResult} result - The speech recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member SpeechRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n/**\n * Defines contents of conversation transcribed/transcribing event.\n * @class ConversationTranscriptionEventArgs\n */\nclass ConversationTranscriptionEventArgs extends SpeechRecognitionEventArgs {\n}\n\n//# sourceMappingURL=SpeechRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognitionResult\", function() { return SpeechRecognitionResult; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech recognition.\n * @class SpeechRecognitionResult\n */\nclass SpeechRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionResult\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @public\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} language - Primary Language detected, if provided.\n     * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n     * @param {string} speakerId - speaker id for conversation transcription, if provided.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);\n        this.privSpeakerId = speakerId;\n    }\n    /**\n     * speaker id from conversation transcription/id scenarios\n     * @member SpeechRecognitionResult.prototype.speakerId\n     * @function\n     * @public\n     * @returns {string} id of speaker in given result\n     */\n    get speakerId() {\n        return this.privSpeakerId;\n    }\n}\n\n//# sourceMappingURL=SpeechRecognitionResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js ***!
  \********************************************************************************************************/
/*! exports provided: SpeechRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechRecognizer\", function() { return SpeechRecognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n/**\n * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.\n * @class SpeechRecognizer\n */\nclass SpeechRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__[\"Recognizer\"] {\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(speechConfigImpl, \"speechConfig\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n        super(audioConfig, speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechConnectionFactory\"]());\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * SpeechRecognizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        const recognizer = new SpeechRecognizer(speechConfig, audioConfig);\n        return recognizer;\n    }\n    /**\n     * Gets the endpoint id of a customized speech model that is used for speech recognition.\n     * @member SpeechRecognizer.prototype.endpointId\n     * @function\n     * @public\n     * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.\n     */\n    get endpointId() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_EndpointId, \"00000000-0000-0000-0000-000000000000\");\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeechRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member SpeechRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets the output format of recognition.\n     * @member SpeechRecognizer.prototype.outputFormat\n     * @function\n     * @public\n     * @returns {OutputFormat} The output format of recognition.\n     */\n    get outputFormat() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        if (this.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormatPropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"].Simple]) === _Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"].Simple]) {\n            return _Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"].Simple;\n        }\n        else {\n            return _Exports__WEBPACK_IMPORTED_MODULE_3__[\"OutputFormat\"].Detailed;\n        }\n    }\n    /**\n     * The collection of properties and their values defined for this SpeechRecognizer.\n     * @member SpeechRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Starts speech recognition, and stops after the first utterance is recognized.\n     * The task returns the recognition text as result.\n     * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n     * so it is suitable only for single shot recognition\n     * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.\n     * @member SpeechRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the SpeechRecognitionResult.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Interactive), cb, err);\n    }\n    /**\n     * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Conversation), cb, err);\n    }\n    /**\n     * Stops continuous speech recognition.\n     * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * Starts speech recognition with keyword spotting, until\n     * stopKeywordRecognitionAsync() is called.\n     * User must subscribe to events to receive recognition results.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param {KeywordRecognitionModel} model The keyword recognition model that\n     * specifies the keyword to be recognized.\n     * @param cb - Callback invoked once the recognition has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startKeywordRecognitionAsync(model, cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(model, \"model\");\n        if (!!err) {\n            err(\"Not yet implemented.\");\n        }\n    }\n    /**\n     * Stops continuous speech recognition.\n     * Note: Key word spotting functionality is only available on the\n     * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n     * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the recognition has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopKeywordRecognitionAsync(cb) {\n        if (!!cb) {\n            cb();\n        }\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member SpeechRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member SpeechRecognizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedRecognizer) {\n                return;\n            }\n            if (disposing) {\n                this.privDisposedRecognizer = true;\n                yield this.implRecognizerStop();\n            }\n            yield _super.dispose.call(this, disposing);\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognizerConfig\"](speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechServiceRecognizer\"](authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n}\n\n//# sourceMappingURL=SpeechRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \************************************************************************************************************************/
/*! exports provided: SpeechSynthesisBookmarkEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBookmarkEventArgs\", function() { return SpeechSynthesisBookmarkEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis bookmark event.\n * @class SpeechSynthesisBookmarkEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisBookmarkEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {string} text - The bookmark text.\n     */\n    constructor(audioOffset, text) {\n        this.privAudioOffset = audioOffset;\n        this.privText = text;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the bookmark.\n     * @member SpeechSynthesisBookmarkEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the bookmark text.\n     */\n    get text() {\n        return this.privText;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisBookmarkEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SpeechSynthesisBoundaryType */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisBoundaryType\", function() { return SpeechSynthesisBoundaryType; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the boundary type of speech synthesis boundary event.\n * @class SpeechSynthesisBoundaryType\n * Added in version 1.21.0\n */\nvar SpeechSynthesisBoundaryType;\n(function (SpeechSynthesisBoundaryType) {\n    /**\n     * Indicates the boundary text is a word.\n     * @member SpeechSynthesisBoundaryType.Word\n     */\n    SpeechSynthesisBoundaryType[\"Word\"] = \"WordBoundary\";\n    /**\n     * Indicates the boundary text is a punctuation.\n     * @member SpeechSynthesisBoundaryType.Punctuation\n     */\n    SpeechSynthesisBoundaryType[\"Punctuation\"] = \"PunctuationBoundary\";\n    /**\n     * Indicates the boundary text is a sentence.\n     * @member SpeechSynthesisBoundaryType.Sentence\n     */\n    SpeechSynthesisBoundaryType[\"Sentence\"] = \"SentenceBoundary\";\n})(SpeechSynthesisBoundaryType || (SpeechSynthesisBoundaryType = {}));\n\n//# sourceMappingURL=SpeechSynthesisBoundaryType.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js ***!
  \****************************************************************************************************************/
/*! exports provided: SpeechSynthesisEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisEventArgs\", function() { return SpeechSynthesisEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis events.\n * @class SpeechSynthesisEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {SpeechSynthesisResult} result - The speech synthesis result.\n     */\n    constructor(result) {\n        this.privResult = result;\n    }\n    /**\n     * Specifies the synthesis result.\n     * @member SpeechSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {SpeechSynthesisResult} the synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \*******************************************************************************************************************/
/*! exports provided: SpeechSynthesisOutputFormat */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisOutputFormat\", function() { return SpeechSynthesisOutputFormat; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define speech synthesis audio output formats.\n * @enum SpeechSynthesisOutputFormat\n * Updated in version 1.17.0\n */\nvar SpeechSynthesisOutputFormat;\n(function (SpeechSynthesisOutputFormat) {\n    /**\n     * raw-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoMULaw\"] = 0] = \"Raw8Khz8BitMonoMULaw\";\n    /**\n     * riff-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16KbpsMonoSiren\"] = 1] = \"Riff16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-16kbps-mono-siren\n     * @note Unsupported by the service. Do not use this value.\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16KbpsMonoSiren\"] = 2] = \"Audio16Khz16KbpsMonoSiren\";\n    /**\n     * audio-16khz-32kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz32KBitRateMonoMp3\"] = 3] = \"Audio16Khz32KBitRateMonoMp3\";\n    /**\n     * audio-16khz-128kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz128KBitRateMonoMp3\"] = 4] = \"Audio16Khz128KBitRateMonoMp3\";\n    /**\n     * audio-16khz-64kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz64KBitRateMonoMp3\"] = 5] = \"Audio16Khz64KBitRateMonoMp3\";\n    /**\n     * audio-24khz-48kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz48KBitRateMonoMp3\"] = 6] = \"Audio24Khz48KBitRateMonoMp3\";\n    /**\n     * audio-24khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz96KBitRateMonoMp3\"] = 7] = \"Audio24Khz96KBitRateMonoMp3\";\n    /**\n     * audio-24khz-160kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz160KBitRateMonoMp3\"] = 8] = \"Audio24Khz160KBitRateMonoMp3\";\n    /**\n     * raw-16khz-16bit-mono-truesilk\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoTrueSilk\"] = 9] = \"Raw16Khz16BitMonoTrueSilk\";\n    /**\n     * riff-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16BitMonoPcm\"] = 10] = \"Riff16Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz16BitMonoPcm\"] = 11] = \"Riff8Khz16BitMonoPcm\";\n    /**\n     * riff-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff24Khz16BitMonoPcm\"] = 12] = \"Riff24Khz16BitMonoPcm\";\n    /**\n     * riff-8khz-8bit-mono-mulaw\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoMULaw\"] = 13] = \"Riff8Khz8BitMonoMULaw\";\n    /**\n     * raw-16khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoPcm\"] = 14] = \"Raw16Khz16BitMonoPcm\";\n    /**\n     * raw-24khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoPcm\"] = 15] = \"Raw24Khz16BitMonoPcm\";\n    /**\n     * raw-8khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz16BitMonoPcm\"] = 16] = \"Raw8Khz16BitMonoPcm\";\n    /**\n     * ogg-16khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg16Khz16BitMonoOpus\"] = 17] = \"Ogg16Khz16BitMonoOpus\";\n    /**\n     * ogg-24khz-16bit-mono-opus\n     * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg24Khz16BitMonoOpus\"] = 18] = \"Ogg24Khz16BitMonoOpus\";\n    /**\n     * raw-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw48Khz16BitMonoPcm\"] = 19] = \"Raw48Khz16BitMonoPcm\";\n    /**\n     * riff-48khz-16bit-mono-pcm\n     * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff48Khz16BitMonoPcm\"] = 20] = \"Riff48Khz16BitMonoPcm\";\n    /**\n     * audio-48khz-96kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz96KBitRateMonoMp3\"] = 21] = \"Audio48Khz96KBitRateMonoMp3\";\n    /**\n     * audio-48khz-192kbitrate-mono-mp3\n     * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz192KBitRateMonoMp3\"] = 22] = \"Audio48Khz192KBitRateMonoMp3\";\n    /**\n     * ogg-48khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg48Khz16BitMonoOpus\"] = 23] = \"Ogg48Khz16BitMonoOpus\";\n    /**\n     * webm-16khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm16Khz16BitMonoOpus\"] = 24] = \"Webm16Khz16BitMonoOpus\";\n    /**\n     * webm-24khz-16bit-mono-opus\n     * Added in version 1.16.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16BitMonoOpus\"] = 25] = \"Webm24Khz16BitMonoOpus\";\n    /**\n     * raw-24khz-16bit-mono-truesilk\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoTrueSilk\"] = 26] = \"Raw24Khz16BitMonoTrueSilk\";\n    /**\n     * raw-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoALaw\"] = 27] = \"Raw8Khz8BitMonoALaw\";\n    /**\n     * riff-8khz-8bit-mono-alaw\n     * Added in version 1.17.0\n     * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoALaw\"] = 28] = \"Riff8Khz8BitMonoALaw\";\n    /**\n     * webm-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.\n     * Added in version 1.19.0\n     * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16Bit24KbpsMonoOpus\"] = 29] = \"Webm24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * audio-16khz-16bit-32kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 32kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16Bit32KbpsMonoOpus\"] = 30] = \"Audio16Khz16Bit32KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-48kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 48kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit48KbpsMonoOpus\"] = 31] = \"Audio24Khz16Bit48KbpsMonoOpus\";\n    /**\n     * audio-24khz-16bit-24kbps-mono-opus\n     * Audio compressed by OPUS codec without container, with bitrate of 24kbps.\n     * Added in version 1.20.0\n     * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit24KbpsMonoOpus\"] = 32] = \"Audio24Khz16Bit24KbpsMonoOpus\";\n    /**\n     * raw-22050hz-16bit-mono-pcm\n     * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw22050Hz16BitMonoPcm\"] = 33] = \"Raw22050Hz16BitMonoPcm\";\n    /**\n     * riff-22050hz-16bit-mono-pcm\n     * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff22050Hz16BitMonoPcm\"] = 34] = \"Riff22050Hz16BitMonoPcm\";\n    /**\n     * raw-44100hz-16bit-mono-pcm\n     * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw44100Hz16BitMonoPcm\"] = 35] = \"Raw44100Hz16BitMonoPcm\";\n    /**\n     * riff-44100hz-16bit-mono-pcm\n     * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.\n     * Added in version 1.22.0\n     * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm\n     */\n    SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff44100Hz16BitMonoPcm\"] = 36] = \"Riff44100Hz16BitMonoPcm\";\n})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));\n\n//# sourceMappingURL=SpeechSynthesisOutputFormat.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js ***!
  \*************************************************************************************************************/
/*! exports provided: SpeechSynthesisResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisResult\", function() { return SpeechSynthesisResult; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech synthesis.\n * @class SpeechSynthesisResult\n * Added in version 1.11.0\n */\nclass SpeechSynthesisResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisResult\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {ArrayBuffer} audioData - The synthesized audio binary.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     * @param {number} audioDuration - The audio duration.\n     */\n    constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {\n        super(resultId, reason, errorDetails, properties);\n        this.privAudioData = audioData;\n        this.privAudioDuration = audioDuration;\n    }\n    /**\n     * The synthesized audio data\n     * @member SpeechSynthesisResult.prototype.audioData\n     * @function\n     * @public\n     * @returns {ArrayBuffer} The synthesized audio data.\n     */\n    get audioData() {\n        return this.privAudioData;\n    }\n    /**\n     * The time duration of synthesized audio, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisResult.prototype.audioDuration\n     * @function\n     * @public\n     * @returns {number} The time duration of synthesized audio.\n     */\n    get audioDuration() {\n        return this.privAudioDuration;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \**********************************************************************************************************************/
/*! exports provided: SpeechSynthesisVisemeEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisVisemeEventArgs\", function() { return SpeechSynthesisVisemeEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis viseme event.\n * @class SpeechSynthesisVisemeEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisVisemeEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} visemeId - The viseme ID.\n     * @param {string} animation - The animation, could be in svg or other format.\n     */\n    constructor(audioOffset, visemeId, animation) {\n        this.privAudioOffset = audioOffset;\n        this.privVisemeId = visemeId;\n        this.privAnimation = animation;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the viseme ID.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId\n     * @function\n     * @public\n     * @returns {number} the viseme ID.\n     */\n    get visemeId() {\n        return this.privVisemeId;\n    }\n    /**\n     * Specifies the animation.\n     * @member SpeechSynthesisVisemeEventArgs.prototype.animation\n     * @function\n     * @public\n     * @returns {string} the animation, could be in svg or other format.\n     */\n    get animation() {\n        return this.privAnimation;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisVisemeEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \****************************************************************************************************************************/
/*! exports provided: SpeechSynthesisWordBoundaryEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesisWordBoundaryEventArgs\", function() { return SpeechSynthesisWordBoundaryEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis word boundary event.\n * @class SpeechSynthesisWordBoundaryEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisWordBoundaryEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {number} audioOffset - The audio offset.\n     * @param {number} duration - The audio duration.\n     * @param {string} text - The text.\n     * @param {number} wordLength - The length of the word.\n     * @param {number} textOffset - The text offset.\n     * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type\n     */\n    constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {\n        this.privAudioOffset = audioOffset;\n        this.privDuration = duration;\n        this.privText = text;\n        this.privWordLength = wordLength;\n        this.privTextOffset = textOffset;\n        this.privBoundaryType = boundaryType;\n    }\n    /**\n     * Specifies the audio offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset\n     * @function\n     * @public\n     * @returns {number} the audio offset.\n     */\n    get audioOffset() {\n        return this.privAudioOffset;\n    }\n    /**\n     * Specifies the duration, in ticks (100 nanoseconds).\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration\n     * @function\n     * @public\n     * @returns {number} Duration in 100 nanosecond increments.\n     */\n    get duration() {\n        return this.privDuration;\n    }\n    /**\n     * Specifies the text of the word boundary event.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text\n     * @function\n     * @public\n     * @returns {string} the text.\n     */\n    get text() {\n        return this.privText;\n    }\n    /**\n     * Specifies the word length\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength\n     * @function\n     * @public\n     * @returns {number} the word length\n     */\n    get wordLength() {\n        return this.privWordLength;\n    }\n    /**\n     * Specifies the text offset.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset\n     * @function\n     * @public\n     * @returns {number} the text offset.\n     */\n    get textOffset() {\n        return this.privTextOffset;\n    }\n    /**\n     * Specifies the boundary type.\n     * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType\n     * @function\n     * @public\n     * @returns {SpeechSynthesisBoundaryType} the boundary type.\n     */\n    get boundaryType() {\n        return this.privBoundaryType;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesisWordBoundaryEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js ***!
  \*********************************************************************************************************/
/*! exports provided: SpeechSynthesizer, SynthesisRequest */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechSynthesizer\", function() { return SpeechSynthesizer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisRequest\", function() { return SynthesisRequest; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioFileWriter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js\");\n/* harmony import */ var _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* eslint-disable @typescript-eslint/no-empty-function */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n/**\n * Defines the class SpeechSynthesizer for text to speech.\n * Updated in version 1.16.0\n * @class SpeechSynthesizer\n */\nclass SpeechSynthesizer {\n    /**\n     * SpeechSynthesizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.\n     */\n    constructor(speechConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_5__[\"Contracts\"].throwIfNull(speechConfigImpl, \"speechConfig\");\n        if (audioConfig !== null) {\n            if (audioConfig === undefined) {\n                this.audioConfig = (typeof window === \"undefined\") ? undefined : _Exports__WEBPACK_IMPORTED_MODULE_6__[\"AudioConfig\"].fromDefaultSpeakerOutput();\n            }\n            else {\n                this.audioConfig = audioConfig;\n            }\n        }\n        this.privProperties = speechConfigImpl.properties.clone();\n        this.privDisposed = false;\n        this.privSynthesizing = false;\n        this.privConnectionFactory = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechSynthesisConnectionFactory\"]();\n        this.synthesisRequestQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"Queue\"]();\n        this.implCommonSynthesizeSetup();\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member SpeechSynthesizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member SpeechSynthesizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_5__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * The collection of properties and their values defined for this SpeechSynthesizer.\n     * @member SpeechSynthesizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Indicates if auto detect source language is enabled\n     * @member SpeechSynthesizer.prototype.properties\n     * @function\n     * @public\n     * @returns {boolean} if auto detect source language is enabled\n     */\n    get autoDetectSourceLanguage() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceConnection_AutoDetectSourceLanguages) === _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"AutoDetectSourceLanguagesOpenRangeOptionName\"];\n    }\n    /**\n     * SpeechSynthesizer constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer\n     * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer\n     */\n    static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n        const speechConfigImpl = speechConfig;\n        autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n        return new SpeechSynthesizer(speechConfig, audioConfig);\n    }\n    buildSsml(text) {\n        const languageToDefaultVoice = {\n            [\"af-ZA\"]: \"af-ZA-AdriNeural\",\n            [\"am-ET\"]: \"am-ET-AmehaNeural\",\n            [\"ar-AE\"]: \"ar-AE-FatimaNeural\",\n            [\"ar-BH\"]: \"ar-BH-AliNeural\",\n            [\"ar-DZ\"]: \"ar-DZ-AminaNeural\",\n            [\"ar-EG\"]: \"ar-EG-SalmaNeural\",\n            [\"ar-IQ\"]: \"ar-IQ-BasselNeural\",\n            [\"ar-JO\"]: \"ar-JO-SanaNeural\",\n            [\"ar-KW\"]: \"ar-KW-FahedNeural\",\n            [\"ar-LY\"]: \"ar-LY-ImanNeural\",\n            [\"ar-MA\"]: \"ar-MA-JamalNeural\",\n            [\"ar-QA\"]: \"ar-QA-AmalNeural\",\n            [\"ar-SA\"]: \"ar-SA-HamedNeural\",\n            [\"ar-SY\"]: \"ar-SY-AmanyNeural\",\n            [\"ar-TN\"]: \"ar-TN-HediNeural\",\n            [\"ar-YE\"]: \"ar-YE-MaryamNeural\",\n            [\"bg-BG\"]: \"bg-BG-BorislavNeural\",\n            [\"bn-BD\"]: \"bn-BD-NabanitaNeural\",\n            [\"bn-IN\"]: \"bn-IN-BashkarNeural\",\n            [\"ca-ES\"]: \"ca-ES-JoanaNeural\",\n            [\"cs-CZ\"]: \"cs-CZ-AntoninNeural\",\n            [\"cy-GB\"]: \"cy-GB-AledNeural\",\n            [\"da-DK\"]: \"da-DK-ChristelNeural\",\n            [\"de-AT\"]: \"de-AT-IngridNeural\",\n            [\"de-CH\"]: \"de-CH-JanNeural\",\n            [\"de-DE\"]: \"de-DE-KatjaNeural\",\n            [\"el-GR\"]: \"el-GR-AthinaNeural\",\n            [\"en-AU\"]: \"en-AU-NatashaNeural\",\n            [\"en-CA\"]: \"en-CA-ClaraNeural\",\n            [\"en-GB\"]: \"en-GB-LibbyNeural\",\n            [\"en-HK\"]: \"en-HK-SamNeural\",\n            [\"en-IE\"]: \"en-IE-ConnorNeural\",\n            [\"en-IN\"]: \"en-IN-NeerjaNeural\",\n            [\"en-KE\"]: \"en-KE-AsiliaNeural\",\n            [\"en-NG\"]: \"en-NG-AbeoNeural\",\n            [\"en-NZ\"]: \"en-NZ-MitchellNeural\",\n            [\"en-PH\"]: \"en-PH-JamesNeural\",\n            [\"en-SG\"]: \"en-SG-LunaNeural\",\n            [\"en-TZ\"]: \"en-TZ-ElimuNeural\",\n            [\"en-US\"]: \"en-US-JennyNeural\",\n            [\"en-ZA\"]: \"en-ZA-LeahNeural\",\n            [\"es-AR\"]: \"es-AR-ElenaNeural\",\n            [\"es-BO\"]: \"es-BO-MarceloNeural\",\n            [\"es-CL\"]: \"es-CL-CatalinaNeural\",\n            [\"es-CO\"]: \"es-CO-GonzaloNeural\",\n            [\"es-CR\"]: \"es-CR-JuanNeural\",\n            [\"es-CU\"]: \"es-CU-BelkysNeural\",\n            [\"es-DO\"]: \"es-DO-EmilioNeural\",\n            [\"es-EC\"]: \"es-EC-AndreaNeural\",\n            [\"es-ES\"]: \"es-ES-AlvaroNeural\",\n            [\"es-GQ\"]: \"es-GQ-JavierNeural\",\n            [\"es-GT\"]: \"es-GT-AndresNeural\",\n            [\"es-HN\"]: \"es-HN-CarlosNeural\",\n            [\"es-MX\"]: \"es-MX-DaliaNeural\",\n            [\"es-NI\"]: \"es-NI-FedericoNeural\",\n            [\"es-PA\"]: \"es-PA-MargaritaNeural\",\n            [\"es-PE\"]: \"es-PE-AlexNeural\",\n            [\"es-PR\"]: \"es-PR-KarinaNeural\",\n            [\"es-PY\"]: \"es-PY-MarioNeural\",\n            [\"es-SV\"]: \"es-SV-LorenaNeural\",\n            [\"es-US\"]: \"es-US-AlonsoNeural\",\n            [\"es-UY\"]: \"es-UY-MateoNeural\",\n            [\"es-VE\"]: \"es-VE-PaolaNeural\",\n            [\"et-EE\"]: \"et-EE-AnuNeural\",\n            [\"fa-IR\"]: \"fa-IR-DilaraNeural\",\n            [\"fi-FI\"]: \"fi-FI-SelmaNeural\",\n            [\"fil-PH\"]: \"fil-PH-AngeloNeural\",\n            [\"fr-BE\"]: \"fr-BE-CharlineNeural\",\n            [\"fr-CA\"]: \"fr-CA-SylvieNeural\",\n            [\"fr-CH\"]: \"fr-CH-ArianeNeural\",\n            [\"fr-FR\"]: \"fr-FR-DeniseNeural\",\n            [\"ga-IE\"]: \"ga-IE-ColmNeural\",\n            [\"gl-ES\"]: \"gl-ES-RoiNeural\",\n            [\"gu-IN\"]: \"gu-IN-DhwaniNeural\",\n            [\"he-IL\"]: \"he-IL-AvriNeural\",\n            [\"hi-IN\"]: \"hi-IN-MadhurNeural\",\n            [\"hr-HR\"]: \"hr-HR-GabrijelaNeural\",\n            [\"hu-HU\"]: \"hu-HU-NoemiNeural\",\n            [\"id-ID\"]: \"id-ID-ArdiNeural\",\n            [\"is-IS\"]: \"is-IS-GudrunNeural\",\n            [\"it-IT\"]: \"it-IT-IsabellaNeural\",\n            [\"ja-JP\"]: \"ja-JP-NanamiNeural\",\n            [\"jv-ID\"]: \"jv-ID-DimasNeural\",\n            [\"kk-KZ\"]: \"kk-KZ-AigulNeural\",\n            [\"km-KH\"]: \"km-KH-PisethNeural\",\n            [\"kn-IN\"]: \"kn-IN-GaganNeural\",\n            [\"ko-KR\"]: \"ko-KR-SunHiNeural\",\n            [\"lo-LA\"]: \"lo-LA-ChanthavongNeural\",\n            [\"lt-LT\"]: \"lt-LT-LeonasNeural\",\n            [\"lv-LV\"]: \"lv-LV-EveritaNeural\",\n            [\"mk-MK\"]: \"mk-MK-AleksandarNeural\",\n            [\"ml-IN\"]: \"ml-IN-MidhunNeural\",\n            [\"mr-IN\"]: \"mr-IN-AarohiNeural\",\n            [\"ms-MY\"]: \"ms-MY-OsmanNeural\",\n            [\"mt-MT\"]: \"mt-MT-GraceNeural\",\n            [\"my-MM\"]: \"my-MM-NilarNeural\",\n            [\"nb-NO\"]: \"nb-NO-PernilleNeural\",\n            [\"nl-BE\"]: \"nl-BE-ArnaudNeural\",\n            [\"nl-NL\"]: \"nl-NL-ColetteNeural\",\n            [\"pl-PL\"]: \"pl-PL-AgnieszkaNeural\",\n            [\"ps-AF\"]: \"ps-AF-GulNawazNeural\",\n            [\"pt-BR\"]: \"pt-BR-FranciscaNeural\",\n            [\"pt-PT\"]: \"pt-PT-DuarteNeural\",\n            [\"ro-RO\"]: \"ro-RO-AlinaNeural\",\n            [\"ru-RU\"]: \"ru-RU-SvetlanaNeural\",\n            [\"si-LK\"]: \"si-LK-SameeraNeural\",\n            [\"sk-SK\"]: \"sk-SK-LukasNeural\",\n            [\"sl-SI\"]: \"sl-SI-PetraNeural\",\n            [\"so-SO\"]: \"so-SO-MuuseNeural\",\n            [\"sr-RS\"]: \"sr-RS-NicholasNeural\",\n            [\"su-ID\"]: \"su-ID-JajangNeural\",\n            [\"sv-SE\"]: \"sv-SE-SofieNeural\",\n            [\"sw-KE\"]: \"sw-KE-RafikiNeural\",\n            [\"sw-TZ\"]: \"sw-TZ-DaudiNeural\",\n            [\"ta-IN\"]: \"ta-IN-PallaviNeural\",\n            [\"ta-LK\"]: \"ta-LK-KumarNeural\",\n            [\"ta-SG\"]: \"ta-SG-AnbuNeural\",\n            [\"te-IN\"]: \"te-IN-MohanNeural\",\n            [\"th-TH\"]: \"th-TH-PremwadeeNeural\",\n            [\"tr-TR\"]: \"tr-TR-AhmetNeural\",\n            [\"uk-UA\"]: \"uk-UA-OstapNeural\",\n            [\"ur-IN\"]: \"ur-IN-GulNeural\",\n            [\"ur-PK\"]: \"ur-PK-AsadNeural\",\n            [\"uz-UZ\"]: \"uz-UZ-MadinaNeural\",\n            [\"vi-VN\"]: \"vi-VN-HoaiMyNeural\",\n            [\"zh-CN\"]: \"zh-CN-XiaoxiaoNeural\",\n            [\"zh-HK\"]: \"zh-HK-HiuMaanNeural\",\n            [\"zh-TW\"]: \"zh-TW-HsiaoChenNeural\",\n            [\"zu-ZA\"]: \"zu-ZA-ThandoNeural\",\n        };\n        let language = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceConnection_SynthLanguage, \"en-US\");\n        let voice = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceConnection_SynthVoice, \"\");\n        let ssml = SpeechSynthesizer.XMLEncode(text);\n        if (this.autoDetectSourceLanguage) {\n            language = \"en-US\";\n        }\n        else {\n            voice = voice || languageToDefaultVoice[language];\n        }\n        if (voice) {\n            ssml = `<voice name='${voice}'>${ssml}</voice>`;\n        }\n        ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;\n        return ssml;\n    }\n    /**\n     * Executes speech synthesis on plain text.\n     * The task returns the synthesis result.\n     * @member SpeechSynthesizer.prototype.speakTextAsync\n     * @function\n     * @public\n     * @param text - Text to be synthesized.\n     * @param cb - Callback that received the SpeechSynthesisResult.\n     * @param err - Callback invoked in case of an error.\n     * @param stream - AudioOutputStream to receive the synthesized audio.\n     */\n    speakTextAsync(text, cb, err, stream) {\n        this.speakImpl(text, false, cb, err, stream);\n    }\n    /**\n     * Executes speech synthesis on SSML.\n     * The task returns the synthesis result.\n     * @member SpeechSynthesizer.prototype.speakSsmlAsync\n     * @function\n     * @public\n     * @param ssml - SSML to be synthesized.\n     * @param cb - Callback that received the SpeechSynthesisResult.\n     * @param err - Callback invoked in case of an error.\n     * @param stream - AudioOutputStream to receive the synthesized audio.\n     */\n    speakSsmlAsync(ssml, cb, err, stream) {\n        this.speakImpl(ssml, true, cb, err, stream);\n    }\n    /**\n     * Get list of synthesis voices available.\n     * The task returns the synthesis voice result.\n     * @member SpeechSynthesizer.prototype.getVoicesAsync\n     * @function\n     * @async\n     * @public\n     * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.\n     * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.\n     */\n    getVoicesAsync(locale = \"\") {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.getVoices(locale);\n        });\n    }\n    /**\n     * Dispose of associated resources.\n     * @member SpeechSynthesizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_5__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, err);\n    }\n    /**\n     * @Internal\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privAdapter;\n    }\n    /**\n     * This method performs cleanup of resources.\n     * The Boolean parameter disposing indicates whether the method is called\n     * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n     * Derived classes should override this method to dispose resource if needed.\n     * @member SpeechSynthesizer.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - Flag to request disposal.\n     */\n    dispose(disposing) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposed) {\n                return;\n            }\n            if (disposing) {\n                if (this.privAdapter) {\n                    yield this.privAdapter.dispose();\n                }\n            }\n            this.privDisposed = true;\n        });\n    }\n    //\n    // ################################################################################################################\n    // IMPLEMENTATION.\n    // Move to independent class\n    // ################################################################################################################\n    //\n    createSynthesizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesizerConfig\"](speechConfig, this.privProperties);\n    }\n    // Creates the synthesis adapter\n    createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisAdapterBase\"](authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);\n    }\n    implCommonSynthesizeSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const synthesizerConfig = this.createSynthesizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechServiceConfig\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OS\"](osPlatform, osName, osVersion))));\n        const subscriptionKey = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceConnection_Key, undefined);\n        const authentication = (subscriptionKey && subscriptionKey !== \"\") ?\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CognitiveSubscriptionKeyAuthentication\"](subscriptionKey) :\n            new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CognitiveTokenAuthentication\"](() => {\n                const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            }, () => {\n                const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceAuthorization_Token, undefined);\n                return Promise.resolve(authorizationToken);\n            });\n        this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);\n        this.privAdapter.audioOutputFormat = _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_3__[\"AudioOutputFormatImpl\"].fromSpeechSynthesisOutputFormat(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"SpeechSynthesisOutputFormat\"][this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_6__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, undefined)]);\n        this.privRestAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisRestAdapter\"](synthesizerConfig, authentication);\n    }\n    speakImpl(text, IsSsml, cb, err, dataStream) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_5__[\"Contracts\"].throwIfDisposed(this.privDisposed);\n            const requestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n            let audioDestination;\n            if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_6__[\"PushAudioOutputStreamCallback\"]) {\n                audioDestination = new _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_4__[\"PushAudioOutputStreamImpl\"](dataStream);\n            }\n            else if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_6__[\"PullAudioOutputStream\"]) {\n                audioDestination = dataStream;\n            }\n            else if (dataStream !== undefined) {\n                audioDestination = new _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_2__[\"AudioFileWriter\"](dataStream);\n            }\n            else {\n                audioDestination = undefined;\n            }\n            this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, (e) => {\n                this.privSynthesizing = false;\n                if (!!cb) {\n                    try {\n                        cb(e);\n                    }\n                    catch (e) {\n                        if (!!err) {\n                            err(e);\n                        }\n                    }\n                }\n                cb = undefined;\n                /* eslint-disable no-empty */\n                this.adapterSpeak().catch(() => { });\n            }, (e) => {\n                if (!!err) {\n                    err(e);\n                }\n            }, audioDestination));\n            /* eslint-disable no-empty-function */\n            this.adapterSpeak().catch(() => { });\n        }\n        catch (error) {\n            if (!!err) {\n                if (error instanceof Error) {\n                    const typedError = error;\n                    err(typedError.name + \": \" + typedError.message);\n                }\n                else {\n                    err(error);\n                }\n            }\n            // Destroy the synthesizer.\n            /* eslint-disable no-empty */\n            this.dispose(true).catch(() => { });\n        }\n    }\n    getVoices(locale) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const requestId = Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"createNoDashGuid\"])();\n            const response = yield this.privRestAdapter.getVoicesList(requestId);\n            if (response.ok && Array.isArray(response.json)) {\n                let json = response.json;\n                if (!!locale && locale.length > 0) {\n                    json = json.filter((item) => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());\n                }\n                return new _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SynthesisVoicesResult\"](requestId, json, undefined);\n            }\n            else {\n                return new _Exports__WEBPACK_IMPORTED_MODULE_6__[\"SynthesisVoicesResult\"](requestId, undefined, `Error: ${response.status}: ${response.statusText}`);\n            }\n        });\n    }\n    adapterSpeak() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.privDisposed && !this.privSynthesizing) {\n                this.privSynthesizing = true;\n                const request = yield this.synthesisRequestQueue.dequeue();\n                return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);\n            }\n        });\n    }\n    static XMLEncode(text) {\n        return text.replace(/&/g, \"&amp;\")\n            .replace(/</g, \"&lt;\")\n            .replace(/>/g, \"&gt;\")\n            .replace(/\"/g, \"&quot;\")\n            .replace(/'/g, \"&apos;\");\n    }\n}\nclass SynthesisRequest {\n    constructor(requestId, text, isSSML, cb, err, dataStream) {\n        this.requestId = requestId;\n        this.text = text;\n        this.isSSML = isSSML;\n        this.cb = cb;\n        this.err = err;\n        this.dataStream = dataStream;\n    }\n}\n\n//# sourceMappingURL=SpeechSynthesizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js ***!
  \***************************************************************************************************************/
/*! exports provided: SpeechTranslationConfig, SpeechTranslationConfigImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfig\", function() { return SpeechTranslationConfig; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechTranslationConfigImpl\", function() { return SpeechTranslationConfigImpl; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Speech translation configuration.\n * @class SpeechTranslationConfig\n */\nclass SpeechTranslationConfig extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechConfig\"] {\n    /**\n     * Creates an instance of recognizer config.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.\n     * @member SpeechTranslationConfig.fromSubscription\n     * @function\n     * @public\n     * @param {string} subscriptionKey - The subscription key.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechTranslationConfig} The speech translation config.\n     */\n    static fromSubscription(subscriptionKey, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        return ret;\n    }\n    /**\n     * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.\n     * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n     * expires, the caller needs to refresh it by setting the property authorizationToken with a new\n     * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance\n     * will encounter errors during recognition.\n     * As configuration values are copied when creating a new recognizer, the new token value will not apply\n     * to recognizers that have already been created.\n     * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n     * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n     * @member SpeechTranslationConfig.fromAuthorizationToken\n     * @function\n     * @public\n     * @param {string} authorizationToken - The authorization token.\n     * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n     * @returns {SpeechTranslationConfig} The speech translation config.\n     */\n    static fromAuthorizationToken(authorizationToken, region) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(region, \"region\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, authorizationToken);\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region, region);\n        return ret;\n    }\n    /**\n     * Creates an instance of the speech config with specified host and subscription key.\n     * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n     * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n     * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n     * Note: To use an authorization token with fromHost, use fromHost(URL),\n     * and then set the AuthorizationToken property on the created SpeechConfig instance.\n     * Note: Added in version 1.9.0.\n     * @member SpeechConfig.fromHost\n     * @function\n     * @public\n     * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n     * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n     * @returns {SpeechConfig} A speech factory instance.\n     */\n    static fromHost(hostName, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(hostName, \"hostName\");\n        const speechImpl = new SpeechTranslationConfigImpl();\n        speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n        if (undefined !== subscriptionKey) {\n            speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        }\n        return speechImpl;\n    }\n    /**\n     * Creates an instance of the speech translation config with specified endpoint and subscription key.\n     * This method is intended only for users who use a non-standard service endpoint or paramters.\n     * Note: The query properties specified in the endpoint URL are not changed, even if they are\n     * set by any other APIs. For example, if language is defined in the uri as query parameter\n     * \"language=de-DE\", and also set by the speechRecognitionLanguage property, the language\n     * setting in uri takes precedence, and the effective language is \"de-DE\".\n     * Only the properties that are not specified in the endpoint URL can be set by other APIs.\n     * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n     * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n     * use the authorization token.\n     * @member SpeechTranslationConfig.fromEndpoint\n     * @function\n     * @public\n     * @param {URL} endpoint - The service endpoint to connect to.\n     * @param {string} subscriptionKey - The subscription key.\n     * @returns {SpeechTranslationConfig} A speech config instance.\n     */\n    static fromEndpoint(endpoint, subscriptionKey) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(endpoint, \"endpoint\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(subscriptionKey, \"subscriptionKey\");\n        const ret = new SpeechTranslationConfigImpl();\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Endpoint, endpoint.href);\n        ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key, subscriptionKey);\n        return ret;\n    }\n}\n/**\n * @private\n * @class SpeechTranslationConfigImpl\n */\nclass SpeechTranslationConfigImpl extends SpeechTranslationConfig {\n    constructor() {\n        super();\n        this.privSpeechProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"].Simple;\n    }\n    /**\n     * Gets/Sets the authorization token.\n     * If this is set, subscription key is ignored.\n     * User needs to make sure the provided authorization token is valid and not expired.\n     * @member SpeechTranslationConfigImpl.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - The authorization token.\n     */\n    set authorizationToken(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * Sets the speech recognition language.\n     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @param {string} value - The authorization token.\n     */\n    set speechRecognitionLanguage(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage, value);\n    }\n    /**\n     * Gets the speech recognition language.\n     * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @return {string} The speechRecognitionLanguage.\n     */\n    get speechRecognitionLanguage() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * @member SpeechTranslationConfigImpl.prototype.subscriptionKey\n     * @function\n     * @public\n     */\n    get subscriptionKey() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Key]);\n    }\n    /**\n     * Gets the output format\n     * @member SpeechTranslationConfigImpl.prototype.outputFormat\n     * @function\n     * @public\n     */\n    get outputFormat() {\n        // eslint-disable-next-line\n        return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormatPropertyName\"], undefined)];\n    }\n    /**\n     * Gets/Sets the output format\n     * @member SpeechTranslationConfigImpl.prototype.outputFormat\n     * @function\n     * @public\n     */\n    set outputFormat(value) {\n        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OutputFormatPropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"OutputFormat\"][value]);\n    }\n    /**\n     * Gets the endpoint id.\n     * @member SpeechTranslationConfigImpl.prototype.endpointId\n     * @function\n     * @public\n     */\n    get endpointId() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId);\n    }\n    /**\n     * Gets/Sets the endpoint id.\n     * @member SpeechTranslationConfigImpl.prototype.endpointId\n     * @function\n     * @public\n     */\n    set endpointId(value) {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EndpointId, value);\n    }\n    /**\n     * Add a (text) target language to translate into.\n     * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage\n     * @function\n     * @public\n     * @param {string} value - The language such as de-DE\n     */\n    addTargetLanguage(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        const languages = this.targetLanguages;\n        languages.push(value);\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n    }\n    /**\n     * Gets the (text) target language to translate into.\n     * @member SpeechTranslationConfigImpl.prototype.targetLanguages\n     * @function\n     * @public\n     * @param {string} value - The language such as de-DE\n     */\n    get targetLanguages() {\n        if (this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages).split(\",\");\n        }\n        else {\n            return [];\n        }\n    }\n    /**\n     * Gets the voice name.\n     * @member SpeechTranslationConfigImpl.prototype.voiceName\n     * @function\n     * @public\n     */\n    get voiceName() {\n        return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice]);\n    }\n    /**\n     * Gets/Sets the voice of the translated language, enable voice synthesis output.\n     * @member SpeechTranslationConfigImpl.prototype.voiceName\n     * @function\n     * @public\n     * @param {string} value - The name of the voice.\n     */\n    set voiceName(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(value, \"value\");\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice, value);\n    }\n    /**\n     * Provides the region.\n     * @member SpeechTranslationConfigImpl.prototype.region\n     * @function\n     * @public\n     * @returns {string} The region.\n     */\n    get region() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_Region);\n    }\n    setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyHostName], proxyHostName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyPort], proxyPort);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyUserName], proxyUserName);\n        this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_ProxyPassword], proxyPassword);\n    }\n    /**\n     * Gets an arbitrary property value.\n     * @member SpeechTranslationConfigImpl.prototype.getProperty\n     * @function\n     * @public\n     * @param {string} name - The name of the property.\n     * @param {string} def - The default value of the property in case it is not set.\n     * @returns {string} The value of the property.\n     */\n    getProperty(name, def) {\n        return this.privSpeechProperties.getProperty(name, def);\n    }\n    /**\n     * Gets/Sets an arbitrary property value.\n     * @member SpeechTranslationConfigImpl.prototype.setProperty\n     * @function\n     * @public\n     * @param {string} name - The name of the property.\n     * @param {string} value - The value of the property.\n     */\n    setProperty(name, value) {\n        this.privSpeechProperties.setProperty(name, value);\n    }\n    /**\n     * Provides access to custom properties.\n     * @member SpeechTranslationConfigImpl.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The properties.\n     */\n    get properties() {\n        return this.privSpeechProperties;\n    }\n    /**\n     * Dispose of associated resources.\n     * @member SpeechTranslationConfigImpl.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    setServiceProperty(name, value) {\n        const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServicePropertiesPropertyName\"], \"{}\"));\n        currentProperties[name] = value;\n        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ServicePropertiesPropertyName\"], JSON.stringify(currentProperties));\n    }\n    setProfanity(profanity) {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ProfanityOption\"][profanity]);\n    }\n    enableAudioLogging() {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_EnableAudioLogging, \"true\");\n    }\n    requestWordLevelTimestamps() {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n    }\n    enableDictation() {\n        this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ForceDictationPropertyName\"], \"true\");\n    }\n    get speechSynthesisLanguage() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthLanguage);\n    }\n    set speechSynthesisLanguage(language) {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthLanguage, language);\n    }\n    get speechSynthesisVoiceName() {\n        return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthVoice);\n    }\n    set speechSynthesisVoiceName(voice) {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthVoice, voice);\n    }\n    get speechSynthesisOutputFormat() {\n        // eslint-disable-next-line\n        return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisOutputFormat\"][this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, undefined)];\n    }\n    set speechSynthesisOutputFormat(format) {\n        this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"SpeechSynthesisOutputFormat\"][format]);\n    }\n}\n\n//# sourceMappingURL=SpeechTranslationConfig.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js ***!
  \*******************************************************************************************************/
/*! exports provided: SynthesisResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisResult\", function() { return SynthesisResult; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Base class for synthesis results\n * @class SynthesisResult\n * Added in version 1.20.0\n */\nclass SynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(resultId, reason, errorDetails, properties) {\n        this.privResultId = resultId;\n        this.privReason = reason;\n        this.privErrorDetails = errorDetails;\n        this.privProperties = properties;\n    }\n    /**\n     * Specifies the result identifier.\n     * @member SynthesisResult.prototype.resultId\n     * @function\n     * @public\n     * @returns {string} Specifies the result identifier.\n     */\n    get resultId() {\n        return this.privResultId;\n    }\n    /**\n     * Specifies status of the result.\n     * @member SynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} Specifies status of the result.\n     */\n    get reason() {\n        return this.privReason;\n    }\n    /**\n     * In case of an unsuccessful synthesis, provides details of the occurred error.\n     * @member SynthesisResult.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} a brief description of an error.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    /**\n     * The set of properties exposed in the result.\n     * @member SynthesisResult.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The set of properties exposed in the result.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n}\n\n//# sourceMappingURL=SynthesisResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js ***!
  \*************************************************************************************************************/
/*! exports provided: SynthesisVoicesResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisVoicesResult\", function() { return SynthesisVoicesResult; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech synthesis.\n * @class SynthesisVoicesResult\n * Added in version 1.20.0\n */\nclass SynthesisVoicesResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SynthesisResult\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param requestId - result id for request.\n     * @param json - json payload from endpoint.\n     */\n    constructor(requestId, json, errorDetails) {\n        if (Array.isArray(json)) {\n            super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].VoicesListRetrieved, undefined, new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]());\n            this.privVoices = [];\n            for (const item of json) {\n                this.privVoices.push(new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"VoiceInfo\"](item));\n            }\n        }\n        else {\n            super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_0__[\"ResultReason\"].Canceled, errorDetails ? errorDetails : \"Error information unavailable\", new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]());\n        }\n    }\n    /**\n     * The list of voices\n     * @member SynthesisVoicesResult.prototype.voices\n     * @function\n     * @public\n     * @returns {VoiceInfo[]} List of synthesized voices.\n     */\n    get voices() {\n        return this.privVoices;\n    }\n}\n\n//# sourceMappingURL=SynthesisVoicesResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js ***!
  \******************************************************************************************************************/
/*! exports provided: Conversation, ConversationImpl */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Conversation\", function() { return Conversation; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationImpl\", function() { return ConversationImpl; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\nclass Conversation {\n    constructor() {\n        return;\n    }\n    /**\n     * Create a conversation\n     * @param speechConfig\n     * @param cb\n     * @param err\n     */\n    static createConversationAsync(speechConfig, arg2, arg3, arg4) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(speechConfig, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].restErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(speechConfig.region, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Region\"));\n        if (!speechConfig.subscriptionKey && !speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token])) {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(speechConfig.subscriptionKey, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Key\"));\n        }\n        let conversationImpl;\n        let cb;\n        let err;\n        if (typeof arg2 === \"string\") {\n            conversationImpl = new ConversationImpl(speechConfig, arg2);\n            // eslint-disable-next-line @typescript-eslint/no-empty-function\n            Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () { }))(), arg3, arg4);\n        }\n        else {\n            conversationImpl = new ConversationImpl(speechConfig);\n            cb = arg2;\n            err = arg3;\n            conversationImpl.createConversationAsync((() => {\n                if (!!cb) {\n                    cb();\n                }\n            }), (error) => {\n                if (!!err) {\n                    err(error);\n                }\n            });\n        }\n        return conversationImpl;\n    }\n}\nclass ConversationImpl extends Conversation {\n    /**\n     * Create a conversation impl\n     * @param speechConfig\n     * @param {string} id - optional conversationId\n     */\n    constructor(speechConfig, id) {\n        super();\n        this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].restErrors;\n        /** websocket callbacks */\n        /* eslint-disable @typescript-eslint/typedef */\n        this.onConnected = (e) => {\n            var _a;\n            this.privIsConnected = true;\n            try {\n                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStarted)) {\n                    this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onDisconnected = (e) => {\n            var _a;\n            try {\n                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStopped)) {\n                    this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n            finally {\n                void this.close(false);\n            }\n        };\n        this.onCanceled = (r, e) => {\n            var _a;\n            try {\n                if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.canceled)) {\n                    this.privConversationTranslator.canceled(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantUpdateCommandReceived = (r, e) => {\n            try {\n                const updatedParticipant = this.privParticipants.getParticipant(e.id);\n                if (updatedParticipant !== undefined) {\n                    switch (e.key) {\n                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].changeNickname:\n                            updatedParticipant.displayName = e.value;\n                            break;\n                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setUseTTS:\n                            updatedParticipant.isUsingTts = e.value;\n                            break;\n                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setProfanityFiltering:\n                            updatedParticipant.profanity = e.value;\n                            break;\n                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setMute:\n                            updatedParticipant.isMuted = e.value;\n                            break;\n                        case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setTranslateToLanguages:\n                            updatedParticipant.translateToLanguages = e.value;\n                            break;\n                    }\n                    this.privParticipants.addOrUpdateParticipant(updatedParticipant);\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ParticipantChangedReason\"].Updated, [this.toParticipant(updatedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onLockRoomCommandReceived = () => {\n            // TODO\n        };\n        this.onMuteAllCommandReceived = (r, e) => {\n            try {\n                this.privParticipants.participants.forEach((p) => p.isMuted = (p.isHost ? false : e.isMuted));\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ParticipantChangedReason\"].Updated, this.toParticipants(false), e.sessionId));\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantJoinCommandReceived = (r, e) => {\n            try {\n                const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);\n                if (newParticipant !== undefined) {\n                    if (!!this.privConversationTranslator) {\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ParticipantChangedReason\"].JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantLeaveCommandReceived = (r, e) => {\n            try {\n                const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);\n                if (ejectedParticipant !== undefined) {\n                    // remove the participant from the internal participants list\n                    this.privParticipants.deleteParticipant(e.participant.id);\n                    if (!!this.privConversationTranslator) {\n                        // notify subscribers that the participant has left the conversation\n                        this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ParticipantChangedReason\"].LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onTranslationReceived = (r, e) => {\n            try {\n                switch (e.command) {\n                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].final:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribed(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationTranslationEventArgs\"](e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].partial:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.transcribing(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationTranslationEventArgs\"](e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                    case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].instantMessage:\n                        if (!!this.privConversationTranslator) {\n                            this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationTranslationEventArgs\"](e.payload, undefined, e.sessionId));\n                        }\n                        break;\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onParticipantsListReceived = (r, e) => {\n            var _a;\n            try {\n                // check if the session token needs to be updated\n                if (e.sessionToken !== undefined && e.sessionToken !== null) {\n                    this.privRoom.token = e.sessionToken;\n                }\n                // save the participants\n                this.privParticipants.participants = [...e.participants];\n                // enable the conversation\n                if (this.privParticipants.me !== undefined) {\n                    this.privIsReady = true;\n                }\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ParticipantChangedReason\"].JoinedConversation, this.toParticipants(true), e.sessionId));\n                }\n                // if this is the host, update the nickname if needed\n                if (this.me.isHost) {\n                    const nickname = (_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Name);\n                    if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {\n                        // issue a change nickname request\n                        this.changeNicknameAsync(nickname);\n                    }\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.onConversationExpiration = (r, e) => {\n            try {\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);\n                }\n            }\n            catch (e) {\n                //\n            }\n        };\n        this.privIsConnected = false;\n        this.privIsDisposed = false;\n        this.privConversationId = \"\";\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyCollection\"]();\n        this.privManager = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationManager\"]();\n        // check the speech language\n        const language = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n        if (!language) {\n            speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].defaultLanguageCode);\n        }\n        this.privLanguage = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n        if (!id) {\n            // check the target language(s)\n            if (speechConfig.targetLanguages.length === 0) {\n                speechConfig.addTargetLanguage(this.privLanguage);\n            }\n            // check the profanity setting: speech and conversationTranslator should be in sync\n            const profanity = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceResponse_ProfanityOption]);\n            if (!profanity) {\n                speechConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ProfanityOption\"].Masked);\n            }\n            // check the nickname: it should pass this regex: ^\\w+([\\s-][\\w\\(\\)]+)*$\"\n            // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error\n            // TODO: check what the max length is and if a truncation is required or if the service handles it without an error\n            let hostNickname = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Name]);\n            if (hostNickname === undefined || hostNickname === null || hostNickname.length <= 1 || hostNickname.length > 50) {\n                hostNickname = \"Host\";\n            }\n            speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Name], hostNickname);\n        }\n        else {\n            this.privConversationId = id;\n        }\n        // save the speech config for future usage\n        this.privConfig = speechConfig;\n        // save the config properties\n        const configImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNull(configImpl, \"speechConfig\");\n        this.privProperties = configImpl.properties.clone();\n        this.privIsConnected = false;\n        this.privParticipants = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"InternalParticipants\"]();\n        this.privIsReady = false;\n        this.privTextMessageMaxLength = 1000;\n    }\n    // get the internal data about a conversation\n    get room() {\n        return this.privRoom;\n    }\n    // get the wrapper for connecting to the websockets\n    get connection() {\n        return this.privConversationRecognizer; // this.privConnection;\n    }\n    // get the config\n    get config() {\n        return this.privConfig;\n    }\n    // get the conversation Id\n    get conversationId() {\n        return this.privRoom ? this.privRoom.roomId : this.privConversationId;\n    }\n    // get the properties\n    get properties() {\n        return this.privProperties;\n    }\n    // get the speech language\n    get speechRecognitionLanguage() {\n        return this.privLanguage;\n    }\n    get isMutedByHost() {\n        var _a, _b;\n        return ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost) ? false : (_b = this.privParticipants.me) === null || _b === void 0 ? void 0 : _b.isMuted;\n    }\n    get isConnected() {\n        return this.privIsConnected && this.privIsReady;\n    }\n    get participants() {\n        return this.toParticipants(true);\n    }\n    get me() {\n        return this.toParticipant(this.privParticipants.me);\n    }\n    get host() {\n        return this.toParticipant(this.privParticipants.host);\n    }\n    get transcriberRecognizer() {\n        return this.privTranscriberRecognizer;\n    }\n    get conversationInfo() {\n        const convId = this.conversationId;\n        const p = this.participants.map((part) => ({\n            id: part.id,\n            preferredLanguage: part.preferredLanguage,\n            voice: part.voice\n        }));\n        const props = {};\n        for (const key of _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].transcriptionEventKeys) {\n            const val = this.properties.getProperty(key, \"\");\n            if (val !== \"\") {\n                props[key] = val;\n            }\n        }\n        const info = { id: convId, participants: p, conversationProperties: props };\n        return info;\n    }\n    get canSend() {\n        var _a;\n        return this.privIsConnected && !((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isMuted);\n    }\n    get canSendAsHost() {\n        var _a;\n        return this.privIsConnected && ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost);\n    }\n    // get / set the speech auth token\n    // eslint-disable-next-line @typescript-eslint/member-ordering\n    get authorizationToken() {\n        return this.privToken;\n    }\n    set authorizationToken(value) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(value, \"authorizationToken\");\n        this.privToken = value;\n    }\n    set conversationTranslator(conversationTranslator) {\n        this.privConversationTranslator = conversationTranslator;\n    }\n    /**\n     * Create a new conversation as Host\n     * @param cb\n     * @param err\n     */\n    createConversationAsync(cb, err) {\n        try {\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            this.privManager.createOrJoin(this.privProperties, undefined, ((room) => {\n                if (!room) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);\n                }\n                this.privRoom = room;\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Starts a new conversation as host.\n     * @param cb\n     * @param err\n     */\n    startConversationAsync(cb, err) {\n        try {\n            // check if there is already a recognizer\n            if (!!this.privConversationRecognizer) {\n                this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n            }\n            // check if there is conversation data available\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);\n            // connect to the conversation websocket\n            this.privParticipants.meId = this.privRoom.participantId;\n            this.privConversationRecognizer = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationRecognizerFactory\"].fromConfig(this, this.privConfig);\n            // Because ConversationTranslator manually sets up and manages the connection, Conversation\n            // has to forward serviceRecognizer connection events that usually get passed automatically\n            this.privConversationRecognizer.connected = this.onConnected;\n            this.privConversationRecognizer.disconnected = this.onDisconnected;\n            this.privConversationRecognizer.canceled = this.onCanceled;\n            this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;\n            this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;\n            this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;\n            this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;\n            this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;\n            this.privConversationRecognizer.translationReceived = this.onTranslationReceived;\n            this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;\n            this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;\n            this.privConversationRecognizer.connect(this.privRoom.token, (() => {\n                this.handleCallback(cb, err);\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Join a conversation as a participant.\n     * @param { IParticipant } participant - participant to add\n     * @param cb\n     * @param err\n     */\n    addParticipantAsync(participant, cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(participant, \"Participant\");\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.addParticipantImplAsync(participant), cb, err);\n    }\n    /**\n     * Join a conversation as a participant.\n     * @param conversation\n     * @param nickname\n     * @param lang\n     * @param cb\n     * @param err\n     */\n    joinConversationAsync(conversationId, nickname, lang, cb, err) {\n        try {\n            // TODO\n            // if (!!this.privConversationRecognizer) {\n            //     throw new Error(this.privErrors.permissionDeniedStart);\n            // }\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversationId\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace(\"{arg}\", \"language\"));\n            // join the conversation\n            this.privManager.createOrJoin(this.privProperties, conversationId, ((room) => {\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);\n                this.privRoom = room;\n                this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;\n                // join callback\n                if (!!cb) {\n                    cb(room.cognitiveSpeechAuthToken);\n                }\n            }), ((error) => {\n                this.handleError(error, err);\n            }));\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Deletes a conversation\n     * @param cb\n     * @param err\n     */\n    deleteConversationAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.deleteConversationImplAsync(), cb, err);\n    }\n    deleteConversationImplAsync() {\n        return __awaiter(this, void 0, void 0, function* () {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);\n            yield this.privManager.leave(this.privProperties, this.privRoom.token);\n            this.dispose();\n        });\n    }\n    /**\n     * Issues a request to close the client websockets\n     * @param cb\n     * @param err\n     */\n    endConversationAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.endConversationImplAsync(), cb, err);\n    }\n    endConversationImplAsync() {\n        return this.close(true);\n    }\n    /**\n     * Issues a request to lock the conversation\n     * @param cb\n     * @param err\n     */\n    lockConversationAsync(cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"lock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute the conversation\n     * @param cb\n     * @param err\n     */\n    muteAllParticipantsAsync(cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the user's permissions\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"mute\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to mute a participant in the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    muteParticipantAsync(userId, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to remove a participant from the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    removeParticipantAsync(userId, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            if (!!this.privTranscriberRecognizer && userId.hasOwnProperty(\"id\")) {\n                // Assume this is a transcription participant\n                Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.removeParticipantImplAsync(userId), cb, err);\n            }\n            else {\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n                if (!this.canSendAsHost) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"remove\")), err);\n                }\n                let participantId = \"\";\n                if (typeof userId === \"string\") {\n                    participantId = userId;\n                }\n                else if (userId.hasOwnProperty(\"id\")) {\n                    const participant = userId;\n                    participantId = participant.id;\n                }\n                else if (userId.hasOwnProperty(\"userId\")) {\n                    const user = userId;\n                    participantId = user.userId;\n                }\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n                // check the participant exists\n                const index = this.participants.findIndex((p) => p.id === participantId);\n                if (index === -1) {\n                    this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n                }\n                if (!!this.privConversationRecognizer) {\n                    this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), (() => {\n                        this.handleCallback(cb, err);\n                    }), ((error) => {\n                        this.handleError(error, err);\n                    }));\n                }\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unlock the conversation\n     * @param cb\n     * @param err\n     */\n    unlockConversationAsync(cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unlock\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getLockCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute all participants in the conversation\n     * @param cb\n     * @param err\n     */\n    unmuteAllParticipantsAsync(cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSendAsHost) {\n                this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unmute all\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Issues a request to unmute a participant in the conversation\n     * @param userId\n     * @param cb\n     * @param err\n     */\n    unmuteParticipantAsync(userId, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            // check the connection is open (host + participant can perform the mute command)\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // if not host, check the participant is not muting another participant\n            if (!this.me.isHost && this.me.id !== userId) {\n                this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n            }\n            // check the user exists\n            const exists = this.privParticipants.getParticipantIndex(userId);\n            if (exists === -1) {\n                this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Send a text message\n     * @param message\n     * @param cb\n     * @param err\n     */\n    sendTextMessageAsync(message, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", \"message\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            // TODO: is a max length check required?\n            if (message.length > this.privTextMessageMaxLength) {\n                this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"message length\")), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Set translated to languages\n     * @param {string[]} languages - languages to translate to\n     * @param cb\n     * @param err\n     */\n    setTranslatedLanguagesAsync(languages, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace(\"{arg}\", \"languages\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Change nickname\n     * @param {string} nickname - new nickname for the room\n     * @param cb\n     * @param err\n     */\n    changeNicknameAsync(nickname, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privIsDisposed);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privConversationRecognizer.isDisposed());\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n            if (!this.canSend) {\n                this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n            }\n            if (!!this.privConversationRecognizer) {\n                this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), (() => {\n                    this.handleCallback(cb, err);\n                }), ((error) => {\n                    this.handleError(error, err);\n                }));\n            }\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose() {\n        if (this.isDisposed) {\n            return;\n        }\n        this.privIsDisposed = true;\n        if (!!this.config) {\n            this.config.close();\n        }\n        this.privConfig = undefined;\n        this.privLanguage = undefined;\n        this.privProperties = undefined;\n        this.privRoom = undefined;\n        this.privToken = undefined;\n        this.privManager = undefined;\n        this.privIsConnected = false;\n        this.privIsReady = false;\n        this.privParticipants = undefined;\n    }\n    connectTranscriberRecognizer(recognizer) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!!this.privTranscriberRecognizer) {\n                yield this.privTranscriberRecognizer.close();\n            }\n            yield recognizer.enforceAudioGating();\n            this.privTranscriberRecognizer = recognizer;\n            this.privTranscriberRecognizer.conversation = this;\n        });\n    }\n    getKeepAlive() {\n        const nickname = (!!this.me) ? this.me.displayName : \"default_nickname\";\n        return JSON.stringify({\n            id: \"0\",\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].keepAlive\n        });\n    }\n    /* eslint-enable @typescript-eslint/typedef */\n    addParticipantImplAsync(participant) {\n        const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);\n        if (newParticipant !== undefined) {\n            if (!!this.privTranscriberRecognizer) {\n                const conversationInfo = this.conversationInfo;\n                conversationInfo.participants = [participant];\n                return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"join\");\n            }\n        }\n    }\n    removeParticipantImplAsync(participant) {\n        this.privParticipants.deleteParticipant(participant.id);\n        const conversationInfo = this.conversationInfo;\n        conversationInfo.participants = [participant];\n        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"leave\");\n    }\n    close(dispose) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                this.privIsConnected = false;\n                yield ((_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.close());\n                this.privConversationRecognizer = undefined;\n                if (!!this.privConversationTranslator) {\n                    this.privConversationTranslator.dispose();\n                }\n            }\n            catch (e) {\n                // ignore error\n                throw e;\n            }\n            if (dispose) {\n                this.dispose();\n            }\n        });\n    }\n    /** Helpers */\n    handleCallback(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n            cb = undefined;\n        }\n    }\n    handleError(error, err) {\n        if (!!err) {\n            if (error instanceof Error) {\n                const typedError = error;\n                err(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                err(error);\n            }\n        }\n    }\n    /** Participant Helpers */\n    toParticipants(includeHost) {\n        const participants = this.privParticipants.participants.map((p) => (this.toParticipant(p)));\n        if (!includeHost) {\n            return participants.filter((p) => p.isHost === false);\n        }\n        else {\n            return participants;\n        }\n    }\n    toParticipant(p) {\n        return new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"Participant\"](p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);\n    }\n    getMuteAllCommand(isMuted) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setMuteAll,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n            value: isMuted\n        });\n    }\n    getMuteCommand(participantId, isMuted) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setMute,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n            value: isMuted\n        });\n    }\n    getLockCommand(isLocked) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setLockState,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n            value: isLocked\n        });\n    }\n    getEjectCommand(participantId) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].ejectParticipant,\n            // eslint-disable-next-line object-shorthand\n            participantId: participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n        });\n    }\n    getSetTranslateToLanguagesCommand(languages) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].setTranslateToLanguages,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n            value: languages\n        });\n    }\n    getChangeNicknameCommand(nickname) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(nickname, \"nickname\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        return JSON.stringify({\n            command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorCommandTypes\"].changeNickname,\n            nickname,\n            participantId: this.privRoom.participantId,\n            roomid: this.privRoom.roomId,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].participantCommand,\n            value: nickname\n        });\n    }\n    getMessageCommand(message) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(message, \"message\");\n        return JSON.stringify({\n            participantId: this.privRoom.participantId,\n            roomId: this.privRoom.roomId,\n            text: message,\n            type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationTranslatorMessageTypes\"].instantMessage\n        });\n    }\n}\n\n//# sourceMappingURL=Conversation.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js ***!
  \************************************************************************************************************************/
/*! exports provided: ConversationCommon */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationCommon\", function() { return ConversationCommon; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ConversationCommon {\n    constructor(audioConfig) {\n        this.privAudioConfig = audioConfig;\n    }\n    handleCallback(cb, err) {\n        if (!!cb) {\n            try {\n                cb();\n            }\n            catch (e) {\n                if (!!err) {\n                    err(e);\n                }\n            }\n            cb = undefined;\n        }\n    }\n    handleError(error, err) {\n        if (!!err) {\n            if (error instanceof Error) {\n                const typedError = error;\n                err(typedError.name + \": \" + typedError.message);\n            }\n            else {\n                err(error);\n            }\n        }\n    }\n}\n\n//# sourceMappingURL=ConversationCommon.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \*************************************************************************************************************************************/
/*! exports provided: ConversationExpirationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationExpirationEventArgs\", function() { return ConversationExpirationEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationExpirationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(expirationTime, sessionId) {\n        super(sessionId);\n        this.privExpirationTime = expirationTime;\n    }\n    /** How much longer until the conversation expires (in minutes). */\n    get expirationTime() {\n        return this.privExpirationTime;\n    }\n}\n\n//# sourceMappingURL=ConversationExpirationEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \**********************************************************************************************************************************************/
/*! exports provided: ConversationParticipantsChangedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationParticipantsChangedEventArgs\", function() { return ConversationParticipantsChangedEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationParticipantsChangedEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    constructor(reason, participants, sessionId) {\n        super(sessionId);\n        this.privReason = reason;\n        this.privParticipant = participants;\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get participants() {\n        return this.privParticipant;\n    }\n}\n\n//# sourceMappingURL=ConversationParticipantsChangedEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js ***!
  \*****************************************************************************************************************************/
/*! exports provided: ConversationTranscriber */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriber\", function() { return ConversationTranscriber; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass ConversationTranscriber {\n    /**\n     * ConversationTranscriber constructor.\n     * @constructor\n     * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n     */\n    constructor(audioConfig) {\n        this.privAudioConfig = audioConfig;\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyCollection\"]();\n        this.privRecognizer = undefined;\n        this.privDisposedRecognizer = false;\n    }\n    /**\n     * Gets the spoken language of recognition.\n     * @member ConversationTranscriber.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} The spoken language of recognition.\n     */\n    get speechRecognitionLanguage() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * The collection of properties and their values defined for this ConversationTranscriber.\n     * @member ConversationTranscriber.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this ConversationTranscriber.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * @Internal\n     * Internal data member to support fromRecognizer* pattern methods on other classes.\n     * Do not use externally, object returned will change without warning or notice.\n     */\n    get internalData() {\n        return this.privRecognizer.internalData;\n    }\n    /**\n     * @Deprecated\n     * @Obsolete\n     * Please use the Connection.fromRecognizer pattern to obtain a connection object\n     */\n    get connection() {\n        return _Exports__WEBPACK_IMPORTED_MODULE_3__[\"Connection\"].fromRecognizer(this.privRecognizer);\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member ConversationTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member ConversationTranscriber.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * @param {Conversation} conversation - conversation to be recognized\n     */\n    joinConversationAsync(conversation, cb, err) {\n        const conversationImpl = conversation;\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(conversationImpl, \"Conversation\");\n        // ref the conversation object\n        // create recognizer and subscribe to recognizer events\n        this.privRecognizer = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"TranscriberRecognizer\"](conversation.config, this.privAudioConfig);\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privRecognizer, \"Recognizer\");\n        this.privRecognizer.connectCallbacks(this);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(conversationImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);\n    }\n    /**\n     * Starts conversation transcription, until stopTranscribingAsync() is called.\n     * User must subscribe to events to receive transcription results.\n     * @member ConversationTranscriber.prototype.startTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startTranscribingAsync(cb, err) {\n        this.privRecognizer.startContinuousRecognitionAsync(cb, err);\n    }\n    /**\n     * Starts conversation transcription, until stopTranscribingAsync() is called.\n     * User must subscribe to events to receive transcription results.\n     * @member ConversationTranscriber.prototype.stopTranscribingAsync\n     * @function\n     * @public\n     * @param cb - Callback invoked once the transcription has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopTranscribingAsync(cb, err) {\n        this.privRecognizer.stopContinuousRecognitionAsync(cb, err);\n    }\n    /**\n     * Leave the current conversation. After this is called, you will no longer receive any events.\n     */\n    leaveConversationAsync(cb, err) {\n        this.privRecognizer.disconnectCallbacks();\n        // eslint-disable-next-line\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () { return; }))(), cb, err);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member ConversationTranscriber.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfDisposed(this.privDisposedRecognizer);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * Disposes any resources held by the object.\n     * @member ConversationTranscriber.prototype.dispose\n     * @function\n     * @public\n     * @param {boolean} disposing - true if disposing the object.\n     */\n    dispose(disposing) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedRecognizer) {\n                return;\n            }\n            if (!!this.privRecognizer) {\n                yield this.privRecognizer.close();\n                this.privRecognizer = undefined;\n            }\n            if (disposing) {\n                this.privDisposedRecognizer = true;\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=ConversationTranscriber.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \**********************************************************************************************************************************************/
/*! exports provided: ConversationTranslationCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationCanceledEventArgs\", function() { return ConversationTranslationCanceledEventArgs; });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__[\"CancellationEventArgsBase\"] {\n}\n\n//# sourceMappingURL=ConversationTranslationCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \**************************************************************************************************************************************/
/*! exports provided: ConversationTranslationEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationEventArgs\", function() { return ConversationTranslationEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ConversationTranslationResult} result - The translation recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @returns {ConversationTranslationResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=ConversationTranslationEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \***********************************************************************************************************************************/
/*! exports provided: ConversationTranslationResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationResult\", function() { return ConversationTranslationResult; });\n/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationResult extends _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__[\"TranslationRecognitionResult\"] {\n    constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n        super(translations, resultId, reason, text, duration, offset, errorDetails, json, properties);\n        this.privId = participantId;\n        this.privOrigLang = originalLanguage;\n    }\n    /**\n     * The unique identifier for the participant this result is for.\n     */\n    get participantId() {\n        return this.privId;\n    }\n    /**\n     * The original language this result was in.\n     */\n    get originalLang() {\n        return this.privOrigLang;\n    }\n}\n\n//# sourceMappingURL=ConversationTranslationResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js ***!
  \****************************************************************************************************************************/
/*! exports provided: SpeechState, ConversationTranslator */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SpeechState\", function() { return SpeechState; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslator\", function() { return ConversationTranslator; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Conversation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n\nvar SpeechState;\n(function (SpeechState) {\n    SpeechState[SpeechState[\"Inactive\"] = 0] = \"Inactive\";\n    SpeechState[SpeechState[\"Connecting\"] = 1] = \"Connecting\";\n    SpeechState[SpeechState[\"Connected\"] = 2] = \"Connected\";\n})(SpeechState || (SpeechState = {}));\n// child class of TranslationRecognizer meant only for use with ConversationTranslator\nclass ConversationTranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_3__[\"TranslationRecognizer\"] {\n    constructor(speechConfig, audioConfig, translator) {\n        super(speechConfig, audioConfig);\n        this.privSpeechState = SpeechState.Inactive;\n        if (!!translator) {\n            this.privTranslator = translator;\n            this.sessionStarted = () => {\n                this.privSpeechState = SpeechState.Connected;\n            };\n            this.sessionStopped = () => {\n                this.privSpeechState = SpeechState.Inactive;\n            };\n            // eslint-disable-next-line @typescript-eslint/no-misused-promises\n            this.recognized = (tr, e) => __awaiter(this, void 0, void 0, function* () {\n                // TODO: add support for getting recognitions from here if own speech\n                var _a;\n                // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.\n                if ((_a = e.result) === null || _a === void 0 ? void 0 : _a.errorDetails) {\n                    yield this.cancelSpeech();\n                    // TODO: format the error message contained in 'errorDetails'\n                    this.fireCancelEvent(e.result.errorDetails);\n                }\n            });\n            // eslint-disable-next-line @typescript-eslint/no-misused-promises\n            this.canceled = () => __awaiter(this, void 0, void 0, function* () {\n                if (this.privSpeechState !== SpeechState.Inactive) {\n                    try {\n                        yield this.cancelSpeech();\n                    }\n                    catch (error) {\n                        this.privSpeechState = SpeechState.Inactive;\n                    }\n                }\n            });\n        }\n    }\n    get state() {\n        return this.privSpeechState;\n    }\n    set state(newState) {\n        this.privSpeechState = newState;\n    }\n    onConnection() {\n        this.privSpeechState = SpeechState.Connected;\n    }\n    onDisconnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.privSpeechState = SpeechState.Inactive;\n            yield this.cancelSpeech();\n        });\n    }\n    /**\n     * Fire a cancel event\n     * @param error\n     */\n    fireCancelEvent(error) {\n        try {\n            if (!!this.privTranslator.canceled) {\n                const cancelEvent = new _Exports__WEBPACK_IMPORTED_MODULE_5__[\"ConversationTranslationCanceledEventArgs\"](_Exports__WEBPACK_IMPORTED_MODULE_3__[\"CancellationReason\"].Error, error, _Exports__WEBPACK_IMPORTED_MODULE_3__[\"CancellationErrorCode\"].RuntimeError);\n                this.privTranslator.canceled(this.privTranslator, cancelEvent);\n            }\n        }\n        catch (e) {\n            //\n        }\n    }\n    cancelSpeech() {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                this.stopContinuousRecognitionAsync();\n                yield ((_a = this.privReco) === null || _a === void 0 ? void 0 : _a.disconnect());\n                this.privSpeechState = SpeechState.Inactive;\n            }\n            catch (e) {\n                // ignore the error\n            }\n        });\n    }\n}\n/**\n * Join, leave or connect to a conversation.\n */\nclass ConversationTranslator extends _Exports__WEBPACK_IMPORTED_MODULE_5__[\"ConversationCommon\"] {\n    constructor(audioConfig) {\n        super(audioConfig);\n        this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].restErrors;\n        this.privIsDisposed = false;\n        this.privIsSpeaking = false;\n        this.privPlaceholderKey = \"abcdefghijklmnopqrstuvwxyz012345\";\n        this.privPlaceholderRegion = \"westus\";\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyCollection\"]();\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get speechRecognitionLanguage() {\n        return this.privSpeechRecognitionLanguage;\n    }\n    get participants() {\n        var _a;\n        return (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.participants;\n    }\n    get canSpeak() {\n        // is there a Conversation websocket available and has the Recognizer been set up\n        if (!this.privConversation.isConnected || !this.privCTRecognizer) {\n            return false;\n        }\n        // is the user already speaking\n        if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {\n            return false;\n        }\n        // is the user muted\n        if (this.privConversation.isMutedByHost) {\n            return false;\n        }\n        return true;\n    }\n    joinConversationAsync(conversation, nickname, param1, param2, param3) {\n        try {\n            if (typeof conversation === \"string\") {\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n                if (!!this.privConversation) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);\n                }\n                let lang = param1;\n                if (lang === undefined || lang === null || lang === \"\") {\n                    lang = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].defaultLanguageCode;\n                }\n                // create a placeholder config\n                this.privSpeechTranslationConfig = _Exports__WEBPACK_IMPORTED_MODULE_3__[\"SpeechTranslationConfig\"].fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);\n                this.privSpeechTranslationConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"ProfanityOption\"].Masked);\n                this.privSpeechTranslationConfig.addTargetLanguage(lang);\n                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage], lang);\n                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Name], nickname);\n                const endpoint = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Host);\n                if (endpoint) {\n                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Host], endpoint);\n                }\n                const speechEndpointHost = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Host);\n                if (speechEndpointHost) {\n                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Host], speechEndpointHost);\n                }\n                // join the conversation\n                this.privConversation = new _Conversation__WEBPACK_IMPORTED_MODULE_4__[\"ConversationImpl\"](this.privSpeechTranslationConfig);\n                this.privConversation.conversationTranslator = this;\n                this.privConversation.joinConversationAsync(conversation, nickname, lang, ((result) => {\n                    if (!result) {\n                        this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);\n                    }\n                    this.privSpeechTranslationConfig.authorizationToken = result;\n                    // connect to the ws\n                    this.privConversation.startConversationAsync((() => {\n                        this.handleCallback(param2, param3);\n                    }), ((error) => {\n                        this.handleError(error, param3);\n                    }));\n                }), ((error) => {\n                    this.handleError(error, param3);\n                }));\n            }\n            else if (typeof conversation === \"object\") {\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n                // save the nickname\n                this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].ConversationTranslator_Name, nickname);\n                // ref the conversation object\n                this.privConversation = conversation;\n                // ref the conversation translator object\n                this.privConversation.conversationTranslator = this;\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n                this.privSpeechTranslationConfig = conversation.config;\n                this.handleCallback(param1, param2);\n            }\n            else {\n                this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"invalid conversation type\")), param2);\n            }\n        }\n        catch (error) {\n            this.handleError(error, typeof param1 === \"string\" ? param3 : param2);\n        }\n    }\n    /**\n     * Leave the conversation\n     * @param cb\n     * @param err\n     */\n    leaveConversationAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () {\n            // stop the speech websocket\n            yield this.cancelSpeech();\n            // stop the websocket\n            yield this.privConversation.endConversationImplAsync();\n            // https delete request\n            yield this.privConversation.deleteConversationImplAsync();\n            this.dispose();\n        }))(), cb, err);\n    }\n    /**\n     * Send a text message\n     * @param message\n     * @param cb\n     * @param err\n     */\n    sendTextMessageAsync(message, cb, err) {\n        try {\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n            _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", message));\n            this.privConversation.sendTextMessageAsync(message, cb, err);\n        }\n        catch (error) {\n            this.handleError(error, err);\n        }\n    }\n    /**\n     * Start speaking\n     * @param cb\n     * @param err\n     */\n    startTranscribingAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () {\n            try {\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n                if (this.privCTRecognizer === undefined) {\n                    yield this.connectTranslatorRecognizer();\n                }\n                _Contracts__WEBPACK_IMPORTED_MODULE_2__[\"Contracts\"].throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);\n                if (!this.canSpeak) {\n                    this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n                }\n                yield this.startContinuousRecognition();\n                this.privIsSpeaking = true;\n            }\n            catch (error) {\n                this.privIsSpeaking = false;\n                yield this.cancelSpeech();\n                throw error;\n            }\n        }))(), cb, err);\n    }\n    /**\n     * Stop speaking\n     * @param cb\n     * @param err\n     */\n    stopTranscribingAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () {\n            try {\n                if (!this.privIsSpeaking) {\n                    // stop speech\n                    yield this.cancelSpeech();\n                    return;\n                }\n                // stop the recognition but leave the websocket open\n                this.privIsSpeaking = false;\n                yield new Promise((resolve, reject) => {\n                    this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);\n                });\n            }\n            catch (error) {\n                yield this.cancelSpeech();\n            }\n        }))(), cb, err);\n    }\n    isDisposed() {\n        return this.privIsDisposed;\n    }\n    dispose(reason, success, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])((() => __awaiter(this, void 0, void 0, function* () {\n            if (this.isDisposed && !this.privIsSpeaking) {\n                return;\n            }\n            yield this.cancelSpeech();\n            this.privIsDisposed = true;\n            this.privSpeechTranslationConfig.close();\n            this.privSpeechRecognitionLanguage = undefined;\n            this.privProperties = undefined;\n            this.privAudioConfig = undefined;\n            this.privSpeechTranslationConfig = undefined;\n            this.privConversation.dispose();\n            this.privConversation = undefined;\n        }))(), success, err);\n    }\n    /**\n     * Cancel the speech websocket\n     */\n    cancelSpeech() {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                this.privIsSpeaking = false;\n                yield ((_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.onDisconnection());\n                this.privCTRecognizer = undefined;\n            }\n            catch (e) {\n                // ignore the error\n            }\n        });\n    }\n    /**\n     * Connect to the speech translation recognizer.\n     * Currently there is no language validation performed before sending the SpeechLanguage code to the service.\n     * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'\n     * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'\n     */\n    connectTranslatorRecognizer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                if (this.privAudioConfig === undefined) {\n                    this.privAudioConfig = _Exports__WEBPACK_IMPORTED_MODULE_3__[\"AudioConfig\"].fromDefaultMicrophoneInput();\n                }\n                // clear the temp subscription key if it's a participant joining\n                if (this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Key])\n                    === this.privPlaceholderKey) {\n                    this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Key], \"\");\n                }\n                // TODO\n                const token = encodeURIComponent(this.privConversation.room.token);\n                let endpointHost = this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Host], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].speechHost);\n                endpointHost = endpointHost.replace(\"{region}\", this.privConversation.room.cognitiveSpeechRegion);\n                const url = `wss://${endpointHost}${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].speechPath}?${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"ConversationConnectionConfig\"].configParams.token}=${token}`;\n                this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_3__[\"PropertyId\"].SpeechServiceConnection_Endpoint], url);\n                this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this);\n            }\n            catch (error) {\n                yield this.cancelSpeech();\n                throw error;\n            }\n        });\n    }\n    /**\n     * Handle the start speaking request\n     */\n    startContinuousRecognition() {\n        return new Promise((resolve, reject) => {\n            this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);\n        });\n    }\n}\n\n//# sourceMappingURL=ConversationTranslator.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js ***!
  \*************************************************************************************************************/
/*! exports provided: Conversation, ConversationImpl, ConversationCommon, ConversationExpirationEventArgs, ConversationParticipantsChangedEventArgs, ConversationTranslationCanceledEventArgs, ConversationTranslationEventArgs, ConversationTranslationResult, ConversationTranslator, ConversationTranscriber, Participant, User, ParticipantChangedReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Conversation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Conversation\", function() { return _Conversation__WEBPACK_IMPORTED_MODULE_0__[\"Conversation\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationImpl\", function() { return _Conversation__WEBPACK_IMPORTED_MODULE_0__[\"ConversationImpl\"]; });\n\n/* harmony import */ var _ConversationCommon__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationCommon */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationCommon\", function() { return _ConversationCommon__WEBPACK_IMPORTED_MODULE_1__[\"ConversationCommon\"]; });\n\n/* harmony import */ var _ConversationExpirationEventArgs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationExpirationEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationExpirationEventArgs\", function() { return _ConversationExpirationEventArgs__WEBPACK_IMPORTED_MODULE_2__[\"ConversationExpirationEventArgs\"]; });\n\n/* harmony import */ var _ConversationParticipantsChangedEventArgs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationParticipantsChangedEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationParticipantsChangedEventArgs\", function() { return _ConversationParticipantsChangedEventArgs__WEBPACK_IMPORTED_MODULE_3__[\"ConversationParticipantsChangedEventArgs\"]; });\n\n/* harmony import */ var _ConversationTranslationCanceledEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslationCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationCanceledEventArgs\", function() { return _ConversationTranslationCanceledEventArgs__WEBPACK_IMPORTED_MODULE_4__[\"ConversationTranslationCanceledEventArgs\"]; });\n\n/* harmony import */ var _ConversationTranslationEventArgs__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslationEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationEventArgs\", function() { return _ConversationTranslationEventArgs__WEBPACK_IMPORTED_MODULE_5__[\"ConversationTranslationEventArgs\"]; });\n\n/* harmony import */ var _ConversationTranslationResult__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationTranslationResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslationResult\", function() { return _ConversationTranslationResult__WEBPACK_IMPORTED_MODULE_6__[\"ConversationTranslationResult\"]; });\n\n/* harmony import */ var _ConversationTranslator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ConversationTranslator */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranslator\", function() { return _ConversationTranslator__WEBPACK_IMPORTED_MODULE_7__[\"ConversationTranslator\"]; });\n\n/* harmony import */ var _ConversationTranscriber__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationTranscriber */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ConversationTranscriber\", function() { return _ConversationTranscriber__WEBPACK_IMPORTED_MODULE_8__[\"ConversationTranscriber\"]; });\n\n/* harmony import */ var _IParticipant__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./IParticipant */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Participant\", function() { return _IParticipant__WEBPACK_IMPORTED_MODULE_9__[\"Participant\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"User\", function() { return _IParticipant__WEBPACK_IMPORTED_MODULE_9__[\"User\"]; });\n\n/* harmony import */ var _ParticipantChangedReason__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./ParticipantChangedReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ParticipantChangedReason\", function() { return _ParticipantChangedReason__WEBPACK_IMPORTED_MODULE_10__[\"ParticipantChangedReason\"]; });\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=Exports.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js ***!
  \******************************************************************************************************************/
/*! exports provided: User, Participant */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"User\", function() { return User; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Participant\", function() { return Participant; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n/* eslint-disable max-classes-per-file */\n\nclass User {\n    constructor(userId) {\n        this.privUserId = userId;\n    }\n    get userId() {\n        return this.privUserId;\n    }\n}\nclass Participant {\n    constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {\n        this.privId = id;\n        this.privAvatar = avatar;\n        this.privDisplayName = displayName;\n        this.privIsHost = isHost;\n        this.privIsMuted = isMuted;\n        this.privIsUsingTts = isUsingTts;\n        this.privPreferredLanguage = preferredLanguage;\n        this.privVoice = voice;\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]();\n    }\n    get avatar() {\n        return this.privAvatar;\n    }\n    get displayName() {\n        return this.privDisplayName;\n    }\n    get id() {\n        return this.privId;\n    }\n    get preferredLanguage() {\n        return this.privPreferredLanguage;\n    }\n    get isHost() {\n        return this.privIsHost;\n    }\n    get isMuted() {\n        return this.privIsMuted;\n    }\n    get isUsingTts() {\n        return this.privIsUsingTts;\n    }\n    get voice() {\n        return this.privVoice;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    static From(id, language, voice) {\n        return new Participant(id, \"\", id, false, false, false, language, voice);\n    }\n}\n\n//# sourceMappingURL=IParticipant.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \******************************************************************************************************************************/
/*! exports provided: ParticipantChangedReason */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParticipantChangedReason\", function() { return ParticipantChangedReason; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar ParticipantChangedReason;\n(function (ParticipantChangedReason) {\n    /** Participant has joined the conversation. */\n    ParticipantChangedReason[ParticipantChangedReason[\"JoinedConversation\"] = 0] = \"JoinedConversation\";\n    /** Participant has left the conversation. This could be voluntary, or involuntary\n     * (e.g. they are experiencing networking issues).\n     */\n    ParticipantChangedReason[ParticipantChangedReason[\"LeftConversation\"] = 1] = \"LeftConversation\";\n    /** The participants' state has changed (e.g. they became muted, changed their nickname). */\n    ParticipantChangedReason[ParticipantChangedReason[\"Updated\"] = 2] = \"Updated\";\n})(ParticipantChangedReason || (ParticipantChangedReason = {}));\n\n//# sourceMappingURL=ParticipantChangedReason.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
/*! exports provided: TranslationRecognitionCanceledEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionCanceledEventArgs\", function() { return TranslationRecognitionCanceledEventArgs; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define payload of speech recognition canceled result events.\n * @class TranslationRecognitionCanceledEventArgs\n */\nclass TranslationRecognitionCanceledEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} sessionid - The session id.\n     * @param {CancellationReason} cancellationReason - The cancellation reason.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {TranslationRecognitionResult} result - The result.\n     */\n    constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {\n        this.privCancelReason = cancellationReason;\n        this.privErrorDetails = errorDetails;\n        this.privResult = result;\n        this.privSessionId = sessionid;\n        this.privErrorCode = errorCode;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n    /**\n     * Specifies the session identifier.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId\n     * @function\n     * @public\n     * @returns {string} the session identifier.\n     */\n    get sessionId() {\n        return this.privSessionId;\n    }\n    /**\n     * The reason the recognition was canceled.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.reason\n     * @function\n     * @public\n     * @returns {CancellationReason} Specifies the reason canceled.\n     */\n    get reason() {\n        return this.privCancelReason;\n    }\n    /**\n     * The error code in case of an unsuccessful recognition.\n     * Added in version 1.1.0.\n     * @return An error code that represents the error reason.\n     */\n    get errorCode() {\n        return this.privErrorCode;\n    }\n    /**\n     * In case of an unsuccessful recognition, provides details of the occurred error.\n     * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails\n     * @function\n     * @public\n     * @returns {string} A String that represents the error details.\n     */\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionCanceledEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js ***!
  \***********************************************************************************************************************/
/*! exports provided: TranslationRecognitionEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionEventArgs\", function() { return TranslationRecognitionEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result event arguments.\n * @class TranslationRecognitionEventArgs\n */\nclass TranslationRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationRecognitionResult} result - The translation recognition result.\n     * @param {number} offset - The offset.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, offset, sessionId) {\n        super(offset, sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the recognition result.\n     * @member TranslationRecognitionEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationRecognitionResult} the recognition result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js ***!
  \********************************************************************************************************************/
/*! exports provided: TranslationRecognitionResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognitionResult\", function() { return TranslationRecognitionResult; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result.\n * @class TranslationRecognitionResult\n */\nclass TranslationRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeechRecognitionResult\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {Translations} translations - The translations.\n     * @param {string} resultId - The result id.\n     * @param {ResultReason} reason - The reason.\n     * @param {string} text - The recognized text.\n     * @param {number} duration - The duration.\n     * @param {number} offset - The offset into the stream.\n     * @param {string} errorDetails - Error details, if provided.\n     * @param {string} json - Additional Json, if provided.\n     * @param {PropertyCollection} properties - Additional properties, if provided.\n     */\n    constructor(translations, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n        super(resultId, reason, text, duration, offset, undefined, undefined, undefined, errorDetails, json, properties);\n        this.privTranslations = translations;\n    }\n    /**\n     * Presents the translation results. Each item in the dictionary represents\n     * a translation result in one of target languages, where the key is the name\n     * of the target language, in BCP-47 format, and the value is the translation\n     * text in the specified language.\n     * @member TranslationRecognitionResult.prototype.translations\n     * @function\n     * @public\n     * @returns {Translations} the current translation map that holds all translations requested.\n     */\n    get translations() {\n        return this.privTranslations;\n    }\n}\n\n//# sourceMappingURL=TranslationRecognitionResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js ***!
  \*************************************************************************************************************/
/*! exports provided: TranslationRecognizer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationRecognizer\", function() { return TranslationRecognizer; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Exports.js\");\n/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Connection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n/**\n * Translation recognizer\n * @class TranslationRecognizer\n */\nclass TranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_4__[\"Recognizer\"] {\n    /**\n     * Initializes an instance of the TranslationRecognizer.\n     * @constructor\n     * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.\n     * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n     */\n    constructor(speechConfig, audioConfig) {\n        const configImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNull(configImpl, \"speechConfig\");\n        super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"TranslationConnectionFactory\"]());\n        this.privDisposedTranslationRecognizer = false;\n        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {\n            _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice), _Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice]);\n        }\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages), _Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages]);\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"][_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage]);\n    }\n    /**\n     * Gets the language name that was set when the recognizer was created.\n     * @member TranslationRecognizer.prototype.speechRecognitionLanguage\n     * @function\n     * @public\n     * @returns {string} Gets the language name that was set when the recognizer was created.\n     */\n    get speechRecognitionLanguage() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_RecoLanguage);\n    }\n    /**\n     * Gets target languages for translation that were set when the recognizer was created.\n     * The language is specified in BCP-47 format. The translation will provide translated text for each of language.\n     * @member TranslationRecognizer.prototype.targetLanguages\n     * @function\n     * @public\n     * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.\n     */\n    get targetLanguages() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages).split(\",\");\n    }\n    /**\n     * Gets the name of output voice.\n     * @member TranslationRecognizer.prototype.voiceName\n     * @function\n     * @public\n     * @returns {string} the name of output voice.\n     */\n    get voiceName() {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privDisposedTranslationRecognizer);\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationVoice, undefined);\n    }\n    /**\n     * The collection of properties and their values defined for this TranslationRecognizer.\n     * @member TranslationRecognizer.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member TranslationRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member TranslationRecognizer.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} value - Authorization token.\n     */\n    set authorizationToken(value) {\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceAuthorization_Token, value);\n    }\n    /**\n     * Starts recognition and translation, and stops after the first utterance is recognized.\n     * The task returns the translation text as result.\n     * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only\n     * for single shot recognition like command or query. For long-running recognition,\n     * use startContinuousRecognitionAsync() instead.\n     * @member TranslationRecognizer.prototype.recognizeOnceAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the result when the translation has completed.\n     * @param err - Callback invoked in case of an error.\n     */\n    recognizeOnceAsync(cb, err) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privDisposedTranslationRecognizer);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Conversation), cb, err);\n    }\n    /**\n     * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.\n     * User must subscribe to events to receive translation results.\n     * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the translation has started.\n     * @param err - Callback invoked in case of an error.\n     */\n    startContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognitionMode\"].Conversation), cb, err);\n    }\n    /**\n     * Stops continuous recognition and translation.\n     * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync\n     * @function\n     * @public\n     * @param cb - Callback that received the translation has stopped.\n     * @param err - Callback invoked in case of an error.\n     */\n    stopContinuousRecognitionAsync(cb, err) {\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n    }\n    /**\n     * dynamically remove a language from list of target language\n     * (can be used while recognition is ongoing)\n     * @member TranslationRecognizer.prototype.removeTargetLanguage\n     * @function\n     * @param lang - language to be removed\n     * @public\n     */\n    removeTargetLanguage(lang) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrUndefined(lang, \"language to be removed\");\n        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            const languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages).split(\",\");\n            const index = languages.indexOf(lang);\n            if (index > -1) {\n                languages.splice(index, 1);\n                this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n                this.updateLanguages(languages);\n            }\n        }\n    }\n    /**\n     * dynamically add a language to list of target language\n     * (can be used while recognition is ongoing)\n     * @member TranslationRecognizer.prototype.addTargetLanguage\n     * @function\n     * @param lang - language to be added\n     * @public\n     */\n    addTargetLanguage(lang) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfNullOrUndefined(lang, \"language to be added\");\n        let languages = [];\n        if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n            languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages).split(\",\");\n            if (!languages.includes(lang)) {\n                languages.push(lang);\n                this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n            }\n        }\n        else {\n            this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__[\"PropertyId\"].SpeechServiceConnection_TranslationToLanguages, lang);\n            languages = [lang];\n        }\n        this.updateLanguages(languages);\n    }\n    /**\n     * closes all external resources held by an instance of this class.\n     * @member TranslationRecognizer.prototype.close\n     * @function\n     * @public\n     */\n    close(cb, errorCb) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_3__[\"Contracts\"].throwIfDisposed(this.privDisposedTranslationRecognizer);\n        Object(_common_Exports__WEBPACK_IMPORTED_MODULE_1__[\"marshalPromiseToCallbacks\"])(this.dispose(true), cb, errorCb);\n    }\n    /**\n     * handles ConnectionEstablishedEvent for conversation translation scenarios.\n     * @member TranslationRecognizer.prototype.onConnection\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    onConnection() { }\n    /**\n     * handles disconnection events for conversation translation scenarios.\n     * @member TranslationRecognizer.prototype.onDisconnection\n     * @function\n     * @public\n     */\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    onDisconnection() {\n        return __awaiter(this, void 0, void 0, function* () { });\n    }\n    dispose(disposing) {\n        const _super = Object.create(null, {\n            dispose: { get: () => super.dispose }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.privDisposedTranslationRecognizer) {\n                return;\n            }\n            this.privDisposedTranslationRecognizer = true;\n            if (disposing) {\n                yield this.implRecognizerStop();\n                yield _super.dispose.call(this, disposing);\n            }\n        });\n    }\n    createRecognizerConfig(speechConfig) {\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"RecognizerConfig\"](speechConfig, this.properties);\n    }\n    createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n        const configImpl = audioConfig;\n        return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"TranslationServiceRecognizer\"](authentication, connectionFactory, configImpl, recognizerConfig, this);\n    }\n    updateLanguages(languages) {\n        const conn = _Connection__WEBPACK_IMPORTED_MODULE_2__[\"Connection\"].fromRecognizer(this);\n        if (!!conn) {\n            conn.setMessageProperty(\"speech.context\", \"translationcontext\", { to: languages });\n            conn.sendMessageAsync(\"event\", JSON.stringify({\n                id: \"translation\",\n                name: \"updateLanguage\",\n                to: languages\n            }));\n        }\n    }\n}\n\n//# sourceMappingURL=TranslationRecognizer.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js ***!
  \*********************************************************************************************************************/
/*! exports provided: TranslationSynthesisEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisEventArgs\", function() { return TranslationSynthesisEventArgs; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation Synthesis event arguments\n * @class TranslationSynthesisEventArgs\n */\nclass TranslationSynthesisEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__[\"SessionEventArgs\"] {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {TranslationSynthesisResult} result - The translation synthesis result.\n     * @param {string} sessionId - The session id.\n     */\n    constructor(result, sessionId) {\n        super(sessionId);\n        this.privResult = result;\n    }\n    /**\n     * Specifies the translation synthesis result.\n     * @member TranslationSynthesisEventArgs.prototype.result\n     * @function\n     * @public\n     * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.\n     */\n    get result() {\n        return this.privResult;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js ***!
  \******************************************************************************************************************/
/*! exports provided: TranslationSynthesisResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TranslationSynthesisResult\", function() { return TranslationSynthesisResult; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation synthesis result, i.e. the voice output of the translated\n * text in the target language.\n * @class TranslationSynthesisResult\n */\nclass TranslationSynthesisResult {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {ResultReason} reason - The synthesis reason.\n     * @param {ArrayBuffer} audio - The audio data.\n     */\n    constructor(reason, audio) {\n        this.privReason = reason;\n        this.privAudio = audio;\n    }\n    /**\n     * Translated text in the target language.\n     * @member TranslationSynthesisResult.prototype.audio\n     * @function\n     * @public\n     * @returns {ArrayBuffer} Translated audio in the target language.\n     */\n    get audio() {\n        return this.privAudio;\n    }\n    /**\n     * The synthesis status.\n     * @member TranslationSynthesisResult.prototype.reason\n     * @function\n     * @public\n     * @returns {ResultReason} The synthesis status.\n     */\n    get reason() {\n        return this.privReason;\n    }\n}\n\n//# sourceMappingURL=TranslationSynthesisResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js ***!
  \****************************************************************************************************/
/*! exports provided: Translations */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Translations\", function() { return Translations; });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of parameters and their values.\n * @class Translations\n */\nclass Translations {\n    constructor() {\n        // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.\n        this.privMap = new _Exports__WEBPACK_IMPORTED_MODULE_0__[\"PropertyCollection\"]();\n    }\n    /**\n     * Get the languages in the object in a String array.\n     * @member Translations.prototype.languages\n     * @function\n     * @public\n     * @returns {string[]} languages in translations object.\n     */\n    get languages() {\n        return this.privMap.keys;\n    }\n    /**\n     * Returns the parameter value in type String. The parameter must have the same type as String.\n     * Currently only String, int and bool are allowed.\n     * If the name is not available, the specified defaultValue is returned.\n     * @member Translations.prototype.get\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} def - The default value which is returned if the parameter is not available in the collection.\n     * @returns {string} value of the parameter.\n     */\n    get(key, def) {\n        return this.privMap.getProperty(key, def);\n    }\n    /**\n     * Sets the String value of the parameter specified by name.\n     * @member Translations.prototype.set\n     * @function\n     * @public\n     * @param {string} key - The parameter name.\n     * @param {string} value - The value of the parameter.\n     */\n    set(key, value) {\n        this.privMap.setProperty(key, value);\n    }\n}\n\n//# sourceMappingURL=Translations.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \*******************************************************************************************************************/
/*! exports provided: TurnStatusReceivedEventArgs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TurnStatusReceivedEventArgs\", function() { return TurnStatusReceivedEventArgs; });\n/* harmony import */ var _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines contents of received message/events.\n * @class TurnStatusReceivedEventArgs\n */\nclass TurnStatusReceivedEventArgs {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} turnStatus - The JSON-encoded turn status message.\n     */\n    constructor(turnStatus) {\n        this.privTurnStatus = _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__[\"TurnStatusResponsePayload\"].fromJSON(turnStatus);\n    }\n    /**\n     * Gets the interaction identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.interactionId\n     * @function\n     * @public\n     * @returns {any} the received interaction id.\n     */\n    get interactionId() {\n        return this.privTurnStatus.interactionId;\n    }\n    /**\n     * Gets the conversation identifier associated with this turn status event.\n     * @member TurnStatusReceivedEventArgs.prototype.conversationId\n     * @function\n     * @public\n     * @returns {any} the received conversation id.\n     */\n    get conversationId() {\n        return this.privTurnStatus.conversationId;\n    }\n    /**\n     * Gets the received turn status code.\n     * @member TurnStatusReceivedEventArgs.prototype.statusCode\n     * @function\n     * @public\n     * @returns {number} the received turn status.\n     */\n    get statusCode() {\n        return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return\n    }\n}\n\n//# sourceMappingURL=TurnStatusReceivedEventArgs.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js ***!
  \*************************************************************************************************/
/*! exports provided: SynthesisVoiceGender, SynthesisVoiceType, VoiceInfo */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisVoiceGender\", function() { return SynthesisVoiceGender; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SynthesisVoiceType\", function() { return SynthesisVoiceType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceInfo\", function() { return VoiceInfo; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the gender of synthesis voices.\n * Added in version 1.20.0.\n */\nvar SynthesisVoiceGender;\n(function (SynthesisVoiceGender) {\n    /** Gender unknown */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Unknown\"] = 0] = \"Unknown\";\n    /** Female voice */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Female\"] = 1] = \"Female\";\n    /** Male voice */\n    SynthesisVoiceGender[SynthesisVoiceGender[\"Male\"] = 2] = \"Male\";\n})(SynthesisVoiceGender || (SynthesisVoiceGender = {}));\nvar SynthesisVoiceType;\n(function (SynthesisVoiceType) {\n    SynthesisVoiceType[SynthesisVoiceType[\"OnlineNeural\"] = 1] = \"OnlineNeural\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OnlineStandard\"] = 2] = \"OnlineStandard\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OfflineNeural\"] = 3] = \"OfflineNeural\";\n    SynthesisVoiceType[SynthesisVoiceType[\"OfflineStandard\"] = 4] = \"OfflineStandard\";\n})(SynthesisVoiceType || (SynthesisVoiceType = {}));\n/**\n * Information about Speech Synthesis voice\n * Added in version 1.20.0.\n * @class VoiceInfo\n */\nclass VoiceInfo {\n    constructor(json) {\n        this.privStyleList = [];\n        this.privVoicePath = \"\";\n        if (!!json) {\n            this.privName = json.Name;\n            this.privLocale = json.Locale;\n            this.privShortName = json.ShortName;\n            this.privLocalName = json.LocalName;\n            this.privVoiceType = json.VoiceType.endsWith(\"Standard\") ? SynthesisVoiceType.OnlineStandard : SynthesisVoiceType.OnlineNeural;\n            this.privGender = json.Gender === \"Male\" ? SynthesisVoiceGender.Male : json.Gender === \"Female\" ? SynthesisVoiceGender.Female : SynthesisVoiceGender.Unknown;\n            if (!!json.StyleList && Array.isArray(json.StyleList)) {\n                for (const style of json.StyleList) {\n                    this.privStyleList.push(style);\n                }\n            }\n        }\n    }\n    get name() {\n        return this.privName;\n    }\n    get locale() {\n        return this.privLocale;\n    }\n    get shortName() {\n        return this.privShortName;\n    }\n    get localName() {\n        return this.privLocalName;\n    }\n    get gender() {\n        return this.privGender;\n    }\n    get voiceType() {\n        return this.privVoiceType;\n    }\n    get styleList() {\n        return this.privStyleList;\n    }\n    get voicePath() {\n        return this.privVoicePath;\n    }\n}\n\n//# sourceMappingURL=VoiceInfo.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js ***!
  \****************************************************************************************************/
/*! exports provided: VoiceProfile */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfile\", function() { return VoiceProfile; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines Voice Profile class for Speaker Recognition\n * @class VoiceProfile\n */\nclass VoiceProfile {\n    /**\n     * Creates and initializes an instance of this class.\n     * @constructor\n     * @param {string} profileId - profileId of this Voice Profile.\n     * @param {VoiceProfileType} profileType - profileType of this Voice Profile.\n     */\n    constructor(profileId, profileType) {\n        this.privId = profileId;\n        this.privProfileType = profileType;\n    }\n    /**\n     * profileId of this Voice Profile instance\n     * @member VoiceProfile.prototype.profileId\n     * @function\n     * @public\n     * @returns {string} profileId of this Voice Profile instance.\n     */\n    get profileId() {\n        return this.privId;\n    }\n    /**\n     * profileType of this Voice Profile instance\n     * @member VoiceProfile.prototype.profileType\n     * @function\n     * @public\n     * @returns {VoiceProfileType} profile type of this Voice Profile instance.\n     */\n    get profileType() {\n        return this.privProfileType;\n    }\n}\n\n//# sourceMappingURL=VoiceProfile.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js ***!
  \**********************************************************************************************************/
/*! exports provided: VoiceProfileClient */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileClient\", function() { return VoiceProfileClient; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n/**\n * Defines VoiceProfileClient class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class VoiceProfileClient\n */\nclass VoiceProfileClient {\n    /**\n     * VoiceProfileClient constructor.\n     * @constructor\n     * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)\n     */\n    constructor(speechConfig) {\n        const speechConfigImpl = speechConfig;\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNull(speechConfigImpl, \"speechConfig\");\n        this.privProperties = speechConfigImpl.properties.clone();\n        this.implClientSetup();\n    }\n    /**\n     * The collection of properties and their values defined for this VoiceProfileClient.\n     * @member VoiceProfileClient.prototype.properties\n     * @function\n     * @public\n     * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.\n     */\n    get properties() {\n        return this.privProperties;\n    }\n    /**\n     * Gets the authorization token used to communicate with the service.\n     * @member VoiceProfileClient.prototype.authorizationToken\n     * @function\n     * @public\n     * @returns {string} Authorization token.\n     */\n    get authorizationToken() {\n        return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token);\n    }\n    /**\n     * Gets/Sets the authorization token used to communicate with the service.\n     * @member VoiceProfileClient.prototype.authorizationToken\n     * @function\n     * @public\n     * @param {string} token - Authorization token.\n     */\n    set authorizationToken(token) {\n        _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrWhitespace(token, \"token\");\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyId\"].SpeechServiceAuthorization_Token, token);\n    }\n    /**\n     * Create a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.createProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType Type of Voice Profile to be created\n     * @param {string} lang Language string (locale) for Voice Profile\n     * @return {Promise<VoiceProfile>} - Promise of a VoiceProfile.\n     */\n    createProfileAsync(profileType, lang) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.createProfile(profileType, lang);\n            if (!result.ok) {\n                throw new Error(`createProfileAsync failed with code: ${result.status}, message: ${result.statusText}`);\n            }\n            const response = result.json;\n            const profile = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfile\"](response.profileId, profileType);\n            return profile;\n        });\n    }\n    /**\n     * Get current information of a voice profile\n     * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to retrieve info for\n     * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n     */\n    retrieveEnrollmentResultAsync(profile) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.getProfileStatus(profile);\n            return new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentResult\"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled, result.data, result.statusText);\n        });\n    }\n    /**\n     * Get all voice profiles on account with given voice profile type\n     * @member VoiceProfileClient.prototype.getAllProfilesAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles\n     * @return {Promise<VoiceProfileEnrollmentResult[]>} - Promise of an array of VoiceProfileEnrollmentResults.\n     */\n    getAllProfilesAsync(profileType) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.getProfiles(profileType);\n            if (profileType === _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileType\"].TextIndependentIdentification) {\n                return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentResult\"].FromIdentificationProfileList(result.json);\n            }\n            return _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentResult\"].FromVerificationProfileList(result.json);\n        });\n    }\n    /**\n     * Get valid authorization phrases for voice profile enrollment\n     * @member VoiceProfileClient.prototype.getAuthorizationPhrasesAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfileType} profileType Profile Type to get activation phrases for\n     * @param {string} lang Language string (locale) for Voice Profile\n     */\n    getActivationPhrasesAsync(profileType, lang) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.getPhrases(profileType, lang);\n            return new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfilePhraseResult\"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].EnrollingVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled, result.statusText, result.json);\n        });\n    }\n    /**\n     * Create a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.enrollProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to create enrollment for\n     * @param {AudioConfig} audioConfig source info from which to create enrollment\n     * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n     */\n    enrollProfileAsync(profile, audioConfig) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const configImpl = audioConfig;\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(configImpl, \"audioConfig\");\n            const result = yield this.privAdapter.createEnrollment(profile, configImpl);\n            return new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileEnrollmentResult\"](result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled, result.data, result.statusText);\n        });\n    }\n    /**\n     * Delete a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.deleteProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to be deleted\n     * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n     */\n    deleteProfileAsync(profile) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.deleteProfile(profile);\n            return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].DeletedVoiceProfile);\n        });\n    }\n    /**\n     * Remove all enrollments for a speaker recognition voice profile\n     * @member VoiceProfileClient.prototype.resetProfileAsync\n     * @function\n     * @public\n     * @async\n     * @param {VoiceProfile} profile Voice Profile to be reset\n     * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n     */\n    resetProfileAsync(profile) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield this.privAdapter.resetProfile(profile);\n            return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].ResetVoiceProfile);\n        });\n    }\n    /**\n     * Included for compatibility\n     * @member VoiceProfileClient.prototype.close\n     * @function\n     * @public\n     */\n    close() {\n        return;\n    }\n    // Does class setup, swiped from Recognizer.\n    implClientSetup() {\n        let osPlatform = (typeof window !== \"undefined\") ? \"Browser\" : \"Node\";\n        let osName = \"unknown\";\n        let osVersion = \"unknown\";\n        if (typeof navigator !== \"undefined\") {\n            osPlatform = osPlatform + \"/\" + navigator.platform;\n            osName = navigator.userAgent;\n            osVersion = navigator.appVersion;\n        }\n        const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeakerRecognitionConfig\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"Context\"](new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"OS\"](osPlatform, osName, osVersion)), this.privProperties);\n        this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"SpeakerIdMessageAdapter\"](recognizerConfig);\n    }\n    getResult(result, successReason) {\n        const response = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"VoiceProfileResult\"](result.ok ? successReason : _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled, result.statusText);\n        return (response);\n    }\n}\n\n//# sourceMappingURL=VoiceProfileClient.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js ***!
  \********************************************************************************************************************/
/*! exports provided: VoiceProfileEnrollmentResult, VoiceProfileEnrollmentCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentResult\", function() { return VoiceProfileEnrollmentResult; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileEnrollmentCancellationDetails\", function() { return VoiceProfileEnrollmentCancellationDetails; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\nconst parse = (json) => JSON.parse(json);\n/**\n * Output format\n * @class VoiceProfileEnrollmentResult\n */\nclass VoiceProfileEnrollmentResult {\n    constructor(reason, json, statusText) {\n        this.privReason = reason;\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__[\"PropertyCollection\"]();\n        if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled) {\n            if (!!json) {\n                this.privDetails = parse(json);\n                if (this.privDetails.enrollmentStatus.toLowerCase() === \"enrolling\") {\n                    this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].EnrollingVoiceProfile;\n                }\n            }\n        }\n        else {\n            this.privErrorDetails = statusText;\n            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].ServiceError]);\n        }\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get enrollmentsCount() {\n        return this.privDetails.enrollmentsCount;\n    }\n    get enrollmentsLengthInSec() {\n        return this.privDetails.enrollmentsLengthInSec;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get enrollmentResultDetails() {\n        return this.privDetails;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n    static FromIdentificationProfileList(json) {\n        const results = [];\n        for (const item of json.value) {\n            const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ?\n                _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ?\n                _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled;\n            const result = new VoiceProfileEnrollmentResult(reason, null, null);\n            result.privDetails = this.getIdentificationDetails(item);\n            results.push(result);\n        }\n        return results;\n    }\n    static FromVerificationProfileList(json) {\n        const results = [];\n        for (const item of json.value) {\n            const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ?\n                _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ?\n                _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__[\"ResultReason\"].Canceled;\n            const result = new VoiceProfileEnrollmentResult(reason, null, null);\n            result.privDetails = this.getVerificationDetails(item);\n            results.push(result);\n        }\n        return results;\n    }\n    static getIdentificationDetails(json) {\n        return {\n            audioLengthInSec: json.audioLengthInSec ? parseFloat(json.audioLengthInSec) : 0,\n            audioSpeechLengthInSec: json.audioSpeechLengthInSec ? parseFloat(json.audioSpeechLengthInSec) : 0,\n            enrollmentStatus: json.enrollmentStatus,\n            enrollmentsCount: json.enrollmentsCount || 0,\n            enrollmentsLengthInSec: json.enrollmentsLengthInSec ? parseFloat(json.enrollmentsLengthInSec) : 0,\n            enrollmentsSpeechLengthInSec: json.enrollmentsSpeechLengthInSec ? parseFloat(json.enrollmentsSpeechLengthInSec) : 0,\n            profileId: json.profileId || json.identificationProfileId,\n            remainingEnrollmentsSpeechLengthInSec: json.remainingEnrollmentsSpeechLengthInSec ? parseFloat(json.remainingEnrollmentsSpeechLengthInSec) : 0\n        };\n    }\n    static getVerificationDetails(json) {\n        return {\n            audioLengthInSec: json.audioLengthInSec ? parseFloat(json.audioLengthInSec) : 0,\n            audioSpeechLengthInSec: json.audioSpeechLengthInSec ? parseFloat(json.audioSpeechLengthInSec) : 0,\n            enrollmentStatus: json.enrollmentStatus,\n            enrollmentsCount: json.enrollmentsCount,\n            enrollmentsLengthInSec: json.enrollmentsLengthInSec ? parseFloat(json.enrollmentsLengthInSec) : 0,\n            enrollmentsSpeechLengthInSec: json.enrollmentsSpeechLengthInSec ? parseFloat(json.enrollmentsSpeechLengthInSec) : 0,\n            profileId: json.profileId || json.verificationProfileId,\n            remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount,\n            remainingEnrollmentsSpeechLengthInSec: json.remainingEnrollmentsSpeechLengthInSec ? parseFloat(json.remainingEnrollmentsSpeechLengthInSec) : 0\n        };\n    }\n}\n/**\n * @class VoiceProfileEnrollmentCancellationDetails\n */\nclass VoiceProfileEnrollmentCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationDetailsBase\"] {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.\n     * @member VoiceProfileEnrollmentCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.\n     * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationReason\"].Error;\n        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].NoError;\n        if (!!result.properties) {\n            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_1__[\"CancellationErrorCode\"].NoError])]; //eslint-disable-line\n        }\n        return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\n\n//# sourceMappingURL=VoiceProfileEnrollmentResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js ***!
  \****************************************************************************************************************/
/*! exports provided: VoiceProfilePhraseResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfilePhraseResult\", function() { return VoiceProfilePhraseResult; });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Output format\n * @class VoiceProfilePhraseResult\n */\nclass VoiceProfilePhraseResult extends _Exports__WEBPACK_IMPORTED_MODULE_1__[\"VoiceProfileResult\"] {\n    constructor(reason, statusText, json) {\n        super(reason, statusText);\n        this.privPhrases = [];\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__[\"Contracts\"].throwIfNullOrUndefined(json, \"phrase result JSON\");\n        if (!!json.value && !!json.value[0]) {\n            for (const item of json.value) {\n                this.privPhrases.push(item.passPhrase || item.activationPhrase);\n            }\n        }\n    }\n    get phrases() {\n        return this.privPhrases;\n    }\n}\n\n//# sourceMappingURL=VoiceProfilePhraseResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js ***!
  \**********************************************************************************************************/
/*! exports provided: VoiceProfileResult, VoiceProfileCancellationDetails */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileResult\", function() { return VoiceProfileResult; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileCancellationDetails\", function() { return VoiceProfileCancellationDetails; });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Output format\n * @class VoiceProfileResult\n */\nclass VoiceProfileResult {\n    constructor(reason, statusText) {\n        this.privReason = reason;\n        this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__[\"PropertyCollection\"]();\n        if (reason === _Exports__WEBPACK_IMPORTED_MODULE_2__[\"ResultReason\"].Canceled) {\n            _Contracts__WEBPACK_IMPORTED_MODULE_1__[\"Contracts\"].throwIfNullOrUndefined(statusText, \"statusText\");\n            this.privErrorDetails = statusText;\n            this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].ServiceError]);\n        }\n    }\n    get reason() {\n        return this.privReason;\n    }\n    get properties() {\n        return this.privProperties;\n    }\n    get errorDetails() {\n        return this.privErrorDetails;\n    }\n}\n/**\n * @class VoiceProfileCancellationDetails\n */\nclass VoiceProfileCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationDetailsBase\"] {\n    constructor(reason, errorDetails, errorCode) {\n        super(reason, errorDetails, errorCode);\n    }\n    /**\n     * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.\n     * @member VoiceProfileCancellationDetails.fromResult\n     * @function\n     * @public\n     * @param {VoiceProfileResult} result - The result that was canceled.\n     * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.\n     */\n    static fromResult(result) {\n        const reason = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationReason\"].Error;\n        let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError;\n        if (!!result.properties) {\n            errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__[\"CancellationErrorCodePropertyName\"], _Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"][_Exports__WEBPACK_IMPORTED_MODULE_2__[\"CancellationErrorCode\"].NoError])]; //eslint-disable-line\n        }\n        return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);\n    }\n}\n\n//# sourceMappingURL=VoiceProfileResult.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js ***!
  \********************************************************************************************************/
/*! exports provided: VoiceProfileType */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VoiceProfileType\", function() { return VoiceProfileType; });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Output format\n * @class VoiceProfileType\n */\nvar VoiceProfileType;\n(function (VoiceProfileType) {\n    /**\n     * Text independent speaker identification\n     * @member VoiceProfileType.TextIndependentIdentification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentIdentification\"] = 0] = \"TextIndependentIdentification\";\n    /**\n     * Text dependent speaker verification\n     * @member VoiceProfileType.TextDependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextDependentVerification\"] = 1] = \"TextDependentVerification\";\n    /**\n     * Text independent speaker verification\n     * @member VoiceProfileType.TextIndependentVerification\n     */\n    VoiceProfileType[VoiceProfileType[\"TextIndependentVerification\"] = 2] = \"TextIndependentVerification\";\n})(VoiceProfileType || (VoiceProfileType = {}));\n\n//# sourceMappingURL=VoiceProfileType.js.map\n\n\n//# sourceURL=webpack:///./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/index.js ***!
  \*****************************************************/
/*! exports provided: v1, v3, v4, v5, NIL, version, validate, stringify, parse */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _v1_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v1.js */ \"./node_modules/uuid/dist/esm-browser/v1.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"v1\", function() { return _v1_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]; });\n\n/* harmony import */ var _v3_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./v3.js */ \"./node_modules/uuid/dist/esm-browser/v3.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"v3\", function() { return _v3_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]; });\n\n/* harmony import */ var _v4_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./v4.js */ \"./node_modules/uuid/dist/esm-browser/v4.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"v4\", function() { return _v4_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]; });\n\n/* harmony import */ var _v5_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./v5.js */ \"./node_modules/uuid/dist/esm-browser/v5.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"v5\", function() { return _v5_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]; });\n\n/* harmony import */ var _nil_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./nil.js */ \"./node_modules/uuid/dist/esm-browser/nil.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NIL\", function() { return _nil_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]; });\n\n/* harmony import */ var _version_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./version.js */ \"./node_modules/uuid/dist/esm-browser/version.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"version\", function() { return _version_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"]; });\n\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"validate\", function() { return _validate_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"]; });\n\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"stringify\", function() { return _stringify_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]; });\n\n/* harmony import */ var _parse_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/esm-browser/parse.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"parse\", function() { return _parse_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"]; });\n\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/index.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/md5.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/md5.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/*\n * Browser-compatible JavaScript MD5\n *\n * Modification of JavaScript MD5\n * https://github.com/blueimp/JavaScript-MD5\n *\n * Copyright 2011, Sebastian Tschan\n * https://blueimp.net\n *\n * Licensed under the MIT license:\n * https://opensource.org/licenses/MIT\n *\n * Based on\n * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message\n * Digest Algorithm, as defined in RFC 1321.\n * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n * Distributed under the BSD License\n * See http://pajhome.org.uk/crypt/md5 for more info.\n */\nfunction md5(bytes) {\n  if (typeof bytes === 'string') {\n    var msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = new Uint8Array(msg.length);\n\n    for (var i = 0; i < msg.length; ++i) {\n      bytes[i] = msg.charCodeAt(i);\n    }\n  }\n\n  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));\n}\n/*\n * Convert an array of little-endian words to an array of bytes\n */\n\n\nfunction md5ToHexEncodedArray(input) {\n  var output = [];\n  var length32 = input.length * 32;\n  var hexTab = '0123456789abcdef';\n\n  for (var i = 0; i < length32; i += 8) {\n    var x = input[i >> 5] >>> i % 32 & 0xff;\n    var hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);\n    output.push(hex);\n  }\n\n  return output;\n}\n/**\n * Calculate output length with padding and bit length\n */\n\n\nfunction getOutputLength(inputLength8) {\n  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;\n}\n/*\n * Calculate the MD5 of an array of little-endian words, and a bit length.\n */\n\n\nfunction wordsToMd5(x, len) {\n  /* append padding */\n  x[len >> 5] |= 0x80 << len % 32;\n  x[getOutputLength(len) - 1] = len;\n  var a = 1732584193;\n  var b = -271733879;\n  var c = -1732584194;\n  var d = 271733878;\n\n  for (var i = 0; i < x.length; i += 16) {\n    var olda = a;\n    var oldb = b;\n    var oldc = c;\n    var oldd = d;\n    a = md5ff(a, b, c, d, x[i], 7, -680876936);\n    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);\n    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);\n    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);\n    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);\n    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);\n    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);\n    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);\n    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);\n    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);\n    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);\n    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);\n    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);\n    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);\n    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);\n    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);\n    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);\n    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);\n    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);\n    b = md5gg(b, c, d, a, x[i], 20, -373897302);\n    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);\n    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);\n    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);\n    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);\n    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);\n    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);\n    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);\n    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);\n    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);\n    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);\n    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);\n    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);\n    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);\n    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);\n    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);\n    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);\n    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);\n    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);\n    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);\n    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);\n    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);\n    d = md5hh(d, a, b, c, x[i], 11, -358537222);\n    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);\n    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);\n    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);\n    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);\n    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);\n    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);\n    a = md5ii(a, b, c, d, x[i], 6, -198630844);\n    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);\n    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);\n    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);\n    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);\n    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);\n    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);\n    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);\n    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);\n    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);\n    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);\n    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);\n    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);\n    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);\n    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);\n    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);\n    a = safeAdd(a, olda);\n    b = safeAdd(b, oldb);\n    c = safeAdd(c, oldc);\n    d = safeAdd(d, oldd);\n  }\n\n  return [a, b, c, d];\n}\n/*\n * Convert an array bytes to an array of little-endian words\n * Characters >255 have their high-byte silently ignored.\n */\n\n\nfunction bytesToWords(input) {\n  if (input.length === 0) {\n    return [];\n  }\n\n  var length8 = input.length * 8;\n  var output = new Uint32Array(getOutputLength(length8));\n\n  for (var i = 0; i < length8; i += 8) {\n    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;\n  }\n\n  return output;\n}\n/*\n * Add integers, wrapping at 2^32. This uses 16-bit operations internally\n * to work around bugs in some JS interpreters.\n */\n\n\nfunction safeAdd(x, y) {\n  var lsw = (x & 0xffff) + (y & 0xffff);\n  var msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n  return msw << 16 | lsw & 0xffff;\n}\n/*\n * Bitwise rotate a 32-bit number to the left.\n */\n\n\nfunction bitRotateLeft(num, cnt) {\n  return num << cnt | num >>> 32 - cnt;\n}\n/*\n * These functions implement the four basic operations the algorithm uses.\n */\n\n\nfunction md5cmn(q, a, b, x, s, t) {\n  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);\n}\n\nfunction md5ff(a, b, c, d, x, s, t) {\n  return md5cmn(b & c | ~b & d, a, b, x, s, t);\n}\n\nfunction md5gg(a, b, c, d, x, s, t) {\n  return md5cmn(b & d | c & ~d, a, b, x, s, t);\n}\n\nfunction md5hh(a, b, c, d, x, s, t) {\n  return md5cmn(b ^ c ^ d, a, b, x, s, t);\n}\n\nfunction md5ii(a, b, c, d, x, s, t) {\n  return md5cmn(c ^ (b | ~d), a, b, x, s, t);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (md5);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/md5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/nil.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/nil.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony default export */ __webpack_exports__[\"default\"] = ('00000000-0000-0000-0000-000000000000');\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/nil.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/parse.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/parse.js ***!
  \*****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n\nfunction parse(uuid) {\n  if (!Object(_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  var v;\n  var arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (parse);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/parse.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/regex.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
  \*****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony default export */ __webpack_exports__[\"default\"] = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/regex.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/rng.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
  \***************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return rng; });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nvar getRandomValues;\nvar rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation. Also,\n    // find the complete implementation of crypto (msCrypto) on IE11.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/rng.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/sha1.js":
/*!****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/sha1.js ***!
  \****************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// Adapted from Chris Veness' SHA1 code at\n// http://www.movable-type.co.uk/scripts/sha1.html\nfunction f(s, x, y, z) {\n  switch (s) {\n    case 0:\n      return x & y ^ ~x & z;\n\n    case 1:\n      return x ^ y ^ z;\n\n    case 2:\n      return x & y ^ x & z ^ y & z;\n\n    case 3:\n      return x ^ y ^ z;\n  }\n}\n\nfunction ROTL(x, n) {\n  return x << n | x >>> 32 - n;\n}\n\nfunction sha1(bytes) {\n  var K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];\n  var H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n\n  if (typeof bytes === 'string') {\n    var msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = [];\n\n    for (var i = 0; i < msg.length; ++i) {\n      bytes.push(msg.charCodeAt(i));\n    }\n  } else if (!Array.isArray(bytes)) {\n    // Convert Array-like to Array\n    bytes = Array.prototype.slice.call(bytes);\n  }\n\n  bytes.push(0x80);\n  var l = bytes.length / 4 + 2;\n  var N = Math.ceil(l / 16);\n  var M = new Array(N);\n\n  for (var _i = 0; _i < N; ++_i) {\n    var arr = new Uint32Array(16);\n\n    for (var j = 0; j < 16; ++j) {\n      arr[j] = bytes[_i * 64 + j * 4] << 24 | bytes[_i * 64 + j * 4 + 1] << 16 | bytes[_i * 64 + j * 4 + 2] << 8 | bytes[_i * 64 + j * 4 + 3];\n    }\n\n    M[_i] = arr;\n  }\n\n  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);\n  M[N - 1][14] = Math.floor(M[N - 1][14]);\n  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;\n\n  for (var _i2 = 0; _i2 < N; ++_i2) {\n    var W = new Uint32Array(80);\n\n    for (var t = 0; t < 16; ++t) {\n      W[t] = M[_i2][t];\n    }\n\n    for (var _t = 16; _t < 80; ++_t) {\n      W[_t] = ROTL(W[_t - 3] ^ W[_t - 8] ^ W[_t - 14] ^ W[_t - 16], 1);\n    }\n\n    var a = H[0];\n    var b = H[1];\n    var c = H[2];\n    var d = H[3];\n    var e = H[4];\n\n    for (var _t2 = 0; _t2 < 80; ++_t2) {\n      var s = Math.floor(_t2 / 20);\n      var T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[_t2] >>> 0;\n      e = d;\n      d = c;\n      c = ROTL(b, 30) >>> 0;\n      b = a;\n      a = T;\n    }\n\n    H[0] = H[0] + a >>> 0;\n    H[1] = H[1] + b >>> 0;\n    H[2] = H[2] + c >>> 0;\n    H[3] = H[3] + d >>> 0;\n    H[4] = H[4] + e >>> 0;\n  }\n\n  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (sha1);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/sha1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nvar byteToHex = [];\n\nfor (var i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).substr(1));\n}\n\nfunction stringify(arr) {\n  var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  var uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!Object(_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (stringify);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/stringify.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v1.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v1.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n // **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nvar _nodeId;\n\nvar _clockseq; // Previous uuid creation time\n\n\nvar _lastMSecs = 0;\nvar _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  var i = buf && offset || 0;\n  var b = buf || new Array(16);\n  options = options || {};\n  var node = options.node || _nodeId;\n  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    var seedBytes = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])();\n\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n\n  var msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  var dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  var tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (var n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf || Object(_stringify_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(b);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (v1);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/v1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v3.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v3.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _v35_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/esm-browser/v35.js\");\n/* harmony import */ var _md5_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./md5.js */ \"./node_modules/uuid/dist/esm-browser/md5.js\");\n\n\nvar v3 = Object(_v35_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('v3', 0x30, _md5_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n/* harmony default export */ __webpack_exports__[\"default\"] = (v3);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/v3.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v35.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v35.js ***!
  \***************************************************/
/*! exports provided: DNS, URL, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DNS\", function() { return DNS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"URL\", function() { return URL; });\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n/* harmony import */ var _parse_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/esm-browser/parse.js\");\n\n\n\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  var bytes = [];\n\n  for (var i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n\n  return bytes;\n}\n\nvar DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nvar URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\n/* harmony default export */ __webpack_exports__[\"default\"] = (function (name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n\n    if (typeof namespace === 'string') {\n      namespace = Object(_parse_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(namespace);\n    }\n\n    if (namespace.length !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n\n    var bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n\n    if (buf) {\n      offset = offset || 0;\n\n      for (var i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n\n      return buf;\n    }\n\n    return Object(_stringify_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n});\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/v35.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v4.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\n\nfunction v4(options, buf, offset) {\n  options = options || {};\n  var rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (var i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return Object(_stringify_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(rnds);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (v4);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/v4.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v5.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v5.js ***!
  \**************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _v35_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/esm-browser/v35.js\");\n/* harmony import */ var _sha1_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./sha1.js */ \"./node_modules/uuid/dist/esm-browser/sha1.js\");\n\n\nvar v5 = Object(_v35_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('v5', 0x50, _sha1_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n/* harmony default export */ __webpack_exports__[\"default\"] = (v5);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/v5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/validate.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
  \********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/esm-browser/regex.js\");\n\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (validate);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/validate.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/version.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/version.js ***!
  \*******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n\nfunction version(uuid) {\n  if (!Object(_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  return parseInt(uuid.substr(14, 1), 16);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (version);\n\n//# sourceURL=webpack:///./node_modules/uuid/dist/esm-browser/version.js?");

/***/ }),

/***/ "./src/main/const.ts":
/*!***************************!*\
  !*** ./src/main/const.ts ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.electronEvent = void 0;\r\nexports.electronEvent = {\r\n    /** サーバー起動 */\r\n    START_SERVER: 'start-server',\r\n    /** サーバー停止 */\r\n    STOP_SERVER: 'stop-server',\r\n    /** Config適用 */\r\n    APPLY_CONFIG: 'apply-config',\r\n    /** アラート表示 */\r\n    SHOW_ALERT: 'show-alert',\r\n    SAVE_CONFIG: 'save-config',\r\n    /** 棒読み再生 */\r\n    PLAY_TAMIYASU: 'play-tamiyasu',\r\n    /** レス着信音再生 */\r\n    PLAY_SOUND_START: 'play-sound-start',\r\n    PLAY_SOUND_END: 'play-sound-end',\r\n    WAIT_YOMIKO_TIME: 'wait-yomiko-time',\r\n    SPEAKING_END: 'speaking-end',\r\n    /** コメント表示 */\r\n    SHOW_COMMENT: 'show-comment',\r\n    /** コメント欄初期化 */\r\n    CLEAR_COMMENT: 'clear-comment',\r\n    /** 翻訳コメント表示 */\r\n    SHOW_COMMENT_TL: 'show_comment_translate',\r\n    /** サーバー起動の返信 */\r\n    START_SERVER_REPLY: 'start-server-reply',\r\n    /** 強制的に端にスクロール */\r\n    FORCE_SCROLL: 'FORCE_SCROLL',\r\n    /** ステータス更新 */\r\n    UPDATE_STATUS: 'UPDATE_STATUS',\r\n    /** コメントテスト */\r\n    COMMENT_TEST: 'COMMENT_TEST',\r\n    /** 画像プレビュー */\r\n    PREVIEW_IMAGE: 'PREVIEW_IMAGE',\r\n    /** Azure Speech To text **/\r\n    AZURE_STT_START: 'azure-stt-start',\r\n    AZURE_STT_STOP: 'azure-stt-stop',\r\n    AZURE_STT_EVENT: 'azure-stt-event',\r\n};\r\n\n\n//# sourceURL=webpack:///./src/main/const.ts?");

/***/ }),

/***/ "./src/renderer/azureStt.ts":
/*!**********************************!*\
  !*** ./src/renderer/azureStt.ts ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\n// マイクからの入力は Renderer 側でしかできないので、こちらで認識全体を行う\r\nvar __importDefault = (this && this.__importDefault) || function (mod) {\r\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\r\n};\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar electron_1 = __importDefault(__webpack_require__(/*! electron */ \"electron\"));\r\nvar electron_log_1 = __importDefault(__webpack_require__(/*! electron-log */ \"./node_modules/electron-log/src/index.js\"));\r\nvar logger = electron_log_1.default.scope('renderer-azureStt');\r\nvar const_1 = __webpack_require__(/*! ../main/const */ \"./src/main/const.ts\");\r\nvar microsoft_cognitiveservices_speech_sdk_1 = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js\");\r\nvar ipcRenderer = electron_1.default.ipcRenderer;\r\nvar speechRecognizer;\r\nvar start = function (key, region, language, inputDevice) {\r\n    logger.info('starting text recognition from microphone.');\r\n    var speechConfig = microsoft_cognitiveservices_speech_sdk_1.SpeechConfig.fromSubscription(key, region);\r\n    speechConfig.speechRecognitionLanguage = language;\r\n    var audioConfig = microsoft_cognitiveservices_speech_sdk_1.AudioConfig.fromMicrophoneInput(inputDevice === '' ? undefined : inputDevice);\r\n    var startTime = Date.now();\r\n    var recognizer = new microsoft_cognitiveservices_speech_sdk_1.SpeechRecognizer(speechConfig, audioConfig);\r\n    recognizer.recognized = function (s, e) {\r\n        if (e.result.text) {\r\n            logger.debug('text recognized:' + e.result.text);\r\n            ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'comment', { date: new Date(startTime + e.result.offset / 10000).toLocaleString(), text: e.result.text });\r\n        }\r\n    };\r\n    recognizer.canceled = function (s, e) {\r\n        logger.warn('text recognition is canceled.');\r\n        if (e.reason == microsoft_cognitiveservices_speech_sdk_1.CancellationReason.Error) {\r\n            ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'error', { date: new Date(startTime + e.offset / 10000).toLocaleString(), text: 'Speech recognition error.' });\r\n        }\r\n        recognizer.stopContinuousRecognitionAsync();\r\n        if (speechRecognizer === recognizer) {\r\n            speechRecognizer = undefined;\r\n        }\r\n    };\r\n    recognizer.sessionStopped = function (s, e) {\r\n        logger.warn('text recognition session is stopped.');\r\n        recognizer.stopContinuousRecognitionAsync();\r\n        if (speechRecognizer === recognizer) {\r\n            speechRecognizer = undefined;\r\n        }\r\n    };\r\n    speechRecognizer = recognizer;\r\n    recognizer.startContinuousRecognitionAsync();\r\n    ipcRenderer.send(const_1.electronEvent.AZURE_STT_EVENT, 'end');\r\n};\r\nvar stop = function () {\r\n    if (speechRecognizer) {\r\n        speechRecognizer.stopContinuousRecognitionAsync();\r\n        speechRecognizer = undefined;\r\n    }\r\n};\r\nipcRenderer.on(const_1.electronEvent.AZURE_STT_START, function (event, arg) {\r\n    logger.debug('DOM Content Loaded');\r\n    start(arg.key, arg.region, arg.language, arg.inputDevice);\r\n});\r\nipcRenderer.on(const_1.electronEvent.AZURE_STT_STOP, function (event) {\r\n    stop();\r\n});\r\n\n\n//# sourceURL=webpack:///./src/renderer/azureStt.ts?");

/***/ }),

/***/ 0:
/*!********************!*\
  !*** ws (ignored) ***!
  \********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///ws_(ignored)?");

/***/ }),

/***/ 1:
/*!******************************************!*\
  !*** ../../external/ocsp/ocsp (ignored) ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///../../external/ocsp/ocsp_(ignored)?");

/***/ }),

/***/ 2:
/*!****************************!*\
  !*** agent-base (ignored) ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///agent-base_(ignored)?");

/***/ }),

/***/ 3:
/*!**********************************!*\
  !*** async-disk-cache (ignored) ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///async-disk-cache_(ignored)?");

/***/ }),

/***/ 4:
/*!***********************************!*\
  !*** https-proxy-agent (ignored) ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///https-proxy-agent_(ignored)?");

/***/ }),

/***/ "electron":
/*!***************************!*\
  !*** external "electron" ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"electron\");\n\n//# sourceURL=webpack:///external_%22electron%22?");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"events\");\n\n//# sourceURL=webpack:///external_%22events%22?");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"fs\");\n\n//# sourceURL=webpack:///external_%22fs%22?");

/***/ }),

/***/ "http":
/*!***********************!*\
  !*** external "http" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"http\");\n\n//# sourceURL=webpack:///external_%22http%22?");

/***/ }),

/***/ "https":
/*!************************!*\
  !*** external "https" ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"https\");\n\n//# sourceURL=webpack:///external_%22https%22?");

/***/ }),

/***/ "net":
/*!**********************!*\
  !*** external "net" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"net\");\n\n//# sourceURL=webpack:///external_%22net%22?");

/***/ }),

/***/ "os":
/*!*********************!*\
  !*** external "os" ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"os\");\n\n//# sourceURL=webpack:///external_%22os%22?");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"path\");\n\n//# sourceURL=webpack:///external_%22path%22?");

/***/ }),

/***/ "tls":
/*!**********************!*\
  !*** external "tls" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"tls\");\n\n//# sourceURL=webpack:///external_%22tls%22?");

/***/ }),

/***/ "url":
/*!**********************!*\
  !*** external "url" ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"url\");\n\n//# sourceURL=webpack:///external_%22url%22?");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"util\");\n\n//# sourceURL=webpack:///external_%22util%22?");

/***/ })

/******/ });